# 統計理論

[toc]
<!-- toc --> 

## 邏輯回歸

- [數據科學家要先學邏輯迴歸？圖樣圖森破！ - 幫趣](http://bangqu.com/j8Hxw7.html#utm_source=Facebook_PicSee&utm_medium=Social)

    > 下面列出了5條邏輯迴歸應放在最後學習的理由：
    > 
    > * 存在着上百種不同類型的邏輯迴歸，一些適用於分類變量，一些適用於特定的分佈（例如泊松分佈）。專家在使用時也常常感到困惑，初學者和你的老闆更會如此。
    > 
    > * 轉換因變量後（通常是比例或二值型因變量，例如本文觀點正確/錯誤），問題就變成了線性迴歸。雖然純粹主義者聲稱實際的邏輯迴歸模型更精確，然而相較於模型的精確度，數據的質量纔是至關重要的。如果數據有20%的噪聲，或者理論模型是對實際情況的粗略估計，那麼模型精確度高出1%並沒有實際用處。
    > 
    > * 除非能夠妥善處理（例如使用ridge或Lasso迴歸），否則在噪聲、缺失值和髒數據的影響下會導致模型過度擬合及缺乏穩健性（使用例如梯度優化等技術的迭代算法）。
    > 
    > * 邏輯迴歸的係數不容易解釋。當你對決策者或者其他部門解釋模型時，很少有人能夠理解。
    > 
    > * 最好的模型通常會將多種方法混合到一起，以便能儘可能多的獲得/解釋差異。在我作爲數據科學家長達30年的職業生涯中，從未使用過純邏輯迴歸，但我開發出了一項更加穩健且便於使用及編程的混合技術，結果也容易解讀。它將「不純的」邏輯迴歸和「不純的」決策樹混合在一起，效果十分顯著，尤其是對於你的「不純」數據評分時。詳情請戳。
    >     
