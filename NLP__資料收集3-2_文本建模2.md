# NLP__資料收集3-2_文本建模2

[toc]
<!-- toc --> 

# CNN-based model

## CNN over Tree Structures

- [[1409.5718] Convolutional Neural Networks over Tree Structures for Programming Language Processing](https://arxiv.org/abs/1409.5718)

- [[1504.01106] Discriminative Neural Sentence Modeling by Tree-Based Convolution](https://arxiv.org/abs/1504.01106)

- [[1512.08422] Natural Language Inference by Tree-Based Convolution and Heuristic Matching](https://arxiv.org/abs/1512.08422)




## CNN on Word2Vec

### Multi-Perspective Sentence Similarity Modeling with Convolution Neural Networks

- [he+etal.emnlp15.pdf](http://ttic.uchicago.edu/~kgimpel/papers/he+etal.emnlp15.pdf)

- [论文阅读笔记: Multi-Perspective Sentence Similarity Modeling with Convolution Neural Networks - gart - 博客园](https://www.cnblogs.com/databingo/databingo/p/9280716.html)

    > 处理比较两个句子相似度的问题, 适用于解决智能客服问题匹配场景中用户提交的问句与知识库中问句的匹配.

- [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)

    > ### He’s Paper
    > 
    > 第四篇论文即He的文章中所提出的模型，是所有基于NN的模型中，在Paraphrase identification任务标准数据集MSRP上效果最佳的。下面我们来学习一下这个模型。
    > 
    > #### 模型结构与原理
    > 
    > 模型主要分为两个部分：
    > 
    > -   **句子的表征模型**：得到句子的表征(representation)，以供后续的相似度计算；
    > -   **相似度计算模型**：使用多种相似度计算方法，针对句子表征后的局部进行相应的计算；
    > 
    > 模型不需要借助WordNet, 句法解析树等资源；但是可以选择性地使用词性标注、word embedding等方法来增强模型的性能；与之前的模型区别在于，文中的模型使用了多种类型的卷积、池化方法，以及针对得到的句子表征的局部进行相应的相似度计算。（这样做的优点在于能够更加充分地挖掘出句子中的特征信息，从而提升性能，但同时使得模型变得复杂、耗时）
    > 
    > 模型的整体框架如下：
    > 
    > [![](http://i.imgur.com/uz4z7le.png)](http://i.imgur.com/uz4z7le.png)
    > 
    > 下面具体看看这两个模型是如何实现的。
    > 
    > 1.  **句子的表征模型**
    > 
    >     模型是基于CNN的，卷积层有两种卷积方式，池化层则有三种。
    > 
    >     -   **卷积层**
    > 
    >         假设模型的输入为二维矩阵 $Sent$ ， $Sent \in R^{len×Dim}$ ，其中 $len$ 表示句子切分为Token List后的长度(Token可以是词/字)，$Dim$ 表示Token的Embedding表示的维度。由此有 $Sent_{i}$ 表示矩阵的第 $i$ 行，即输入中的第 $i$ 个Token的Embedding表示；$Sent_{i:j}$ 表示矩阵中的第 $i$ 到第 $j$ 行的一个切片，也是一个子矩阵；$Sent_{i}^{[k]}$ 表示矩阵的第 $i$ 行第 $k$ 列的值，对应是Embedding的第 $k$ 个值；而 $Sent_{i:j}^{[k]}$ 则是矩阵中第 $i$ 行到第 $j$ 行中的第 $k$ 列的一个切片。
    > 
    >         卷积层有两种卷积的方式：(1)粒度为word的卷积;(2)粒度为embedding 维度上的卷积。如下图：
    > 
    >         [![](http://i.imgur.com/26LDDfD.png)](http://i.imgur.com/26LDDfD.png)
    > 
    >         其中，第一种卷积方式与之前的Kim Y提出模型中的相同，相当于是_n-gram_特征的抽取；而对于第二种卷积方式，论文作者给出的解释是，(1)这种方式有助于充分地提取出输入的特征信息；(2)由于粒度更小，所以在学习过程中的参数调整上，每一个维度能够得到不同程度的参数调整。（第二种卷积方式从直观上没有太多的物理意义，而作者也是直说不能够给出符合人直观想法上的解释）。
    > 
    >     -   **池化层**
    > 
    >         模型除了使用传统的`max-pooling`，还使用了`min-pooling`和`mean-pooling`方式。
    > 
    >         假设 $group(ws, pooling, sent)$ 表示卷积宽度为 $ws$，使用 $pooling$ 池化函数，应用在输入的句子 $sent$ 上。我们使用了两种类型的 **`building block`** ，分别是 $block_{A}$ 和 
    > 
    >         $block_{B}$ 上，定义如下
    > 
    >         $$block_{A} = \lbrace group_{A}(ws_{a}, p, sent): p \in {max, min, mean} \rbrace$$
    > 
    >         这里 $block_{A}$ 有三组卷积层，卷积窗口的宽度一致(都是 $ws_{a}$ )，每一组对应一种池化操作。这里池化操作和卷积层是一一对应的，也就是说并不是一个卷积层上实施三种池化操作(虽然也可以这么做，作者没有这么做的原因是由于激活函数的存在，对每个卷积结果都进行`max-pooling`和`min-pooling`是没有必要的)。
    > 
    >         而 $block_{B}$ 的定义如下：
    > 
    >         $$block_{B} = \lbrace group_{B}(ws_{b}, p, sent): p \in {max, min} \rbrace$$
    > 
    >         这里 $block_{B}$ 有两组卷积层，卷积窗口的宽度为 $ws_{b}$，两组分别对应`max-pooling`和`min-pooling`的操作。值得说明的是，$group_{B}(*)$ 中的卷积层对应有 
    > 
    >         $Dim$ 个以`embedding dimension`为粒度的卷积窗口，也就是对`embedding`的每一维度做卷积运算。
    > 
    >         这里只所以要组合这些多样的卷积和池化操作，原因是希望能够从多个方面来提取出输入中的特征信息，以供后续的决策任务。
    > 
    >     -   **多种窗口尺寸**
    > 
    >         与传统的_n-gram_模型相似，这里在 **`building block`** 中使用了多种尺寸的卷积窗口。如下图所示：
    > 
    >         [![](http://imgur.com/kRijNVc.png)](http://imgur.com/kRijNVc.png)
    > 
    >         其中 $ws$ 表示卷积时卷积的 _n-gram_ 长度，而 $ws=\infty$ 表示卷积窗口为整个`word embedding`矩阵。
    > 
    >         $ws$ 的值及`Feature Map` 的数量都是需要调参的。
    > 
    > 1.  **相似度计算模型**
    > 
    >     下面介绍在得到句子的表征向量之后，如何计算它们的相似度。直观的想法是，我们可以使用传统的相似度计算方法如余弦相似度等来计算两个句子向量的相似度。但是，**直接应用这种做法在两个句子向量上并不是最优的**，原因在于最后生成的句子向量中的每一个部分的意义各不相同，这样简单粗暴的计算势必会影响效果，所以做法是**对句子向量中的各个部分进行相应的比较和计算(Structured Comparision)**。为了使得句子向量中的局部间的比较和计算更加有效，我们需要考虑如下方面：
    > 
    >     (1) 是否来自相同的`building block`；  
    >     (2) 是否来自相同卷积窗口大小下的卷积结果；  
    >     (3) 是否来自相同的`pooling层`；  
    >     (4) 是否来自相同的`Feature Map`；
    > 
    >     最终比较句子中的相应部分时，需要至少满足以上两个条件。为了识别句子中的哪些对应部分需要参与到相似度计算，文中提供了两种算法。
    > 
    > 2. **相似度计算单元(Unit)**
    > 
    >     两种相似度计算单元如下：
    > 
    >     [![](http://imgur.com/wttqwKe.png)](http://imgur.com/wttqwKe.png)
    > 
    > 2. **基于句子局部的相似度计算**
    > 
    >     算法1和算法2为句子表征向量的两种计算方法，其中算法1仅用在 
    > 
    >     $block_{A}$ 上；而算法2则都用在 $block_{A}$ 和 
    > 
    >     $block_{B}$ 上，两种算法都是针对相同类型(pooling和block类型)的输出做局部比较。
    > 
    >     给出如下的符号假设：
    > 
    >     [![](http://imgur.com/0Oxsp9O.png)](http://imgur.com/0Oxsp9O.png)
    > 
    >     算法的伪代码如下：
    > 
    >     [![](http://imgur.com/pkDPaky.png)](http://imgur.com/pkDPaky.png)
    > 
    >     下面的图示说明了在 $block_{A}$ 上，两种算法的计算方式的区别，算法一表现了向量在水平方向上的比较；而算法二则是在垂直方向。
    > 
    >     [![](http://imgur.com/f4qrseS.png)](http://imgur.com/f4qrseS.png)
    > 
    >     需要注意的是，在算法二中相同类型的pooling的输出groups中，向量是两两进行比较的（图中的红色虚线只是为了说明比较的方向，并不是只针对group中相同大小的卷积窗口作比较）；而算法一中的每一行都要作比较，不仅仅是第一行。
    > 
    > 1.  **模型的其他细节**
    > 
    >     -   **相似度向量输出 \+ 全连接层**
    > 
    >         基于句子局部的相似度计算之后，得到相应的相似度向量；然后这组向量之后连接一个全连接层，最后softmax对应输出。如果是计算相似度度量值，可以用softmax输出的类别概率值。
    > 
    >     -   **激活函数**
    > 
    >         使用`tanh`函数作为激活函数。
    > 
    > #### 实验部分
    > 
    > 1.  **实验数据集**
    > 
    >     -   [Microsoft Research Paraphrase Corpus (MSRP)](http://research.microsoft.com/en-us/downloads/607d14d9-20cd-47e3-85bc-a2f65cd28042/)
    > 
    >         用于评测同义句检测 (Paraphrase Identification) 任务的经典数据集，数据集来源于新闻；包含5801对句子对，其中4076对用于模型训练，而1725对用于测试；每一对句子拥有一个标签，0或者1,0表示两个句子不是互为同义句，而1则表示两个句子互为同义句。因此这是一个二分类的任务。
    > 
    >     -   [Sentences Involving Compositional Knowledge (SICK)](http://alt.qcri.org/semeval2014/task1/index.php?id=data-and-tools)
    > 
    >         数据来源于2014年SemEval比赛，数据集有9927对句子对，其中4500对用于模型训练，500对用于模型验证，而剩下的4927对用于模型测试。这些句子都是在图片和视频描述中抽取得到的，每一对句子对有一个相关分数，区间在\[1, 5\]，分数越高表示句子越相关。
    > 
    >     -   [Microsoft Video Paraphrase Corpus (MSRVID)](https://www.cs.york.ac.uk/semeval-2012/task6/data/uploads/datasets/train-readme.txt)
    > 
    >         数据集来源于2012年的SemEval比赛，包含1500对短文本（用于描述视频信息）。其中一般用于模型训练，一半用于模型测试，每一对句子有一个相关性分数，区间在\[0, 5\]，分数越高表示句子越相关。
    > 
    > 1.  **模型训练**
    > 
    >     针对MSRP和其他两个数据集，分别使用两种损失函数。对于MSRP数据集，损失函数（Hinge Loss）如下：
    > 
    >     [![](http://imgur.com/jjQu3pY.png)](http://imgur.com/jjQu3pY.png)
    > 
    >     对于其余两个数据集，损失函数（KL-divergence Loss）如下：
    > 
    >     [![](http://imgur.com/kfVigMW.png)](http://imgur.com/kfVigMW.png)
    > 
    > 1.  **实验参数设置**
    > 
    >     -   **$ws$ 的值**：$ws \in [1, 3]$和 $ws=\infty$.
    >     -   **Word Embedding**: 300维的`GloVe word embedding`；对于MSRP数据集，还额外使用了200维的`POS embedding` ([Standford POS tagger](http://nlp.stanford.edu/software/tagger.shtml))和25维的`Paragram Vectors` ([Wieting et al., 2015 PDF](http://ttic.uchicago.edu/~wieting/wieting2015TACL.pdf)，[数据下载地址](http://ttic.uchicago.edu/~wieting/paragram_vectors.txt))。因此对于MSRP任务而言，`word embedding`的维数为525维 (200+300+25)；而其余两个任务则对应是300维。
    >     -   在MSRP上使用了 **5-折交叉验证** 的方式，对模型参数进行 _tuning_. _Tuning_ 好的模型参数将会用在另外两个数据集任务上。
    >     -   只有在MSRP数据集任务上，允许模型参数进行更新。
    >     -   输出的全连接层，MSRP有250个神经元节点，而SICK和MSRVID则是150个。
    >     -   在 $block_{A}$ 中，`Feature Map` 的数量与输入的`embedding`维数相同，即MSRP是525个，而SICK和MSRVID则是300个。
    >     -   优化算法使用随机梯度下降方法。
    >     -   学习率为0.01，而正则化参数 $\lambda=10^{-4}$.
    > 
    > 1.  **实验结果**
    > 
    >     -   **MSRP数据集**
    > 
    >         [![](http://imgur.com/CLF0SKJ.png)](http://imgur.com/CLF0SKJ.png)
    > 
    >         可以看出，文中的模型是所有基于NN的方法中在MSRP数据集上性能最好的。
    > 
    >     -   **SICK数据集**
    > 
    >         [![](http://imgur.com/16bJWHS.png)](http://imgur.com/16bJWHS.png)
    > 
    >     -   **MSRVID数据集**
    > 
    >         [![](http://imgur.com/s89LYEb.png)](http://imgur.com/s89LYEb.png)
    > 
    >         而模型在SICK和MSRVID数据集上的表现也很好。
    > 
    > 1.  **模型的敏感度分析**
    > 
    >     下面的表格说明了在不使用某种技术下，模型性能在实验数据集上的变化情况。
    > 
    >     [![](http://imgur.com/pmTY9TY.png)](http://imgur.com/pmTY9TY.png)
    > 
    >     从中可以得出以下结论：
    > 
    >     -   对于MSRP数据集任务而言，增加 **`POS Embedding`** 和 **`Paragram Vector`** 效果显著；
    >     -   移除相似度计算层的影响显著，说明结构化的句子局部比较方法是有效且必要的；
    >     -   **`Horizontal`** 和 **`Vertical`** 算法均有一定的提升效果，而 **`Vertical`** 算法的提升程度更高；
    >     -   **`max-pooling`** 方式确实要比 **`min-pooling`** 和 **`mean-pooling`** 强太多。
    > 
    > 1.  **总结**
    > 
    >     文中的模型包含两个部分：卷积-池化模型和相似度计算模型。实验部分已经验证了模型的有效性，在MSRP数据集上模型取得了仅次于state-of-art的结果，并且在基于NN的方法中是最好的。模型中的相似度计算层是有必要的，因为对卷积池化处理后的句子成分进行了针对性的比较，从直观上要比直接扔进全连接层更合理，而实验结果也表明了这一点。
    > 
    >     然而，个人觉得，文中的模型结构较为复杂，而且其中有很多trick的地方，比如为什么要对word embedding中的每一维度做卷积，$block_{B}$ 中的`pooling`方式为什么只用了max和min，不用mean的方式等问题，而这些方式或许是作者自己做了大量实验后，从果到因而使用的。
    >     


- [论文Multi-Perspective Sentence Similarity Modeling with Convolution Neural Networks实现之数据集制作 - 飞星恋的博客 - CSDN博客](https://blog.csdn.net/weixin_34613450/article/details/82350456)

    > 1. 数据集
    >     本文采用的是STS数据集，如下图所示，包括所有的2012-2016年的数据，而all文件夹包含2012-2015的所有数据。
    >     
    >     ![](https://i.imgur.com/niHwo0E.jpg)
    >     
    >     每一个文件的具体数据如下所示，每一行为一个三元组：<相似性得分，句子1，句子2>.
    >     
    >     ![](https://i.imgur.com/ADwhyb3.jpg)
    > 
    >     在实现时将all文件夹中的所有数据当作训练集，将2016年的文件当作测试集。
    >     
    > 1. 数据读取
    > 
    >     采用以下代码进行单个文件的数据读取：
    > 
    >     ```python
    >     """读取一个数据集文件"""
    >     def load_one_sts(filename):
    >         s0s = []
    >         s1s = []
    >         labels = []
    >         num_samples = 0
    >         with open(filename, 'r', encoding='utf-8') as f:
    >             for line in f:
    >                 #rstrip:是从字符串最右边删除了参数指定字符后的字符串，不带参数进去则是去除最右边的空格
    >                 #strip:同时去除左右两边指定的字符,不带参数进去则是去除空格
    >                 data = line.rstrip()
    >                 # line = data.split('\t')
    >                 # print(line)
    >                 label, s0, s1 = data.split('\t')
    >                 #如果没有对应的相似性得分，则直接跳过
    >                 if label == '':
    >                     continue
    >                 else:
    >                     score = round(float(label)) #如果距离两边一样远，会保留到偶数的一边。比如round(0.5)和round(-0.5)都会保留到0，而round(1.5)会保留到2
    >                     # scores.append(score)
    >                     """经验证可知score的取值范围为0-5，故标签使用one-hot encoding，数目为6"""
    >                     y = [0] * 6  #此时的y是一个list
    >                     y[score] = 1 #将score值所对应的位置置为1
    >                     labels.append(np.array(y)) #此时label转换完成,内置元素应为array
    >                     # labels = np.asarray(labels)
    >                     num_samples = len(labels)
    >                     s0s.append(s0)
    >                     s1s.append(s1)
    >     ```
    > 
    >     注意：如上面所示代码data = line.rstrip()，在本地文件中，有的两个句子是没有对应的相似度得分的，此时对应字段为空，如果使用data = line.strip()，程序会将这一行左面的空格去掉，在后面进行循环读取每个文件的时候会报错：You don't get unenough unpacks(expected 3, get 2)这样的信息。
    > 
    >     此时已经将相似度得分，句子1，句子2分别存储，接下来就是将每一个句子映射成id索引的组合形式，这就需要读入GloVe模型，以下代码为读入GloVe模型的辅助函数（这些函数在另一个文件embedding.py中）：
    > 
    >     ```python
    >     import word2vec
    >     import os
    >     import shutil
    >     from sys import platform
    >     import numpy as np
    >     import pandas as pd
    > 
    >     # 计算行数，就是单词数
    >     def getFileLineNums(filename):
    >         f = open(filename, 'r', encoding='utf-8')
    >         count = 0
    >         for line in f:
    >             count += 1
    >         return count
    > 
    >     # Linux或者Windows下打开词向量文件，在开始增加一行
    >     def prepend_line(infile, outfile, line):
    >         with open(infile, 'r', encoding='utf-8') as old:
    >             with open(outfile, 'w', encoding='utf-8') as new:
    >                 new.write(str(line) + "\n")
    >                 shutil.copyfileobj(old, new)
    > 
    >     def prepend_slow(infile, outfile, line):
    >         with open(infile, 'r', encoding='utf-8') as fin:
    >             with open(outfile, 'w', encoding='utf-8') as fout:
    >                 fout.write(line + "\n")
    >                 for line in fin:
    >                     fout.write(line)
    > 
    >     """生成符合word2vec工具读取格式的模型文件"""
    >     def normalize_data(filename):
    >         num_lines = getFileLineNums(filename)
    >         model_file = 'glove_model_50d.txt'
    >         model_first_line = "{} {}".format(num_lines, 50)
    >         # Prepends the line.
    >         if platform == "linux" or platform == "linux2":
    >             prepend_line(filename, model_file, model_first_line)
    >         else:
    >             prepend_slow(filename, model_file, model_first_line)
    >         print('模型向量文件数据已规范化！后续请使用文件', model_file)
    > 
    >     """读取Glove模型，生成id和词向量"""
    >     def load_glove_model(glove_model_path):
    >         normalize_data(glove_model_path)
    >         wv = word2vec.load('glove_model_50d.txt')
    >         print('GloVe模型载入完毕！')
    >         vocab = wv.vocab
    >         word2id = pd.Series(range(1, len(vocab)+1), index=vocab)
    >         #将未知词对应的id设置为0，对应word_embedding中的第0行
    >         word2id['< unk>'] = 0
    >         # print(word2id[399990:])
    >         print('word2id转换完成，未知词使用< unk>标识符！')
    >         word_embedding = wv.vectors
    >         #采取均值作为未知词的词向量表示
    >         word_mean = np.mean(word_embedding, axis=0)
    >         word_embedding = np.vstack([word_mean, word_embedding])
    >         # print(word_embedding[:2])
    >         print('id词向量嵌入完成！')
    > 
    >         return word2id, word_embedding
    >     ```
    > 
    >     由于官方提供的GloVe文件格式并不符合word2vec工具读取的要求，故使用其中的normalize_data()将其标准化，未知词采用`<unk>`标记，继而调用load_glove_model()得到word2id和word_embedding。得到词对应的嵌入向量之后，对第一步读取到的数据进行映射。
    > 
    >     ```python
    >     """通过单词获取id"""
    >     def get_id(word):
    >         if word in word2id:
    >             return word2id[word]
    >         else:
    >             return word2id['< unk>']
    > 
    >     """数据清洗并将句子表示成索引组合"""
    >     def seq2id(texts):
    >         texts = clean_text(texts)
    >         texts = texts.split(' ')
    >         texts_id = map(get_id, texts)
    >         return texts_id
    > 
    >     """填充句子, padding_length:句子填充的长度"""
    >     def padding_sentence(s0, s1, padding_length):
    >         sentence_num = len(s1)
    >         # sentence_length = 100
    >         # print('句子填充长度为100')
    >         s0s = []
    >         s1s = []
    > 
    >         for s in s0:
    >             left = padding_length -len(s)
    >             pad = [0] * left
    >             s= list(s)
    >             s.extend(pad)
    >             s0s.append(np.array(s))
    >         for s in s1:
    >             left = padding_length -len(s)
    >             pad = [0] * left
    >             s= list(s)
    >             s.extend(pad)
    >             s1s.append(np.array(s))
    > 
    >         # print('%d个句子填充完毕！'%sentence_num)
    >         return s0s, s1s
    >     ```
    > 
    >     上面所示为句子映射的辅助函数，其中seqid()用来得到句子各个单词对应的id。实际情况中每条句子的长度都不一样，导致输入网络的tensor长度也不一致，故此处调用padding_sentence()填充各个句子（此处使用定长100， 有些地方使用最长句子的长度来进行填充）。
    > 
    >     其中数据清洗函数如下所示，对于其中的标点（！、......等）、缩写（You're替换成You 're）等进行处理：
    > 
    >     ```python
    >     """数据清洗函数"""
    >     def clean_text(line):
    >         # print('过滤前--------------->', line)
    >         #替换掉无意义的单个字符
    >         line = re.sub(r'[^A-Za-z0-9(),!?.\'\`]', ' ', line)
    >         """使用空格将单词后缀单独分离开来"""
    >         line = re.sub(r'\'s', ' \'s ', line)
    >         line = re.sub(r'\'ve', ' \'ve ', line)
    >         line = re.sub(r'n\'t', ' n\'t ', line)
    >         line = re.sub(r'\'re', ' \'re ', line)
    >         line = re.sub(r'\'d', ' \'d ',line)
    >         line = re.sub(r'\'ll', ' \'ll ',line)
    >         """使用空格将标点符号、括号等字符单独分离开来"""
    >         line = re.sub(r',', ' , ', line)
    >         line = re.sub(r'!', ' ! ', line)
    >         line = re.sub(r'\?', ' \? ', line)
    >         line = re.sub(r'\(', ' ( ', line)
    >         line = re.sub(r'\)', ' ) ', line)
    >         line = re.sub(r'\s{2,}', ' ', line)
    >         # line = re.sub(r'\n', '', line)
    >         # line = re.sub(r'')
    >         # line = re.sub(r',', ' , ', line)
    >         # print('过滤后--------------->',line)
    >         return line.strip().lower()
    >     ```
    > 
    >     做完上述动作，继续在load_one_sts()函数中进行编辑：
    > 
    >     ```python
    >     def load_one_sts(filename):
    >         """以下是紧接着第一部分继续编写的代码，二者合起来才是一个完整的函数"""
    >         s0s_id = []
    >         for s0 in s0s:
    >             s0_id = list(seq2id(s0))
    >             # print(type(s0_id))
    >             # print('s0_id:', s0_id)
    >             s0s_id.append(np.asarray(s0_id))
    > 
    >         s1s_id = []
    >         for s1 in s1s:
    >             s1_id = list(seq2id(s1))
    >             s1s_id.append(np.asarray(s1_id))
    > 
    >         #句子填充,填充长度为100
    >         s0_padding, s1_padding= padding_sentence(s0s_id, s1s_id, 100)
    >         # print(len(s0_padding[0]))
    >         # print(s0_padding[0])
    >         return s0_padding, s1_padding, labels
    > 
    >     ```
    > 
    >     如上所示，单个文件的读取编写完毕，接下来需要遍历某个路径下的所有文件，将所得到的数据放入s0,s1,labels中。
    > 
    >     ```python
    >     """将不同文件的数据进行拼接"""
    >     def concat(data):
    >         s0s = []
    >         s1s = []
    >         labels = []
    >         for s0, s1, label in data:
    >             s0s += s0
    >             s1s += s1
    >             labels += label
    >         s0s = np.asarray(s0s)
    >         s1s = np.asarray(s1s)
    >         labels = np.asarray(labels)
    >         return s0s, s1s, labels
    > 
    > 
    >     """读取整个数据集"""
    >     def load_datasets(path):
    >         files = []
    >         #列出路径path下所有的文件
    >         for dirpath,dirnames,filenames in os.walk(path):
    >             for filename in filenames:
    >                 # print(os.path.join(dirpath,filename))
    >                 files.append(dirpath + '/' + filename)
    > 
    >         s0, s1, labels = concat([load_one_sts(file) for file in files])
    > 
    >         return ([s0, s1], labels)
    >     ```
    > 
    >     这样，我们就完成了某个路径下的所有数据文件的读取工作。
    > 
    >     为了放心，对其进行测试，读取测试集和训练集：
    > 
    >     ```python
    >     print('读取训练集-------》')
    >     path = './sts/semeval-sts/all'
    >     x_train, y_train = load_datasets(path)
    >     print('训练集样本数：', len(y_train))
    > 
    >     print('读取测试集-------》')
    >     path = './sts/semeval-sts/2016'
    >     x_test, y_test = load_datasets(path)
    >     print('测试集样本数：', len(y_test))
    >     ```
    > 
    >     程序执行结果如下所示：
    >     
    >     ![](https://i.imgur.com/j44ar8t.jpg)
    > 
    >     OK，至此我们就完成了数据集的读取和创建。下一步就是创建神经网络模型MPCNN，并应用其中的相似度计算公式来得到相似度得分。

### UMD-TTIC-UW at SemEval-2016 Task 1: Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement

- [CNN在句子相似性建模的应用续--基于attention的多角度CNN模型 - 呜呜哈的博客 - CSDN博客](https://blog.csdn.net/liuchonge/article/details/65451608)

    > 其实本篇论文和之前所说的Multi-Perspective CNN原理是一样的。只不过做了一些小的改进。接下来，我们来讲一下。
    > 首先看一下让他的模型架构， 其实就是在embedding层和Multi-Perspective句子建模层之间加入了一个Attention-Based输入层：
    > 
    > ![](https://i.imgur.com/AHDY5Oq.jpg)
    > 
    > 这么做的原因在于，MPCNN模型中，两个句子被相互独立的处理，直到full-connected层二者的信息才有了交互，这样会丢失很多有用的信息。而Attention-based层通过对两个句子的词嵌入矩阵进行融合，获得的新的“词向量”具有二者的信息，可以更好的表征句子的相互关系。其计算方法如下所示：
    > 1，计算attention matrix D（m*n维矩阵，m和n分别代表sent1和sent2的长度）。
    > Dij代表sent1中第i个单词的词向量与sent2中第j个单词的词向量的余弦距离
    > 2，计算每个句子的attention weight vector Ai（长度为对应句子长度）。其计算方法为：
    > 
    > ![](https://i.imgur.com/xzLEPTR.jpg)
    > 
    > 即对于sent1而言，对矩阵D的每一行求和得到E0，对于sent2而言，对矩阵D的每一列求和得到E1，然后使用softmax函数对其进行处理。最终我们获得的新的词向量的计算方式如下所示：
    > 
    > ![](https://i.imgur.com/WtcGbFl.jpg)
    > 
    > 至此，我们就把论文的模型介绍完了。接下来就是使用TensorFlow将Attention层实现即可。这里就不再对整个项目进行介绍，因为其都是基于MPCNN模型的，只不过在其上加了一个Attention层。直接介绍该函数的实现方法即可：
    > 
    > ```python
    > def attention_layer(sent1, sent2):
    > #在句子长度上对其进行切分，以获得每个单词的词向量
    >     sent1_unstack = tf.unstack(sent1, axis=1)
    >     sent2_unstack = tf.unstack(sent2, axis=1)
    >     D = []
    >     #求每个单词之间的余弦距离，得到Attention matrix D
    >     for i in range(len(sent1_unstack)):
    >         d = []
    >         for j in range(len(sent2_unstack)):
    >             dis = compute_cosine_distance(sent1_unstack[i], sent2_unstack[j])
    >             d.append(dis)
    >         D.append(d)
    >        #将D转化为适当维度的Tensor
    >     D = tf.reshape(D, [-1, len(sent1_unstack), len(sent2_unstack), 1])
    >     #计算Attention weight vector A
    >     A = [tf.nn.softmax(tf.expand_dims(tf.reduce_sum(D, axis=i), 2)) for i in [2, 1]]
    >     atten_embed = []
    >     #使用A与sent相乘，对其按照权重进行修正，计算新的词向量
    >     atten_embed.append(tf.concat([sent1, A[0]*sent1], 2))
    >     atten_embed.append(tf.concat([sent2, A[1] * sent2], 2))
    >     return atten_embed
    > ```
    > 
    > 
    > 注意，这里句子的词向量矩阵经过Attention层之后其每个单词的词向量维度变成了原来的两倍，所以接下来的代码中相应的参数也应该做出对应的修改。
    > 
    > 至此，我们在MPCNN的基础上就完成了Attention-Based这篇模型的代码实现。相比第一篇是不是简单了很多呢~~
    > 

## DCNN (Dynamic Convolutional Neural Network)

- [[1404.2188] A Convolutional Neural Network for Modelling Sentences](https://arxiv.org/abs/1404.2188)

- [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)

    > Kal的这篇文章引用次数较高，他提出了一种名为DCNN(Dynamic Convolutional Neural Network)的网络模型，在上一篇（Kim's Paper）中的实验结果部分也验证了这种模型的有效性。这个模型的精妙之处在于Pooling的方式，使用了一种称为 **`动态Pooling`** 的方法。
    > 
    > 下图是这个模型对句子语义建模的过程，可以看到底层通过组合邻近的词语信息，逐步向上传递，上层则又组合新的Phrase信息，从而使得句子中即使相离较远的词语也有交互行为（或者某种语义联系）。从直观上来看，这个模型能够通过词语的组合，提取出句子中重要的语义信息（通过Pooling），某种意义上来说，层次结构的 **`feature graph`** 的作用类似于一棵语法解析树。
    > 
    > [![](http://i.imgur.com/3IbLJX4.png)](http://i.imgur.com/3IbLJX4.png)
    > 
    > DCNN能够处理可变长度的输入，网络中包含两种类型的层，分别是**一维的卷积层**和**动态k-max的池化层(Dynamic k-max pooling)**。其中，动态k-max池化是最大化池化更一般的形式。之前LeCun将CNN的池化操作定义为一种非线性的抽样方式，返回一堆数中的最大值，原话如下：
    > 
    > > The max pooling operator is a non-linear subsampling function that returns the maximum of a set of values (LuCun et al., 1998).
    > 
    > 而文中的k-max pooling方式的一般化体现在：
    > 
    > -   pooling的结果不是返回一个最大值，而是返回k组最大值，这些最大值是原输入的一个子序列；
    > -   pooling中的参数k可以是一个动态函数，具体的值依赖于输入或者网络的其他参数；
    > 
    > #### 模型结构及原理
    > 
    > DCNN的网络结构如下图：
    > 
    > [![](http://i.imgur.com/CNMa0VL.png)](http://i.imgur.com/CNMa0VL.png)
    > 
    > 网络中的卷积层使用了一种称之为 **`宽卷积(Wide Convolution)`** 的方式，紧接着是动态的k-max池化层。中间卷积层的输出即`Feature Map`的大小会根据输入句子的长度而变化。下面讲解一下这些操作的具体细节：
    > 
    > **1\. 宽卷积**
    > 
    > 相比于传统的卷积操作，宽卷积的输出的`Feature Map`的宽度(width)会更宽，原因是卷积窗口并不需要覆盖所有的输入值，也可以是部分输入值（可以认为此时其余的输入值为0，即填充0）。如下图所示：
    > 
    > [![](http://i.imgur.com/YgM3Tsg.png)](http://i.imgur.com/YgM3Tsg.png)
    > 
    > 图中的右图即表示宽卷积的计算过程，当计算第一个节点即s1
    > 
    > 时，可以假使s1
    > 
    > 节点前面有四个输入值为0的节点参与卷积（卷积窗口为5）。明显看出，狭义上的卷积输出结果是宽卷积输出结果的一个子集。
    > 
    > **2\. k-max池化**
    > 
    > 给出数学形式化的表述是，给定一个k
    > 
    > 值，和一个序列p∈Rp(其中p≥k)，`k-max pooling`选择了序列p中的前k
    > 
    > 个最大值，这些最大值保留原来序列的次序（实际上是原序列的一个子序列）。
    > 
    > `k-max pooling`的好处在于，既提取除了句子中的较重要信息（不止一个），同时保留了它们的次序信息（相对位置）。同时，由于应用在最后的卷积层上只需要提取出k
    > 
    > 个值，所以这种方法允许不同长度的输入（输入的长度应该要大于k）。然而，对于中间的卷积层而言，池化的参数k
    > 
    > 不是固定的，具体的选择方法见下面的介绍。
    > 
    > **3\. 动态k-max池化**
    > 
    > 动态k-max池化操作，其中的k
    > 
    > 是`输入句子长度`和`网络深度`两个参数的函数，具体如下：
    > 
    > $$
    > K_{l}=\max \left( k_{top}, \left \lceil \frac {L-l}{L} s \right \rceil \right)
    > $$
    > 
    > 其中$l$
    > 
    > 表示当前卷积的层数（即第几个卷积层），L是网络中总共卷积层的层数；ktop为最顶层的卷积层pooling对应的k值，是一个固定的值。举个例子，例如网络中有三个卷积层，ktop=3，输入的句子长度为18；那么，对于第一层卷积层下面的pooling参数k1=12，而第二层卷积层对于的为k2=6，而k3=ktop=3
    > 
    > 。
    > 
    > 动态k-max池化的意义在于，从不同长度的句子中提取出相应数量的语义特征信息，以保证后续的卷积层的统一性。
    > 
    > **4\. 非线性特征函数**
    > 
    > pooling层与下一个卷积层之间，是通过与一些权值参数相乘后，加上某个偏置参数而来的，这与传统的CNN模型是一样的。
    > 
    > **5\. 多个Feature Map**
    > 
    > 和传统的CNN一样，会提出多个Feature Map以保证提取特征的多样性。
    > 
    > **6\. 折叠操作(Folding)**
    > 
    > 之前的宽卷积是在输入矩阵d×s
    > 
    > 中的每一行内进行计算操作，其中d是word vector的维数，s
    > 
    > 是输入句子的词语数量。而 **`Folding`** 操作则是考虑相邻的两行之间的某种联系，方式也很简单，就是将两行的vector相加；该操作没有增加参数数量，但是提前（在最后的全连接层之前）考虑了特征矩阵中行与行之间的某种关联。
    > 
    > #### 模型的特点
    > 
    > -   保留了句子中词序信息和词语之间的相对位置；
    > -   宽卷积的结果是传统卷积的一个扩展，某种意义上，也是n-gram的一个扩展；
    > -   模型不需要任何的先验知识，例如句法依存树等，并且模型考虑了句子中相隔较远的词语之间的语义信息；
    > 
    > #### 实验部分
    > 
    > **1\. 模型训练及参数**
    > 
    > -   输出层是一个类别概率分布（即softmax），与倒数第二层全连接；
    > -   代价函数为交叉熵，训练目标是最小化代价函数；
    > -   L2正则化；
    > -   优化方法：mini-batch + gradient-based (使用Adagrad update rule, Duchi et al., 2011)
    > 
    > **2\. 实验结果**
    > 
    > 在三个数据集上进行了实验，分别是(1)电影评论数据集上的情感识别，(2)TREC问题分类，以及(3)Twitter数据集上的情感识别。结果如下图：
    > 
    > [![](http://i.imgur.com/zuf2bSu.png)](http://i.imgur.com/zuf2bSu.png)
    > 
    > [![](http://i.imgur.com/6lWY7zC.png)](http://i.imgur.com/6lWY7zC.png)
    > 
    > [![](http://i.imgur.com/PX9N2JB.png)](http://i.imgur.com/PX9N2JB.png)
    > 
    > 可以看出，DCNN的性能非常好，几乎不逊色于传统的模型；而且，DCNN的好处在于不需要任何的先验信息输入，也不需要构造非常复杂的人工特征。


- [《A Convolutional Neural Network for Modelling Sentences 》阅读笔记](https://zhuanlan.zhihu.com/p/29925124)

    > 6 折叠操作
    > 
    > 之前的宽卷积是在输入矩阵d×s中的每一行内进行计算操作，其中d是word vector的维数，s是输入句子的词语数量。而Folding操作则是考虑相邻的两行之间的某种联系，方式也很简单，就是将两行的vector相加；该操作没有增加参数数量，但是提前（在最后的全连接层之前）考虑了特征矩阵中行与行之间的某种关联
    > 
    > ![](https://pic2.zhimg.com/80/v2-2917de002ed6a7d410de8e6ca46198fa_hd.jpg)
    > 
    > 传统CNN和加入folding后的词的表示。增强了表示能力：![\varphi(\sum_{i=1}^{3}\sum_{j=1}^{4}w_{ij}x_{ij})（左图） \\\varphi[\sum_{j=1}^{2}\varphi(\sum_{i=1}^{3}w_{ij}x_{ij})]+\varphi[\sum_{j=3}^{4}\varphi(\sum_{i=1}^{3}w_{ij}x_{ij})]（右图）](https://www.zhihu.com/equation?tex=%5Cvarphi%28%5Csum_%7Bi%3D1%7D%5E%7B3%7D%5Csum_%7Bj%3D1%7D%5E%7B4%7Dw_%7Bij%7Dx_%7Bij%7D%29%EF%BC%88%E5%B7%A6%E5%9B%BE%EF%BC%89+%5C%5C%5Cvarphi%5B%5Csum_%7Bj%3D1%7D%5E%7B2%7D%5Cvarphi%28%5Csum_%7Bi%3D1%7D%5E%7B3%7Dw_%7Bij%7Dx_%7Bij%7D%29%5D%2B%5Cvarphi%5B%5Csum_%7Bj%3D3%7D%5E%7B4%7D%5Cvarphi%28%5Csum_%7Bi%3D1%7D%5E%7B3%7Dw_%7Bij%7Dx_%7Bij%7D%29%5D%EF%BC%88%E5%8F%B3%E5%9B%BE%EF%BC%89)


- [自然语言处理中CNN模型几种常见的Max Pooling操作 - CSDN博客](https://blog.csdn.net/lujiandong1/article/details/52628953)

    > CNN是目前自然语言处理中和RNN并驾齐驱的两种最常见的深度学习模型。图1展示了在NLP任务中使用CNN模型的典型网络结构。一般而言，输入的字或者词用Word Embedding的方式表达，这样本来一维的文本信息输入就转换成了二维的输入结构，假设输入X包含m个字符，而每个字符的Word Embedding的长度为d，那么输入就是m*d的二维向量。
    > 
    > ![](https://img-blog.csdn.net/20160922223900354?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
    > 
    > 这里可以看出，因为NLP中的句子长度是不同的，所以CNN的输入矩阵大小是不确定的，这取决于m的大小是多少。卷积层本质上是个特征抽取层，可以设定超参数F来指定设立多少个特征抽取器（Filter），对于某个Filter来说，可以想象有一个k*d大小的移动窗口从输入矩阵的第一个字开始不断往后移动，其中k是Filter指定的窗口大小，d是Word Embedding长度。对于某个时刻的窗口，通过神经网络的非线性变换，将这个窗口内的输入值转换为某个特征值，随着窗口不断往后移动，这个Filter对应的特征值不断产生，形成这个Filter的特征向量。这就是卷积层抽取特征的过程。每个Filter都如此操作，形成了不同的特征抽取器。Pooling层则对Filter的特征进行降维操作，形成最终的特征。一般在Pooling层之后连接全联接层神经网络，形成最后的分类过程。
    > 
    > 可见，卷积和Pooling是CNN中最重要的两个步骤。下面我们重点介绍NLP中CNN模型常见的Pooling操作方法。
    > 
    > |CNN中的Max Pooling Over Time操作
    > 
    > MaxPooling Over Time是NLP中CNN模型中最常见的一种下采样操作。意思是对于某个Filter抽取到若干特征值，只取其中得分最大的那个值作为Pooling层保留值，其它特征值全部抛弃，值最大代表只保留这些特征中最强的，而抛弃其它弱的此类特征。
    > 
    > CNN中采用Max Pooling操作有几个好处：首先，这个操作可以保证特征的位置与旋转不变性，因为不论这个强特征在哪个位置出现，都会不考虑其出现位置而能把它提出来。对于图像处理来说这种位置与旋转不变性是很好的特性，但是对于NLP来说，这个特性其实并不一定是好事，因为在很多NLP的应用场合，特征的出现位置信息是很重要的，比如主语出现位置一般在句子头，宾语一般出现在句子尾等等，这些位置信息其实有时候对于分类任务来说还是很重要的，但是Max Pooling 基本把这些信息抛掉了。
    > 
    > 其次，MaxPooling能减少模型参数数量，有利于减少模型过拟合问题。因为经过Pooling操作后，往往把2D或者1D的数组转换为单一数值，这样对于后续的Convolution层或者全联接隐层来说无疑单个Filter的参数或者隐层神经元个数就减少了。
    > 
    >  再者，对于NLP任务来说，Max Pooling有个额外的好处；在此处，可以把变长的输入X整理成固定长度的输入。因为CNN最后往往会接全联接层，而其神经元个数是需要事先定好的，如果输入是不定长的那么很难设计网络结构。前文说过,CNN模型的输入X长度是不确定的，而通过Pooling操作，每个Filter固定取1个值，那么有多少个Filter，Pooling层就有多少个神经元，这样就可以把全联接层神经元个数固定住（如图2所示），这个优点也是非常重要的。
    > 
    > ![](https://img-blog.csdn.net/20160922223943493?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
    > 
    > 但是，CNN模型采取MaxPooling Over Time也有一些值得注意的缺点：首先就如上所述，特征的位置信息在这一步骤完全丢失。在卷积层其实是保留了特征的位置信息的，但是通过取唯一的最大值，现在在Pooling层只知道这个最大值是多少，但是其出现位置信息并没有保留；另外一个明显的缺点是：有时候有些强特征会出现多次，比如我们常见的TF.IDF公式，TF就是指某个特征出现的次数，出现次数越多说明这个特征越强，但是因为Max Pooling只保留一个最大值，所以即使某个特征出现多次，现在也只能看到一次，就是说同一特征的强度信息丢失了。这是Max Pooling Over Time典型的两个缺点。
    > 
    > 其实，我们常说"危机危机"，对这个词汇乐观的解读是"危险就是机遇"。同理，发现模型的缺点是个好事情，因为创新往往就是通过改进模型的缺点而引发出来的。那么怎么改进Pooling层的机制能够缓解上述问题呢？下面两个常见的改进Pooling机制就是干这个事情的。
    > 
    > |K-Max Pooling
    > 
    > K-MaxPooling的意思是：原先的Max Pooling Over Time从Convolution层一系列特征值中只取最强的那个值，那么我们思路可以扩展一下，K-Max Pooling可以取所有特征值中得分在Top --K的值，并保留这些特征值原始的先后顺序（图3是2-max Pooling的示意图），就是说通过多保留一些特征信息供后续阶段使用。
    > 
    > ![](https://img-blog.csdn.net/20160922224134153?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
    > 
    > 很明显，K-Max Pooling可以表达同一类特征出现多次的情形，即可以表达某类特征的强度；另外，因为这些Top K特征值的相对顺序得以保留，所以应该说其保留了部分位置信息，但是这种位置信息只是特征间的相对顺序，而非绝对位置信息。
    > 
    > |Chunk-Max Pooling
    > 
    > Chunk-MaxPooling的思想是：把某个Filter对应的Convolution层的所有特征向量进行分段，切割成若干段后，在每个分段里面各自取得一个最大特征值，比如将某个Filter的特征向量切成3个Chunk，那么就在每个Chunk里面取一个最大值，于是获得3个特征值。（如图4所示，不同颜色代表不同分段）
    > 
    > ![](https://img-blog.csdn.net/20160922224215779?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
    > 
    > 乍一看Chunk-Max Pooling思路类似于K-Max Pooling，因为它也是从Convolution层取出了K个特征值，但是两者的主要区别是：K-Max Pooling是一种全局取Top K特征的操作方式，而Chunk-Max Pooling则是先分段，在分段内包含特征数据里面取最大值，所以其实是一种局部Top K的特征抽取方式。
    > 
    > 至于这个Chunk怎么划分，可以有不同的做法，比如可以事先设定好段落个数，这是一种静态划分Chunk的思路；也可以根据输入的不同动态地划分Chunk间的边界位置，可以称之为动态Chunk-Max方法（这种称谓是我随手命名的，非正式称谓，请注意）。
    > 
    > Chunk-Max Pooling很明显也是保留了多个局部Max特征值的相对顺序信息，尽管并没有保留绝对位置信息，但是因为是先划分Chunk再分别取Max值的，所以保留了比较粗粒度的模糊的位置信息；当然，如果多次出现强特征，则也可以捕获特征强度。
    > 
    > Event Extraction via Dynamic Multi-Pooling Convolutional Neural Networks这篇论文提出的是一种ChunkPooling的变体，就是上面说的动态Chunk-Max Pooling的思路，实验证明性能有提升。Local Translation Prediction with Global Sentence Representation 这篇论文也用实验证明了静态Chunk-Max性能相对MaxPooling Over Time方法在机器翻译应用中对应用效果有提升。
    > 
    > 如果思考一下，就会发现，如果分类所需要的关键特征的位置信息很重要，那么类似Chunk-Max Pooling这种能够粗粒度保留位置信息的机制应该能够对分类性能有一定程度的提升作用；但是对于很多分类问题，估计Max-Pooling over time就足够了。
    > 
    > 比如我们拿情感分类来说，估计用Chunk-max策略应该有帮助，因为对于这种表达模式:
    > 
    > "Blablabla....表扬了你半天，BUT.....你本质上就是个渣"
    > 
    > 与这种表达模式
    > 
    > "虽然说你是个渣，但是.....Blablabla.....欧巴我还是觉得你最好，因为你最帅"
    > 
    > 明显位置信息对于判别整体情感倾向是有帮助作用的，所以引入位置信息应该有帮助。
    > 
    > 所以，你分析下你手头的问题，看看位置是不是重要特征，如果是，那么套用一下Chunk-Max策略，估计性能会有提升，比如上面举的情感分类问题估计效果会有提升。
    > 
    > **Pooling层的作用：**
    > 
    > **1\. 不变性，更关注是否存在某些特征而不是特征具体的位置。可以看作加了一个很强的先验，让学到的特征要能容忍一些的变化。**
    > 
    > **2\. 减小下一层输入大小，减小计算量和参数个数。\
    > 3\. 获得定长输出。（文本分类的时候输入是不定长的，可以通过池化获得定长输出）\
    > 4\. 防止过拟合或有可能会带来欠拟合。**
    > 

### 實作

- [FredericGodin/DynamicCNN: Dynamic Convolutional Neural Networks for Theano/Lasagne](https://github.com/FredericGodin/DynamicCNN)

- [CNN与句子分类之动态池化方法DCNN--TensorFlow实现篇 - CSDN博客](https://blog.csdn.net/liuchonge/article/details/67644305)

- [tensorflow - Variable size Convolutional Neural Network Input and Fixed output - Stack Overflow](https://stackoverflow.com/questions/38628014/variable-size-convolutional-neural-network-input-and-fixed-output)

    > I know it's an old thread, but for people who are looking for a solution. It has been implemented in tensorflow 1.4.0
    > 
    > tf.nn.max_pool() now takes 1d tensor as an input as opposed to a list of ints in the older versions. So you can use a placeholder as the argument of ksize.



## (CNN)在句子建模上的应用

- [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)

### Kim Y’s Paper

- [Implementing a CNN for Text Classification in TensorFlow – WildML](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)

- [dennybritz/cnn-text-classification-tf: Convolutional Neural Network for Text Classification in Tensorflow](https://github.com/dennybritz/cnn-text-classification-tf)

- [[Deep Learning] Convolution Neural Network on NLP](https://unilight.github.io/2017/07/04/Convolution-Neural-Network-on-NLP/)

- [Convolutional Methods for Text – Tal Perry – Medium](https://medium.com/@TalPerry/convolutional-methods-for-text-d5260fd5675f)

- [Understanding Convolutional Neural Networks for NLP – WildML](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)


- [How Quid uses deep learning with small data](https://quid.com/feed/how-quid-uses-deep-learning-with-small-data)

    - [[1408.5882v2] Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882v2)

    > ![](https://d15wj1jyee7mbq.cloudfront.net/cnnpic.png?mtime=20161117183048)
    > 
    > ![](https://d15wj1jyee7mbq.cloudfront.net/results.png?mtime=20161117180824)
    > 
    > we managed to achieve near the same level of performance with an approach based on deep learning as did we with an approach that relied on fancy manual feature engineering, even for very small data.
    > 
    > ---
    > 
    > A downfall of CNNs for text is that unlike for images, the input sequences are varying sizes (i.e., varying size sentences), which means most text inputs must be “padded” with some number of 0’s, so that all inputs are the same size. This means that a particularly long sentence will have many fewer zeros than most sentences, and, the model may act unpredictably in this context.
    > 
    > ---
    > 
    > The take-away here, though, is that you can do deep learning with a very low number of training examples and still get tangible benefits in model performance and representational efficiency over manual feature engineering.
    > 



### Hu’s Paper

- [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)


    - [[1503.03244] Convolutional Neural Network Architectures for Matching Natural Language Sentences](https://arxiv.org/abs/1503.03244)

    > #### 模型结构与原理
    > 
    > **1\. 基于CNN的句子建模**
    > 
    > 这篇论文主要针对的是**句子匹配(Sentence Matching)**的问题，但是基础问题仍然是句子建模。首先，文中提出了一种基于CNN的句子建模网络，如下图：
    > 
    > [![](http://i.imgur.com/kG7AbW3.png)](http://i.imgur.com/kG7AbW3.png)
    > 
    > 图中灰色的部分表示对于长度较短的句子，其后面不足的部分填充的全是0值(Zero Padding)。可以看出，模型解决不同长度句子输入的方法是规定一个最大的可输入句子长度，然后长度不够的部分进行0值的填充；图中的卷积计算和传统的CNN卷积计算无异，而池化则是使用Max-Pooling。
    > 
    > -   **卷积结构的分析**
    > 
    > 下图示意性地说明了卷积结构的作用，作者认为卷积的作用是**从句子中提取出局部的语义组合信息**，而多张`Feature Map`则是从多种角度进行提取，也就是**保证提取的语义组合的多样性**；而池化的作用是对多种语义组合进行选择，过滤掉一些置信度低的组合（可能这样的组合语义上并无意义）。
    > 
    > [![](http://i.imgur.com/yrFS2k1.png)](http://i.imgur.com/yrFS2k1.png)
    > 
    > **2\. 基于CNN的句子匹配模型**
    > 
    > 下面是基于之前的句子模型，建立的两种用于两个句子的匹配模型。
    > 
    > **2.1 结构I**
    > 
    > 模型结构如下图：
    > 
    > [![](http://i.imgur.com/xaP0KNV.png)](http://i.imgur.com/xaP0KNV.png)
    > 
    > 简单来说，首先分别单独地对两个句子进行建模（使用上文中的句子模型），从而得到两个相同且固定长度的向量，向量表示句子经过建模后抽象得来的特征信息；然后，将这两个向量作为一个多层感知机(MLP)的输入，最后计算匹配的分数。
    > 
    > 这个模型比较简单，但是有一个较大的缺点：两个句子在建模过程中是完全独立的，没有任何交互行为，一直到最后生成抽象的向量表示后才有交互行为（一起作为下一个模型的输入），这样做使得句子在抽象建模的过程中会丧失很多语义细节，同时过早地失去了句子间语义交互计算的机会。因此，推出了第二种模型结构。
    > 
    > **2.2 结构II**
    > 
    > 模型结构如下图：
    > 
    > [![](http://i.imgur.com/NWvAPVr.png)](http://i.imgur.com/NWvAPVr.png)
    > 
    > 图中可以看出，这种结构提前了两个句子间的交互行为。
    > 
    > -   **第一层卷积层**
    > 
    > 第一层中，首先取一个固定的卷积窗口k1
    > 
    > ，然后遍历 Sx 和 Sy
    > 
    > 中所有组合的二维矩阵进行卷积，每一个二维矩阵输出一个值（文中把这个称作为一维卷积，因为实际上是把组合中所有词语的vector排成一行进行的卷积计算），构成Layer-2。下面给出数学形式化表述：
    > 
    > [![](http://i.imgur.com/f3DqYsp.png)](http://i.imgur.com/f3DqYsp.png)
    > 
    > -   **第一层卷积层后的Max-Pooling层**
    > 
    > 从而得到Layer-2，然后进行2×2的Max-pooling：
    > 
    > [![](http://i.imgur.com/DaFv3ps.png)](http://i.imgur.com/DaFv3ps.png)
    > 
    > -   **后续的卷积层**
    > 
    > 后续的卷积层均是传统的二维卷积操作，形式化表述如下：
    > 
    > [![](http://i.imgur.com/Pr5Mm9n.png)](http://i.imgur.com/Pr5Mm9n.png)
    > 
    > -   **二维卷积结果后的Pooling层**
    > 
    > 与第一层卷积层后的简单Max-Pooling方式不同，后续的卷积层的Pooling是一种**动态Pooling方法**，这种方法来源于参考文献[1]。
    > 
    > -   **结构II的性质**
    > 
    > 1.  保留了词序信息；
    > 2.  更具一般性，实际上结构I是结构II的一种特殊情况（取消指定的权值参数）；
    > 
    > #### 实验部分
    > 
    > **1\. 模型训练及参数**
    > 
    > -   使用基于排序的自定义损失函数(Ranking-based Loss)
    > -   BP反向传播+随机梯度下降；
    > -   mini-batch为100-200,并行化；
    > -   为了防止过拟合，对于中型和大型数据集，会提前停止模型训练；而对于小型数据集，还会使用Dropout策略；
    > -   Word2Vector：50维；英文语料为Wikipedia(~1B words)，中文语料为微博数据(~300M words)；
    > -   使用ReLu函数作为激活函数；
    > -   卷积窗口为3-word window；
    > -   使用Fine tuning；
    > 
    > **2\. 实验结果**
    > 
    > 一共做了三个实验，分别是(1)句子自动填充任务，(2)推文与评论的匹配，以及(3)同义句识别；结果如下面的图示：
    > 
    > [![](http://i.imgur.com/wLIUAHW.png)](http://i.imgur.com/wLIUAHW.png)
    > 
    > [![](http://i.imgur.com/fO0Xhnj.png)](http://i.imgur.com/fO0Xhnj.png)
    > 
    > [![](http://i.imgur.com/qRfsoB0.png)](http://i.imgur.com/qRfsoB0.png)
    > 
    > 其实结构I和结构II的结果相差不大，结构II稍好一些；而相比于其他的模型而言，结构I和结构II的优势还是较大的。
    > 

### Yin’s Paper

- [卷积神经网络(CNN)在句子建模上的应用 | Jey Zhang](http://www.jeyzhang.com/cnn-apply-on-modelling-sentence.html)


# Time Convolution Network(TCN) based

## An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling

- [[1803.01271] An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling](https://arxiv.org/abs/1803.01271)



## TCN 實作

- [机器之心GitHub项目：从循环到卷积，探索序列建模的奥秘 | 机器之心](https://www.jiqizhixin.com/articles/2018-04-12-3)

    >机器之心项目地址：<https://github.com/jiqizhixin/ML-Tutorial-Experiment>

    > **卷积与时间卷积网络**
    > 
    > 卷积神经网络，即至少在一层上使用卷积运算来代替一般的矩阵乘法运算的神经网络，一般我们认为卷积网络擅长处理「网格结构的数据」，例如图像就是二维的像素网格。但其实时序数据同样可以认为是在时间轴上有规律地采样而形成的一维网格，根据 Shaojie Bai 等人的实验结果，一般的时间卷积网络甚至比 LSTM 或 GRU 有更好的性能。
    > 
    > 卷积的基本概念其实已经有非常多的入门教程，因此这里只简要说明一般的卷积运算与一维卷积。在卷积运算中，卷积核会在输入图像上滑动以计算出对应的特征图。卷积层试图将神经网络中的每一小块进行更加深入的分析，从而得出抽象程度更高的特征。一般来说通过卷积层处理的神经元结点矩阵会变得更深，即神经元的组织在第三个维度上会增加。
    > 
    > 一般来说，卷积运算主要通过稀疏权重、参数共享和平移等变性等特性加强了机器学习系统。稀疏权重即卷积核大小会远小于输入图像的大小，这允许卷积网络存储更少的参数和使用更少的计算而实现高效的性能。参数共享也是非常优秀的属性，因为我们假设数据拥有局部结构，那么只需要在小范围神经元中使用不同的参数，而大范围内的神经元可共享参数。最后的平移不变性也建立在参数共享的基础上，它可以直观理解为若移动输入中对象，那么输出中的表示也会移动同样的量。
    > 
    > 以下展示了简单的一维卷积，适用于序列建模的卷积网络一般就是采用的这种架构。从一维卷积的连接方式可以清晰地了解权重共享的方式，图中每个卷积层使用了一个大小为 3 的卷积核，即 k1、k2 和 k3 和 f1、f2 和 f3。下层每一个神经元只会和上层神经元部分连接，例如 h_3 只能由下层的局部神经元 x_2、x_3 和 x_4 计算得出。
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/32fbbfc9-c43d-4303-943b-e208d6384bae/1523507158587.jpg)
    > 
    > 在序列建模任务中，最下层的 x 可视为句子等输入序列，最上层的 g 可视为输出序列，中间的 h 即隐藏层。当然，这种一维卷积并没有限制为只能查看当前时间步以及之前信息的因果卷积。越上层的神经元拥有越广感受野，因此高层的卷积单元将有能力构建长期依赖关系。如上所示，g_3 可以观察到输入序列的所有信息。
    > 
    > 一维卷积从直观上确实能实现序列建模，但我们经常使用的还是循环网络，尤其是 LSTM 或 GRU。不过在论文 An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling 中，作者表明他们所提出的时间卷积网络可作为一般的序列建模框架，且拥有非常好的效果。本文后面将介绍这种网络，并在 PTB 数据集上分别使用 RNN 与 TCN 构建语言模型。
    > 
    > 时间卷积也是从一般的卷积运算中延伸得出，下面简要介绍了卷积序列预测的一般架构。我们的目标是将卷积网络的最佳实践经验精炼为一个简单的架构，它能便捷地处理时序建模问题。这种时间卷积网络（TCN）的显著的特点有如下几点，首先架构中的卷积存在因果关系，这意味着从未来到过去不会存在信息「泄漏」。其次卷积架构可以将任意长度的序列映射到固定长度的序列。除此之外，TCN 还强调利用残差模块和空洞卷积来构建长期依赖关系。
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/97145c1c-946f-46cb-952e-4978bef28f96/1523507158659.jpg)
    > 
    > *TCN 论文图 1：TCN 架构的组成元素。（a）为空洞系数 d=1, 2, 4、卷积核大小 k=3 的空洞因果卷积，感受野能覆盖输入序列中的所有值。（b）为 TCN 残差块，当残差输入和输出有不同的维度，我们会添加一个 1x1 的卷积。（c）为 TCN 中的残差连接示例，其中蓝线为残差函数中的卷积核，绿线为恒等映射。*
    > 
    > **全卷积与因果卷积**
    > 
    > 为了使用卷积运算处理时序数据，TCN 结合了一维全卷积与因果卷积两种结构。通过使用一维全卷积网络，TCN 可以产生和输入序列等长的输出序列，且每一个隐藏层通过使用 Padding 可以保持和输出层等长。而通过使用因果卷积，TCN 可以保证前面时间步的预测不会使用未来的信息，因为时间步 t 的输出只会根据 t-1 及之前时间步上的卷积运算得出。因此总的来说时间卷积网络简单地组合一维全卷积和因果卷积而转化为适合序列数据的模型。
    > 
    > 全卷积网络最开始在论文 Fully Convolutional Networks for Semantic Segmentation（2015）中提出，它将传统卷积神经网络最后几个全连接层替换为卷积层。一般卷积网络会使用全连接层将特征图映射为固定长度的向量，且每一个元素代表一个类别。这种结构相当于将卷积抽取的高级特征实现线性组合而最终预测类别，但它的局限性体现在只能对整张图像或整段序列做分类处理。
    > 
    > 因此引入全卷积的意义在于它能实现密集型的预测，即在二维卷积下对图像实现像素级的分类，在一维卷积下对序列实现元素级的预测。此外，由于低层的卷积运算感受野较小，对于特征的位置变化不敏感，而高层的卷积网络感受野非常大，对特征的变化也非常敏感。因此 TCN 用一维卷积替代最后几个全连接层有助于感受整个输入序列的信息，这对于构建长期记忆非常有帮助。以下展示了带全连接层的卷积网络和全卷积网络的区别：
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/247a386e-1c50-4547-9953-dd6a9de40fbf/1523507158749.jpg)
    > 
    > 如上所示，全卷积网络将预测类别概率（上）转化为像素级的预测（下）。
    > 
    > 因果卷积首次是在 WaveNet（van den Oord et al., 2016）论文中提出，从直观上来说，它类似于将卷积运算「劈」去一半，令其只能对过去时间步的输入进行运算。对于 TCN 所使用的一维卷积来说，因果卷积可以简单将一般卷积的输出移动几个时间步而实现。在训练过程中，所有过去时间步的卷积预测可以并行化，因为它们的输入和标注真值都是已知的，所以这相对于循环网络在训练上有非常大的优势。因果卷积的结构将结合空洞卷积一起展示。
    > 
    > **空洞卷积（Dilated Convolutions）**
    > 
    > 因果卷积其实还有一个问题，它需要非常多的层级数或较大的卷积核来扩宽感受野，而较大的感受野正式构建长期记忆所必须的。因此，如果我们不希望通过前面两种会增加计算量的方法扩展感受野，那我们就需要使用空洞卷积（或称扩张卷积）增加数个量级的感受野。
    > 
    > 空洞卷积最大的特性就是扩张感受野，它不是在像素间插入空白像素，而是略过一些已有的像素。当然，我们也可以理解为保持输入不变，并向卷积核中添加一些值为零的权重，从而在计算量基本不变的情况下增加网络观察到的图像范围或序列长度。此外，如果我们将一般卷积运算的步幅增大，那同样也能起到增加感受野的效果，但卷积步幅大于 1 就会起到降采样的效果，输出的序列长度会减小。如下展示了因果卷积结合空洞卷积的效果：
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/5bee6ea9-fb47-4b91-8d39-2b5eaf8c264f/1523507158835.jpg)
    > 
    > 如上所示，一维卷积的卷积核大小为 2，第一层使用的 dilation 为 1，即常规的卷积运算。而后面层级的空洞大小依次加大，常规卷积只能从右到左观察到 5 个输入数据，而空洞卷积可以观察到所有 16 个输入数据。
    > 
    > 形式上，对于 1 维的输入序列 x ∈ R^n 和卷积核 f : {0, . . . , k - 1} → R，空洞卷积运算 F 可以定义为：
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/d1901808-140f-4bcf-aa8f-2c51864dce1c/1523507158879.jpg)
    > 
    > 其中 d 为扩张系数、k 为卷积核大小，s - d - i 计算了采用上层哪一个单元。扩张系数控制了每两个卷积核间会插入多少零值，当 d=1 时，空洞卷积就会退化为一般的卷积运算。使用较大的扩张系数允许输出端的神经元表征更大范围的输入序列，因此能有效扩张感受野。
    > 
    > 一般在使用空洞卷积时，我们将随着网络深度 i 的增加而指数级地增大 d，即 d=O(2^i)。这确保了卷积核在有效历史信息中覆盖了所有的输入，同样也确保了使用深度网络能产生极其长的有效历史信息。
    > 
    > **高速公路网络与残差连接**
    > 
    > 残差网络在计算机视觉中有非常强大的表达能力，它因为解决了深层网络的训练问题而可以大大增加网络的层数。但要理解残差网络与残差连接，我们需要先理解高速公路网络（Highway Networks）。
    > 
    > 高速公路网络受到 LSTM 的启发，它通过门控令信息在多个神经网络层级中可以高效流动，从而能使用传统基于梯度的方法快速训练深度网络。一般而言，若每一层的卷积运算可以用隐藏函数 H 表示，那么给定该层的输入 x 与权重矩阵 W_H，输出可以表示为 y = H(x, W_H)。在高速公路网络中，传入后一层的信息不仅是当前层的计算结果，同时还包含了前面层级的计算结果。高速公路网络会使用门控机制控制每一层向后传递的信息：
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/1f4fddc2-be2f-4751-94a8-3e350ee5841f/1523507158912.jpg)
    > 
    > 其中 H(x, W_H) 表示当前层传统卷积运算的结果，而非线性函数 T(x, W_T) 表示转换门，它控制了当前层的卷积运算结果对当前层输出的贡献大小。C(x,W_C) 表示携带门，它控制了当前层的输入信息最终不经过计算直接传到输出端的大小。高速公路网络一般采用 1-T(x, W_T) 代替 C(x,W_C) 而减少门控的数量，且门控通过 Sigmoid 函数实现。
    > 
    > 由于增加了复原输入信息的可能性，模型会更加灵活，且当 T=1 而 C=0 时，高速公路网络就退化为了常规的卷积网络。而残差网络与残差连接正是这种架构的特例，如果我们令上式的 T 和 C 都等于 1，那么它就代表了一个残差模块，即 y = H(x, W_H) + x。因为我们要学的是卷积核的权重 W_H，因此经过简单的变形可得 H(x, W_H) = y-x。由此可知，我们实际需要学习的函数 H 是由残差项 y-x 而得出，这也就是我们称之为残差网络的原因。
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/966258c7-a98d-4ae1-a436-d8f4b0477f3d/1523507158958.jpg)
    > 
    > 上图为原论文中的残差块结构，其中 F(x) 和前面 H(x, W_H) 表示相同的过程。残差块的输出结合了输入信息与内部卷积运算的输出信息，这种残差连接或恒等映射表示深层模型至少不能低于浅层网络的准确度。
    > 
    > 原论文展示了实践中的两种残差块，下图左边是一种采用堆叠两个 3×3 的卷积运算方法，它在深层网络中表现并不是很好。右边为一种瓶颈残差网络，第一个 1×1 的卷积可以视为对输入进行降维处理，因此中间的 3×3 卷积层将有更少的计算量，而后面的 1×1 卷积可以升维或恢复所有的信息。瓶颈残差网络有更高的计算效率，因此在非常深的网络中能大量减小计算量。
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/f904049b-eb46-4ca3-88bd-956d2e80a9f2/1523507158999.jpg)
    > 
    > 由于 TCN 的感受野取决于网络深度 n、卷积核大小 k 和空洞卷积中的扩张系数 d，因此更深的 TCN 有更强的稳定性要求。例如在预测依赖于 2^12 历史时间步和高维输入空间下，网络需要达到 12 层。且每一层需要多个卷积核执行特征抽取，在 TCN 论文作者设计的模型中，它使用了残差模块来加深卷积网络。
    > 
    > 在 TCN 的残差模块内，有两层空洞卷积和 ReLU 非线性函数，且卷积核的权重都经过了权重归一化。此外，TCN 在残差模块内的每个空洞卷积后都添加了 Dropout 以实现正则化。
    > 
    > 然而在标准的 ResNet 中，输入可以直接加上残差函数的输出向量。而在 TCN 中，输入与输出有不同的维度，因此我们需要使用额外的 1×1 卷积来确保 F(x) 与 x 间对应像素相加有相同的维度。
    > 
    > 然而，在标准 ResNet 中，输入直接添加到残余函数的输出中，在 TCN 中（通常是 ConvNets），输入和输出可以有不同的宽度。为了解决输入输出宽度的差异，我们使用额外的 1x1 卷积来确保元素相加⊕接收相同形状的张量。
    > 
    > 最后，时间卷积网络即结合了一维因果卷积和空洞卷积作为标准卷积层，而每两个这样的卷积层与恒等映射可以封装为一个残差模块。这样由残差模块堆叠起一个深度网络，并在最后几层使用卷积层代替全连接层而构建完整的全卷积网络。
    > 
    > **实现**
    > 
    > 这一部分简单地实现了 LSTM 网络与 TCN 模型，我们在 PTB 数据集上使用这两种结构构建了语言模型。本文在这里只会简要地分析这两个语言模型的核心代码，完整的实现可查看机器之心的 GitHub 项目地址。
    > 
    > 基于 LSTM 的语言模型使用 TensorFlow 实现，它使用两层 LSTM 网络，且每层有 200 个隐藏单元。我们在训练中截断的输入序列长度为 32，且使用 Dropout 和梯度截断等方法控制模型的过拟合与梯度爆炸等问题。我们在简单地训练 3 个 Epoch 后，测试复杂度（Perplexity）降低到了 179。
    > 
    > 基于 TCN 的语言模型使用 PyTorch 实现，且模型修改自原论文作者 Shaojie Bai 等人的 GitHub 实现。该模型使用论文中介绍的因果卷积与空洞卷积，并采用残差连接的结构完成构建。
    > 
    > 这两个模型实现的都是语言模型，即给定一句话的前面词预测下一个词，因此也可以视为计算语句的出现概率。衡量一个语言模型好坏的方法一般可以用复杂度（Perplexity），它刻画了估计下一句话出现的概率。复杂度的概念其实就是平均分支系数，即模型预测下一个词是的平均可选择数量。我们实现的两个模型并不能成为严格的性能对比，只能帮助读者了解它们的实现过程。但至少，我们可以发现 TCN 确实有能匹敌 LSTM 的性能。
    > 
    > **LSTM 语言建模**
    > 
    > 使用 LSTM 的语言建模非常简单，现在也有非常多的教程，因此我们也不重点介绍它的实现。以下是使用 LSTM 构建语言模型的部分代码，它定义了整个 LSTM 网络的架构。此外，该模型的数据读取、超参数、验证与测试过程请查看 GitHub，我们也给出了必要的代码注释。
    > 
    > ```python
    > # 通过ptbmodel 的类描述模型
    > class PTBModel(object):
    >     def __init__(self, is_training, batch_size, num_steps):
    >         # 记录使用的Batch大小和截断长度
    >         self.batch_size = batch_size
    >         self.num_steps = num_steps
    > 
    >         # 定义输入层，维度为批量大小×截断长度
    >         self.input_data = tf.placeholder(tf.int32, [batch_size, num_steps])
    >         # 定义预期输出
    >         self.targets = tf.placeholder(tf.int32, [batch_size, num_steps])
    > 
    >         # 定义使用LSTM结构为循环体，带Dropout的深度RNN
    >         lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_size)
    >         if is_training:
    >             lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)
    >         cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers)
    > 
    >         # 初始化状态为0
    >         self.initial_state = cell.zero_state(batch_size, tf.float32)
    > 
    >         # 将单词ID转换为单词向量，embedding的维度为vocab_size*hidden_size
    >         embedding = tf.get_variable('embedding', [vocab_size, hidden_size])
    >         # 将一个批量内的单词ID转化为词向量，转化后的输入维度为批量大小×截断长度×隐藏单元数
    >         inputs = tf.nn.embedding_lookup(embedding, self.input_data)
    > 
    >         # 只在训练时使用Dropout
    >         if is_training: inputs = tf.nn.dropout(inputs, keep_prob)
    > 
    >         # 定义输出列表，这里先将不同时刻LSTM的输出收集起来，再通过全连接层得到最终输出
    >         outputs = []
    >         # state 储存不同批量中LSTM的状态，初始为0
    >         state = self.initial_state
    >         with tf.variable_scope('RNN'):
    >             for time_step in range(num_steps):
    >                 if time_step > 0: tf.get_variable_scope().reuse_variables()
    >                 # 从输入数据获取当前时间步的输入与前一时间步的状态，并传入LSTM结构
    >                 cell_output, state = cell(inputs[:, time_step, :], state)
    >                 # 将当前输出加入输出队列
    >                 outputs.append(cell_output)
    > 
    >         # 将输出队列展开成[batch,hidden*num_step]的形状，再reshape为[batch*num_step, hidden]
    >         output = tf.reshape(tf.concat(outputs, 1), [-1, hidden_size])
    > 
    >         # 将LSTM的输出传入全连接层以生成最后的预测结果。最后结果在每时刻上都是长度为vocab_size的张量
    >         # 且经过softmax层后表示下一个位置不同词的概率
    >         weight = tf.get_variable('weight', [hidden_size, vocab_size])
    >         bias = tf.get_variable('bias', [vocab_size])
    >         logits = tf.matmul(output, weight) + bias
    > 
    >         # 定义交叉熵损失函数，一个序列的交叉熵之和
    >         loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(
    >             [logits],  # 预测的结果
    >             [tf.reshape(self.targets, [-1])],  # 期望正确的结果，这里将[batch_size, num_steps]压缩为一维张量
    >             [tf.ones([batch_size * num_steps], dtype=tf.float32)])  # 损失的权重，所有为1表明不同批量和时刻的重要程度一样
    > 
    >         # 计算每个批量的平均损失
    >         self.cost = tf.reduce_sum(loss) / batch_size
    >         self.final_state = state
    > 
    >         # 只在训练模型时定义反向传播操作
    >         if not is_training: return
    >         trainable_variable = tf.trainable_variables()
    > 
    >         # 控制梯度爆炸问题
    >         grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, trainable_variable), max_grad_norm)
    >         optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    >         # 定义训练步骤
    >         self.train_op = optimizer.apply_gradients(zip(grads, trainable_variable))
    > 
    > ```
    > 
    > 如上所示，我们首先需要定义输入与输出的维度占位符，其中 num_steps 表示截断的输入序列长度，也就是输入句子的长度。然后定义单个层级的 LSTM 网络，这里定义的隐藏单元数是 200。此外，定义的 LSTM 循环体在训练过程中还要加一个 Dropout 层以实现正则化和类似集成方法的效果。将这样的 LSTM 层级堆叠在一起就构建成了多层循环神经网络，这也是非常简单的。
    > 
    > 定义输入后，按时间步来读取输入序列中的中的词向量，并将前一时间步的隐藏状态同时传入 LSTM 单元，以得到当前时间步的预测和隐藏状态。最后将循环体的输出结果传入一般的全连接层就能完成最终的词预测，这里会常规地使用 Softmax 函数归一化预测不同词的概率。当然，后面还需要定义损失函数和梯度截断等方法，这里需要将输入语句所有词的误差都累积起来，且计算一个批量内（多条语句）的平均损失作为最终的损失。
    > 
    > **TCN 语言建模**
    > 
    > 这一部分的实现主要采用 TCN 原论文的官方实现，我们修改了一些内容以在 Notebook 上直接运行。本文主要介绍了构建 TCN 整体架构的代码和整体模型的结构，更多如评估过和训练等过程请查看机器之心的 GitHub 项目。
    > 
    > -   机器之心项目地址：https://github.com/jiqizhixin/ML-Tutorial-Experiment
    > -   原论文实现地址：https://github.com/locuslab/TCN
    > 
    > 原论文 tcn.py 文件中实现了 TCN 的残差模块与整体网络架构，以下将依次解释该网络的各个模块。
    > 
    > ```python
    > import torch
    > import torch.nn as nn
    > from torch.nn.utils import weight_norm
    > 
    > #定义实现因果卷积的类（继承自类nn.Module），其中super(Chomp1d, self).__init__()表示对继承自父类的属性进行初始化。
    > class Chomp1d(nn.Module):
    >     def __init__(self, chomp_size):
    >         super(Chomp1d, self).__init__()
    >         self.chomp_size = chomp_size
    > 
    >     # 通过增加Padding的方式并对卷积后的张量做切片而实现因果卷积
    >     # tensor.contiguous()会返回有连续内存的相同张量
    >     def forward(self, x):
    >         return x[:, :, :-self.chomp_size].contiguous()
    > 
    > ```
    > 
    > 如上所示，首先类 Chomp1d 定义了通过 Padding 实现因果卷积的方法。其中 chomp_size 等于 padding=(kernel_size-1) * dilation_size，x 为一般一维空洞卷积后的结果。张量 x 的第一维是批量大小，第二维是通道数量而第三维就是序列长度。如果我们删除卷积后的倒数 padding 个激活值，就相当于将卷积输出向左移动 padding 个位置而实现因果卷积。
    > 
    > 以下实现了 TCN 中的残差模块，它由两个空洞卷积和恒等映射（或一个逐元素的卷积）组成，并使用 torch.nn.Sequential 简单地将这些卷积层和 Dropout 等运算结合在一起。
    > 
    > 首先 TemporalBlock 类会定义第一个空洞卷积层，dilation 控制了扩展系数，即在卷积核权重值之间需要添加多少零。卷积后的结果调用上面定义的 Chomp1d 类实现因果卷积。然后再依次添加 ReLU 非线性激活函数和训练中的 dropout 正则化方法，得出激活值后可作为输入传入相同结构的第二个卷积层。
    > 
    > 因为残差模块可以表示为 y = H(x, W_H) + x，所以将这两个卷积结果再加上恒等映射 f(x)=x 就能完成残差模块。
    > 
    > ```python
    > # 定义残差块，即两个一维卷积与恒等映射
    > class TemporalBlock(nn.Module):
    >     def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):
    >         super(TemporalBlock, self).__init__()
    > 
    >         #定义第一个空洞卷积层
    >         self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,
    >                                            stride=stride, padding=padding, dilation=dilation))
    >         # 根据第一个卷积层的输出与padding大小实现因果卷积
    >         self.chomp1 = Chomp1d(padding)
    >         #添加激活函数与dropout正则化方法完成第一个卷积
    >         self.relu1 = nn.ReLU()
    >         self.dropout1 = nn.Dropout2d(dropout)
    > 
    >         #堆叠同样结构的第二个卷积层
    >         self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,
    >                                            stride=stride, padding=padding, dilation=dilation))
    >         self.chomp2 = Chomp1d(padding)
    >         self.relu2 = nn.ReLU()
    >         self.dropout2 = nn.Dropout2d(dropout)
    > 
    >         # 将卷积模块的所有组建通过Sequential方法依次堆叠在一起
    >         self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,
    >                                  self.conv2, self.chomp2, self.relu2, self.dropout2)
    > 
    >         # padding保证了输入序列与输出序列的长度相等，但卷积前的通道数与卷积后的通道数不一定一样。
    >         # 如果通道数不一样，那么需要对输入x做一个逐元素的一维卷积以使得它的纬度与前面两个卷积相等。
    >         self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None
    >         self.relu = nn.ReLU()
    >         self.init_weights()
    > 
    >     # 初始化为从均值为0，标准差为0.01的正态分布中采样的随机值
    >     def init_weights(self):
    >         self.conv1.weight.data.normal_(0, 0.01)
    >         self.conv2.weight.data.normal_(0, 0.01)
    >         if self.downsample is not None:
    >             self.downsample.weight.data.normal_(0, 0.01)
    > 
    >     # 结合卷积与输入的恒等映射（或输入的逐元素卷积），并投入ReLU 激活函数完成残差模块
    >     def forward(self, x):
    >         out = self.net(x)
    >         res = x if self.downsample is None else self.downsample(x)
    >         return self.relu(out + res)
    > 
    > ```
    > 
    > 但 TCN 的残差模块还有一个需要注意的地方，即它有可能会对 x 执行一个逐元素的卷积而不是直接添加 x。这主要是因为卷积结果的通道数与输入 x 的通道数可能不同，那么我们就需要使用 n_outputs 个卷积核将输入采样至与卷积输出相同的通道数。最后，定义前向传播以结合两部分输出而完成残差模块的构建。
    > 
    > 下面定义了 TCN 的整体架构，简单而言即根据层级数将残差模块叠加起来。其中 num_channels 储存了所有层级（残差模块）的通道数，它的长度即表示一共有多少个残差模块。这里每一个空洞卷积层的扩张系数随着层级数成指数增加，这确保了卷积核在有效历史信息中覆盖了所有的输入，同样也确保了使用深度网络能产生极其长的有效历史信息。
    > 
    > 在从 num_channels 列表中抽取当前残差模块的输入与输出通道数后，就能定义这一层的残差模块。将不同层级的残差模块使用 Sequential 堆叠起来就能构建整个网络架构。
    > 
    > ```python
    > # 定义时间卷积网络的架构
    > class TemporalConvNet(nn.Module):
    >     def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):
    >         super(TemporalConvNet, self).__init__()
    >         layers = []
    > 
    >         # num_channels为各层卷积运算的输出通道数或卷积核数量，它的长度即需要执行的卷积层数量
    >         num_levels = len(num_channels)
    >         # 空洞卷积的扩张系数若随着网络层级的增加而成指数级增加，则可以增大感受野并不丢弃任何输入序列的元素
    >         # dilation_size根据层级数成指数增加，并从num_channels中抽取每一个残差模块的输入通道数与输出通道数
    >         for i in range(num_levels):
    >             dilation_size = 2 ** i
    >             in_channels = num_inputs if i == 0 else num_channels[i-1]
    >             out_channels = num_channels[i]
    >             layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,
    >                                      padding=(kernel_size-1) * dilation_size, dropout=dropout)]
    >         # 将所有残差模块堆叠起来组成一个深度卷积网络
    >         self.network = nn.Sequential(*layers)
    > 
    >     def forward(self, x):
    >         return self.network(x)
    > 
    > ```
    > 
    > 以上的三个类都在定义在 tcn.py 文件中，它适用于所有的测试任务。在语言建模中，还有另一部分定义模型过程的类比较重要，它会将输入序列馈送到网络以完成整个推断过程。
    > 
    > ```python
    > class TCN(nn.Module):
    > 
    >     def __init__(self, input_size, output_size, num_channels,
    >                  kernel_size=2, dropout=0.3, emb_dropout=0.1, tied_weights=False):
    >         super(TCN, self).__init__()
    > 
    >         # 将一个批量的输入数据（one-hot encoding）送入编码器中成为一个批量的词嵌入向量
    >         # 其中output_size为词汇量，input_size为一个词向量的长度
    >         self.encoder = nn.Embedding(output_size, input_size)
    > 
    >         # 构建网络
    >         self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)
    > 
    >         # 定义最后线性变换的纬度，即最后一个卷积层的通道数（类似2D卷积中的特征图数）到所有词汇的映射
    >         self.decoder = nn.Linear(num_channels[-1], output_size)
    > 
    >         # 是否共享编码器与解码器的权重，默认是共享。共享的话需要保持隐藏单元数等于词嵌入长度，这样预测的向量才可以视为词嵌入向量
    >         if tied_weights:
    >             if num_channels[-1] != input_size:
    >                 raise ValueError('When using the tied flag, nhid must be equal to emsize')
    >             self.decoder.weight = self.encoder.weight
    >             print("Weight tied")
    > 
    >         # 对输入词嵌入执行Dropout 表示随机从句子中舍弃词，迫使模型不依赖于单个词完成任务
    >         self.drop = nn.Dropout(emb_dropout)
    >         self.emb_dropout = emb_dropout
    >         self.init_weights()
    > 
    >     def init_weights(self):
    >         self.encoder.weight.data.normal_(0, 0.01)
    >         self.decoder.bias.data.fill_(0)
    >         self.decoder.weight.data.normal_(0, 0.01)
    > 
    >     #先编码，训练中再随机丢弃词，输入到网络实现推断，最后将推断结果解码为词
    >     def forward(self, input):
    >         """Input ought to have dimension (N, C_in, L_in), where L_in is the seq_len; here the input is (N, L, C)"""
    >         emb = self.drop(self.encoder(input))
    >         y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)
    >         y = self.decoder(y)
    >         return y.contiguous()
    > 
    > ```
    > 
    > 如上所示，模型的主要过程即先将输入的向量编码为词嵌入向量，再作为输入投入到时间卷积网络中。该网络的输出为 y，它的第一个纬度表示批量大小，第二个纬度是通道数量，而第三个纬度代表序列长度。全卷积主要体现在解码的过程，我们不需要再向量化卷积结果而进行仿射变换，而是直接将不同的序列通道映射到全部的词汇中以确定预测的词。
    > 
    > 如果读者安装了 PyTorch，那么 TCN 的测试就可以使用 Git 复制原论文官方实践，然后转到 word_cnn 目录下就能直接在 PyCharm 等 IDE 中运行 word_cnn_test.py 文件，当然我们也可以使用命令行运行。此外，为了让更多的入门读者可以运行该模型，我们会修正这个实现语言建模的 TCN，并放到谷歌 Colaboratory 中，这样读者就能使用免费的 GPU 资源进行训练。这一部分还在修正中，稍后我们会上传至机器之心 GitHub 项目。
    > 
    > 最后，Shaojie Bai 等研究者还在很多序列建模任务上测试了 TCN 与传统循环网络的性能：
    > 
    > ![](https://image.jiqizhixin.com/uploads/editor/8b1f6037-1708-4b0b-907b-2046ffd165b0/1523507159070.jpg)
    > 
    > 上表展示了 TCN 和循环架构在合成压力测试、复调音乐建模、字符级语言建模和单词级语言建模任务上的评估结果。一般 TCN 架构在全部任务和数据集上都比经典循环网络性能优秀，上标 h 代表数值越高越好，l 代表数值越低越好。
    > 
    > 从经典的隐马尔科夫模型到现在基于循环神经网络与卷积神经网络的深度方法，序列建模已经走过了很长一段旅程，它对于自然语言处理与语音识别等都非常重要。本文只是简单的介绍了基础的序列建模深度方法，它还有很多地方需要探索与讨论，那么让我们真真切切地去了解它吧。
    > 
    > **参考资料：**
    > 
    > -   《Deep Learning》，Ian Goodfellow，2016
    > 
    > -   An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling：https://arxiv.org/abs/1803.01271
    > 
    > -   TCN 实现地址：https://github.com/locuslab/TCN
    > 
    > -   Deep Residual Learning for Image Recognition：https://arxiv.org/abs/1512.03385
    > 
    > -   Fully Convolutional Networks for Semantic Segmentation：https://arxiv.org/pdf/1605.06211.pdf
    > 
    > -   WAVENET: A GENERATIVE MODEL FOR RAW AUDIO：https://arxiv.org/pdf/1609.03499.pdf
    > 


- [每天三分钟之Pytorch编程-5：RNN的新对手TCN(1)](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUzOTkyMDU5Mg%3D%3D%26mid%3D2247483805%26idx%3D1%26sn%3D5f026d7b935f8d8f4d6bfca694df4c92%26chksm%3Dfac05022cdb7d934b71e3ff83594d28d2c9d6bb2e11569aa8bb1feda1b59e869759d6defd663%26scene%3D21%23wechat_redirect)

    > TCN是指时间卷积网络，一种新型的可以用来解决时间序列预测的算法。在这一两年中已有多篇论文提出，但是普遍认为下篇论文是TCN的开端。
    > 
    > 论文名称：
    > 
    > An Empirical Evaluation of Generic Convolutional and Recurrent Networks  for Sequence Modeling
    > 
    > 作者：Shaojie Bai 1 J. Zico Kolter 2 Vladlen Koltun 3
    > 
    > 自从TCN提出后引起了巨大反响，有人认为
    > 
    > 时间卷积网络（TCN）将取代RNN成为NLP或者时序预测领域的王者。
    > 
    > William Vorhies给出的原因如下：
    > 
    > RNN耗时太长，由于网络一次只读取、解析输入文本中的一个单词（或字符），深度神经网络必须等前一个单词处理完，才能进行下一个单词的处理。这意味着 RNN 不能像 CNN 那样进行大规模并行处理。
    > 
    > 并且TCN的实际结果也要优于RNN算法。
    > 
    > 所以本教程未来几次更新将集中介绍TCN的算法含义与代码解读。
    > 
    > 
    > **什么是TCN?**
    > 
    > TCN中涉及到了最简单的CNN和RNN，此处暂不赘述。还涉及到了一维卷积，扩张卷积，因果卷积，残差卷积的跳层连接等其他知识点。为了能够更准确的了解，我们将结合论文逐步介绍每个部分。
    > 
    > 一维卷积
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1icaKiaYRs2eNIaLwJsWzKL6nms6OI7AiagU4XsFBl1rBOu8x7YlJZ1WsRiaiapovzys6o1hKqG0CWovOg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 以下图为例：图中的输入的数据维度为8，过滤器的维度为5。那么卷积后输出的数据维度为8-5+1=4
    > 
    > 如果过滤器数量为1，输入数据的channel数量变为，即输入数据维度为8×32。这里channel的概念相当于自然语言处理中的embedding，而该输入数据代表8个单词，其中每个单词的词向量维度大小为32。在这种情况下，过滤器的维度由5变为5×32，最终输出的数据维度仍为4。
    > 
    > 如果过滤器数量为n，那么输出的数据维度就变为4×n。
    > 
    > 其实可以看出模型基本上与二维卷积相同，非常容易理解。
    > 
    > 扩张卷积
    > 
    > 扩张卷积与普通的卷积相比，除了卷积核的大小以外，还有一个扩张率(dilation rate)参数，主要用来表示扩张的大小。
    > 
    > 扩张卷积与普通卷积的相同点在于，卷积核的大小是一样的，神经网络中的参数数量不变。
    > 
    > 两者区别区别在于扩张卷积具有更大的感受野。感受野是卷积核在图像上看到的大小，例如3×3卷积核的感受野大小为9。
    > 
    > 例如下图是普通卷积，卷积核的感受野为3×3=9。 
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1icaKiaYRs2eNIaLwJsWzKL6nr9ibuibNg8LKicv9R0a4MEX9vxPJ53JSh2nxtYartPoC87FbVuUW6rJDw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 例如下图是扩张卷积，卷积核的感受野为7×7=49
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1icaKiaYRs2eNIaLwJsWzKL6n9joexza6bn65LfUz1dKvsetby0YpNs3DbCpUrXibDY2NCCqeKyyg5Zw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 下次更新将介绍因果卷积，残差卷积的跳层连接，并结合论文讲解TCN。


- [每天三分钟之Pytorch编程-5：RNN的新对手TCN(2)](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUzOTkyMDU5Mg%3D%3D%26mid%3D2247483811%26idx%3D1%26sn%3D0a834cd0794429e9fc3310d3e65d3889%26chksm%3Dfac0501ccdb7d90ac3aa81be7a3b2d643cdcf3c1f124907485c1951335daefb5bde45aade0c0%26scene%3D21%23wechat_redirect)

    > 上次初步介绍了TCN，时间卷积网络，一种新型的可以用来解决时间序列预测的算法。TCN中涉及到了一维卷积，扩张卷积，因果卷积，残差卷积的跳层连接等其他知识点。
    > 
    > 
    > 上次也介绍了一维卷积和扩张卷积。
    > 
    > 需要补充的是扩张卷积的好处是不做pooling损失信息的情况下，加大了感受野，让每个卷积输出都包含较大范围的信息。
    > 
    > 下面来介绍因果卷积，残差卷积的跳层连接
    > 
    > 因果卷积
    > 
    > 因果卷积的理解可以认为是：不管是自然语言处理领域中的预测还是时序预测，都要求对时刻t 的预测yt只能通过t时刻之前的输入x1到xt-1来判别。这种思想有点类似于马尔科夫链。
    > 
    > 残差卷积的跳层连接
    > 
    > 微软的残差网络 ResNet 就是经典的跳层连接（skip-connection），如下图所示。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ibNj4VFibhBOoiaJ5bSjibrv4YQ3lZaOHTALwiaaysByN4iav32LLctyibvNlCP8fI7rb30hBr0xYZMf93w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 上一层的特征图 x 直接与卷积后的 F(x)对齐加和，变为 F(x)+x （特征图数量不够可用 0 特征补齐，特征图大小不一可用带步长卷积做下采样）。
    > 
    > 这样在每层特征图中添加上一层的特征信息，可使网络更深，加快反馈与收敛。
    > 
    > 但是 ResNet 也有明显的缺陷：无法证明把每一层特征图硬连接到下一层都是有用的；并且实验证明把 ResNet 变深，不如把 ResNet 变宽， 即到了一定深度，加深网络已经无法使 ResNet 准确度提升了（还不如把网络层像 Inception 那样变宽）。
    > 
    > 全卷积网络
    > 
    > 时间卷积网络也用到了全卷积网络，全卷积网络（FCN）是在下篇论文中提出的：
    > 
    > 论文 : Fully Convolutional Networks for Semantic Segmentation
    > 
    > FCN与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类不同，FCN可以接受任意尺寸的输入，采用卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到与输入相同的尺寸，再进行预测。
    > 
    > TCN时间卷积网络
    > 
    >    下面将介绍时间卷积网络中的一维卷积，扩张卷积，因果卷积，残差卷积的跳 层连接是如何体现的，以及之间的关联。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ibNj4VFibhBOoiaJ5bSjibrv4YIzUFk2nCJxOXOwmibSId6HT7a6SjbHmSz8flYMZqdB2uxuibb7hdeGvA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > （a）图为空洞系数 d=1, 2, 4、卷积核大小 k=3 的**扩张卷积**，感受野能覆盖输入序列中的所有值。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ibNj4VFibhBOoiaJ5bSjibrv4Y3qGygiaENpSl0llo8CsL3YialQZU9hwduylQje3ic2ZDj8FLKntMfnfNg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 上式即为扩张卷积的计算公式，d为扩展系数。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ibNj4VFibhBOoiaJ5bSjibrv4Yj1fP8FD6whzeEu2sMx7uw5YEZoQoLMvpJh2C9PrKnnaVjSjQOxiag2A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > （b）为 TCN **残差块**，当残差输入和输出有不同的维度，会往其中添加一个 1x1 的卷积。
    > 
    > （c）为 残差连接的示例，蓝线为残差函数中的卷积核，绿线为恒等映射。
    > 
    > TCN 的卷积层结合了**扩张卷积**与**因果卷积**两种结构。使用因果卷积的目的是为了保证前面时间步的预测不会使用未来的信息，因为时间步 t 的输出只会根据 t-1 及之前时间步上的卷积运算得出。
    > 
    > 可以看出，TCN的卷积和普通的**一维卷积**非常类似，只不过最大的不同是用了扩张卷积，随着层数越多，卷积窗口越大，卷积窗口中的空孔会越多。
    > 
    > 值得一提的是在 TCN 的**残差模块**内(即图b)有两层扩张卷积和 ReLU 非线性函数，且卷积核的权重都经过了权重归一化。此外TCN 在残差模块内的每个空洞卷积后都添加了 Dropout 以实现正则化。
    > 
    > 论文中跳层连接时直接将下层的特征图跳层连接到上层，这样的话对应的通道数channel不一致，所以不能直接做加和操作，于是，为了两个层加和时特征图数量，即通道数数量相同，作者通过用**1×1卷积**进行元素合并来保证两个张量的形状相同。
    > 
    > 总结来讲，时间卷积网络是：
    > 
    > 同时用到一维因果卷积和扩张卷积作为标准卷积层，并将每两个这样的卷积层与恒等映射可以封装为一个残差模块（包含了relu函数）。再由残差模块堆叠起深度网络，并在最后几层使用**全卷积层**代替全连接层。
    > 
    > 由于TCN涉及内容较多，所以本次更新简要介绍整体框架，下次将着重对其中部分细节解释，并开始详解代码。
    > 



- [每天三分钟之Pytorch编程-5：RNN的新对手TCN(3)](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUzOTkyMDU5Mg%3D%3D%26mid%3D2247483814%26idx%3D1%26sn%3D23aab75bd647e7daae17e1dc5bfd9c24%26chksm%3Dfac05019cdb7d90f99e0e647a968491f06d0b5525e0b6f54a9562536c19987ad8bc4ac034b83%26scene%3D21%23wechat_redirect)

    > 代码详解
    > 
    > 下面是代码详解部分
    > 
    > 导入包
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa10HTxEORYFnGkO8nTlHAE58pJmNiaYoM7ugf270rFDXiacic4ibtFG15S7Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 数据读入与预处理
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa1XWNHoEu1yNP7M3G9vjfIXkcwkkHSrfxnIxdvzOocozL3iba007Bl7ZQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa1XcnpGibFCniasvzRoicGEWz0JwS5iaVBpybrCuTN22kGibjLyZy2OlBmPuQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa1nBicpViamW7YP7KPmXgW6QBo2exSjlWajbPicSrVHMpUMHibiaVDSdDcNibQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa19noJATcHh0LUKiby0uCic9nPpzxfAf6MNamS90JFMn6L6ZjxjDibwFgeA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo1ib4bReyCVoWxGLj6auBvEa1d8oExQ5mrCAuapu4IB3Sj5ibsgmjNBAjIvtgZbaeb4SJabZ4kic7EAgg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 具体代码
    > ```python
    > import os
    > 
    > import torch
    > 
    > from torch import nn
    > 
    > from torch.autograd import Variable
    > 
    > import pickle
    > 
    > from torch.nn.utils import weight_norm
    > 
    > import argparse
    > 
    > import time
    > 
    > import math
    > 
    > import torch.optim as optim
    > 
    > def data_generator(data_path):
    > 
    >     corpus = Corpus(data_path)
    > 
    >     pickle.dump(corpus, open(data_path + '/corpus', 'wb'))
    > 
    >     #pickle.dump(obj, file, [,protocol])是指将对象obj保存到文件file中。
    > 
    >     #protocol为序列化使用的协议版本，protocol默认值为0。
    > 
    >     #file：对象保存到的类文件对象。file必须有write()接口，
    > 
    >     return corpus
    > 
    > class Dictionary(object):
    > 
    >     def __init__(self):
    > 
    >         self.word2idx = {}
    > 
    >         self.idx2word = []
    > 
    >     def add_word(self, word):
    > 
    >         if word not in self.word2idx:
    > 
    >             self.idx2word.append(word)
    > 
    >             self.word2idx[word] = len(self.idx2word) - 1
    > 
    >         return self.word2idx[word]
    > 
    >     def __len__(self):
    > 
    >         return len(self.idx2word)
    > 
    > class Corpus(object):
    > 
    >     def __init__(self, path):
    > 
    >         self.dictionary = Dictionary()
    > 
    >         self.train = self.tokenize(os.path.join(path, 'train.txt'))
    > 
    >         self.valid = self.tokenize(os.path.join(path, 'valid.txt'))
    > 
    >         self.test = self.tokenize(os.path.join(path, 'test.txt'))
    > 
    >     def tokenize(self, path):
    > 
    >         """Tokenizes a text file."""
    > 
    >         assert os.path.exists(path)
    > 
    >         # 将word添加到dictionary中
    > 
    >         with open(path, 'r') as f:
    > 
    >             tokens = 0
    > 
    >             for line in f:
    > 
    >                 words = line.split() + ['< eos>']
    > 
    >                 tokens += len(words)
    > 
    >                 for word in words:
    > 
    >                     self.dictionary.add_word(word)
    > 
    >         # Tokenize file content
    > 
    >         with open(path, 'r') as f:
    > 
    >             ids = torch.LongTensor(tokens)
    > 
    >             token = 0
    > 
    >             for line in f:
    > 
    >                 words = line.split() + ['< eos>']
    > 
    >                 for word in words:
    > 
    >                     ids[token] = self.dictionary.word2idx[word]
    > 
    >                     token += 1
    > 
    >         #此处得到的ids就是长度为tokens的tensor，依次记载了每个词在
    > 
    >         #dictionary中的顺序
    > 
    >         return ids
    > 
    > def batchify(data, batch_size, cuda):
    > 
    >     #The output should have size [L x batch_size]
    > 
    >     #where L could be a long sequence length
    > 
    >     nbatch = data.size(0) // batch_size
    > 
    >     #nabatch是批次次数，batch_size是每一批的样本数量。
    > 
    >     # Trim off any extra elements that wouldn't cleanly fit (remainders).
    > 
    >     data = data.narrow(0, 0, nbatch * batch_size)
    > 
    >     #narrow(dim, index, size)的定义是 --表示取出tensor中第dim维上索引
    > 
    >     #从index开始到index+size-1的所有元素存放在data中 
    > 
    >     # Evenly divide the data across the batch_size batches.
    > 
    >     data = data.view(batch_size, -1)
    > 
    >     #view()函数的功能根reshape类似，用来转换size大小。
    > 
    >     #x = x.view(batchsize, -1)中batchsize指转换后有几行，
    > 
    >     #-1是指根据原tensor数据和batchsize自动分配列数
    > 
    >     if cuda:
    > 
    >         data = data.cuda()
    > 
    >     return data
    > 
    > def get_batch(source, i, seq_len, seq_le=None, evaluation=False):
    > 
    >     seq_le = min(seq_le if seq_le else seq_len, source.size(1) - 1 - i)
    > 
    >     data = Variable(source[:, i:i+seq_le], volatile=evaluation)
    > 
    >     #variable的volatile属性默认为False，如果某一个variable的volatile属性被
    > 
    >     #设为True，那么所有依赖它的节点volatile属性都为True。volatile属性为True的
    > 
    >     #节点不会求导，volatile的优先级比requires_grad高。
    > 
    >     target = Variable(source[:, i+1:i+1+seq_le])
    > 
    >     # CAUTION: This is un-flattened!
    > 
    >     return data, target
    > 
    > cuda = False # 是否使用 CUDA
    > 
    > data_path = './tcn/data/penn' #数据地址
    > 
    > batch_size = 16 # 每次训练时批量数据大小
    > 
    > nhid = 600 # 定义了神经网络中每层隐藏单元数
    > 
    > levels = 4 # 残差模块数，用来计算通道数
    > 
    > emsize = 600 # 词嵌入长度
    > 
    > k_size = 3 # 卷积核大小
    > 
    > dropout = 0.45 # 网络层级中的随机dropout比率
    > 
    > emb_dropout = 0.25 # 嵌入层的随机dropout率
    > 
    > tied = True # 是否让编码器与解码器的权重相同
    > 
    > lr = 4 # 初始化的学习率
    > 
    > optimization ='SGD'#梯度下降方法
    > 
    > validseqlen = 40 # 用来验证序列长度
    > 
    > seq_len = 80 # 总序列的长度
    > 
    > log_interval = 100 # 记录最后结果的间隔
    > 
    > clip = 0.35 # 梯度截断的设定，-1表示不采用梯度截断
    > 
    > epochs =100 # 一共训练多少轮的上限
    > 
    > # Set the random seed manually for reproducibility.
    > 
    > torch.manual_seed(11)
    > 
    > if torch.cuda.is_available():
    > 
    >     if not cuda:
    > 
    >         print("WARNING: you should probably run with --cuda")
    > 
    > corpus = data_generator(data_path)
    > 
    > #得到语料库
    > 
    > eval_batch_size = 10
    > 
    > train_data = batchify(corpus.train, batch_size, cuda)
    > 
    > val_data = batchify(corpus.valid, eval_batch_size, cuda)
    > 
    > test_data = batchify(corpus.test, eval_batch_size, cuda)
    > 
    > n_words = len(corpus.dictionary)
    > 
    > #字典长度
    > 
    > num_chans = [nhid] * (levels - 1) + [emsize]
    > 
    > #通道个数
    > ```
    > 


- [每天三分钟之Pytorch编程-5：RNN的新对手TCN(4)](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUzOTkyMDU5Mg%3D%3D%26mid%3D2247483822%26idx%3D1%26sn%3D281081364cdb70aa61131bfed521d1b2%26chksm%3Dfac05011cdb7d907c8d94422b3387e21515d2c72ceef1466a31ba87db7e86abdccf5368fd3da%26scene%3D21%23wechat_redirect)

    > **模型展示**
    > 
    > 为了方便解读代码，先将模型的图片展示如下：
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qM0Jbj9vqcvzsST1V1FqyA1Cwia5PjPiarZiaib32iamy9W8mOB76z6xfshCQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMugv1zkl6ZYCBiaM6oJzJ26IYTY6mMZlvnlZtYL3RXNnkKHHMczSRZFA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMGicIfqhzvIUNTOfrl1QKslS2swLzeOr5NrAl0d4RAdplRAnZUCUvQmw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 
    > 代码详解
    > 
    > 下面是代码详解部分
    > 
    > 实现因果卷积的类
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMZf1taz3hXU0hGSzM3GLEXLHWyBYwIxqZribMWRgE7l7iat0OskBxRMNw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 残差模块
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMSlP6Mw66wFp5Puvql2x6pHVibYrx4SOKJtfpibS0T2g4VI15c4y5X5bg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMViafW4Dkjahr0eAgTZsd2nuxFgicCh2bwyO2g47S6Piag99O5HXca0C0A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 时间卷积网络的架构
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMCzV1rQTolYL3bJ3CN06csiaHWpnrVK9sjEAjy2bZUibc89aUq0NAl8Tg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > TCN
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMpc5dk12UDA26fhEpJ57wT3RUs5JB441KXp0tUdRu4Bp06La6Z74t1w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo18nRNsvicd6jKwtQAZrfS8qMwOtuoZ42QJ9DRe6xjXgkpbgRIH3icj5j4K4oXoRBukhibx9ZyjrxS5sg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 具体代码
    > 
    > ```python
    > # 定义实现因果卷积的类（继承自类nn.Module）
    > 
    > class Chomp1d(nn.Module):
    > 
    >     #继承自类nn.Module
    > 
    >     def __init__(self, chomp_size):
    > 
    >         super(Chomp1d, self).__init__()
    > 
    >         #表示对继承自父类的属性进行初始化。
    > 
    >         self.chomp_size = chomp_size
    > 
    >     def forward(self, x):
    > 
    >         return x[:, :, :-self.chomp_size].contiguous()
    > 
    >     # tensor.contiguous()会返回有连续内存的相同张量
    > 
    >     #有些tensor并不是占用一整块内存，而是由不同的数据块组成
    > 
    >     #而tensor的view()操作依赖于内存是整块的，这时只需要执行
    > 
    >     #contiguous()这个函数，就能把tensor变成在内存中连续分布的形式。
    > 
    >     # 通过增加Padding方式对卷积后的张量做切片而实现因果卷积
    > 
    > # 残差模块，其中有两个一维卷积与恒等映射，具体结构可看图片
    > 
    > class TemporalBlock(nn.Module):
    > 
    >     def __init__(self, n_inputs, n_outputs, kernel_size, 
    > 
    >                  stride, dilation, padding, dropout=0.2):
    > 
    >         super(TemporalBlock, self).__init__()
    > 
    >         self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs,
    > 
    >                                            kernel_size,
    > 
    >                                            stride=stride, 
    > 
    >                                            padding=padding, 
    > 
    >                                            dilation=dilation))
    > 
    >         #定义第一个扩散卷积层，扩散是指dilation=dilation
    > 
    >         self.chomp1 = Chomp1d()
    > 
    >         # 根据第一个卷积层的输出与padding大小实现因果卷积
    > 
    >         self.relu1 = nn.ReLU()
    > 
    >         self.dropout1 = nn.Dropout2d(dropout)
    > 
    >         # 在先前的输出结果上添加激活函数与dropout完成第一个卷积
    > 
    >         self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs,
    > 
    >                                            kernel_size,
    > 
    >                                            stride=stride, 
    > 
    >                                            padding=padding,
    > 
    >                                            dilation=dilation))
    > 
    >         self.chomp2 = Chomp1d(padding)
    > 
    >         # padding保证了输入序列与输出序列的长度相等，
    > 
    >         #但卷积前的通道数与卷积后的通道数不一定一样。
    > 
    >         self.relu2 = nn.ReLU()
    > 
    >         self.dropout2 = nn.Dropout2d(dropout)
    > 
    >         #以上四行是与第一个卷积层堆叠了同样结构的第二个卷积层
    > 
    >         self.net = nn.Sequential(self.conv1, self.chomp1,
    > 
    >                                  self.relu1, self.dropout1,
    > 
    >                                  self.conv2, self.chomp2, 
    > 
    >                                  self.relu2, self.dropout2)
    > 
    >         # 将卷积模块的所有组建通过Sequential方法依次堆叠在一起
    > 
    >         #具体来说的话网络结构是一层一层的叠加起来的，nn库里有一个类型：
    > 
    >         #叫做Sequential序列，它是一个容器类，可以在里面添加一些基本的模块。
    > 
    >         self.downsample=nn.Conv1d(n_inputs,n_outputs,1)if n_inputs!=n_outputs else None
    > 
    >         self.relu = nn.ReLU()
    > 
    >         self.init_weights()
    > 
    >         #正如先前提到的卷积前与卷积后的通道数不一定相同
    > 
    >         #所以如果通道数不一样，那么需要对输入x做一个逐元素的一维卷积
    > 
    >         #以使得它的维度与前面两个卷积相等。
    > 
    >     def init_weights(self):
    > 
    >         self.conv1.weight.data.normal_(0, 0.01)
    > 
    >         self.conv2.weight.data.normal_(0, 0.01)
    > 
    >         #初始化方法是从均值为0，标准差为0.01的正态分布采样
    > 
    >         if self.downsample is not None:
    > 
    >             self.downsample.weight.data.normal_(0, 0.01)
    > 
    >     def forward(self, x):
    > 
    >         out = self.net(x)#输入的逐元素卷积与relu激活函数
    > 
    >         res = x if self.downsample is None else self.downsample(x)
    > 
    >         #残差模块
    > 
    >         return self.relu(out + res)
    > 
    > # 定义时间卷积网络的架构
    > 
    > class TemporalConvNet(nn.Module):
    > 
    >     def __init__(self, num_inputs, num_channels,
    > 
    >                  kernel_size=2, dropout=0.2):
    > 
    >         super(TemporalConvNet, self).__init__()
    > 
    >         layers = []
    > 
    >         #num_channels为各层卷积运算的输出通道数或卷积核数量
    > 
    >         #num_channels的长度即需要执行的卷积层数量
    > 
    >         num_levels = len(num_channels)
    > 
    >         # 扩张系数若能随着网络层级的增加而成指数增加，
    > 
    >         #则可以增大感受野并不丢弃任何输入序列的元素
    > 
    >         for i in range(num_levels):
    > 
    >             dilation_size = 2 ** i
    > 
    >             #dilation_size根据层级数指数增加
    > 
    >             in_channels = num_inputs if i == 0 else num_channels[i - 1]
    > 
    >             out_channels = num_channels[i]
    > 
    >             #从num_channels中抽取每一个残差模块的输入通道数与输出通道数
    > 
    >             layers += [TemporalBlock(in_channels, out_channels, 
    > 
    >                                      kernel_size, stride=1,
    > 
    >                                      dilation=dilation_size,
    > 
    >                                      padding=(kernel_size - 1) * dilation_size, 
    > 
    >                                      dropout=dropout)]
    > 
    >         # 将所有残差模块堆叠起来组成一个深度卷积网络
    > 
    >         self.network = nn.Sequential(*layers)
    > 
    >     def forward(self, x):
    > 
    >         return self.network(x)
    > 
    > class TCN(nn.Module):
    > 
    >     def __init__(self, input_size, output_size, num_channels,
    > 
    >                  kernel_size=2, dropout=0.3, emb_dropout=0.1, 
    > 
    >                  tied_weights=False):
    > 
    >         super(TCN, self).__init__()
    > 
    >         self.encoder = nn.Embedding(output_size, input_size)
    > 
    >         #将one-hot encoding 部分送入编码器作为一个批量的词嵌入向量
    > 
    >         #output_size为词汇量，input_size是词向量的长度
    > 
    >         self.tcn = TemporalConvNet(input_size, num_channels, 
    > 
    >                                    kernel_size, dropout=dropout)
    > 
    >         #时间卷积网络的架构
    > 
    >         self.decoder = nn.Linear(num_channels[-1], output_size)
    > 
    >         # 定义最后线性变换的维度，即最后一个卷积层的通道数到所有词汇的映射
    > 
    >         if tied_weights:
    > 
    >             if num_channels[-1] != input_size:
    > 
    >                 raise ValueError('When using the tied flag, nhid must be equal to emsize')
    > 
    >             self.decoder.weight = self.encoder.weight
    > 
    >             print("Weight tied")
    > 
    >         #是否共享编码器与解码器的权重，默认值为共享
    > 
    >         #共享时需要保持隐藏单元数等于词嵌入的长度
    > 
    >         #此时将预测的向量认为是词嵌入向量
    > 
    >         self.drop = nn.Dropout(emb_dropout)
    > 
    >         self.emb_dropout = emb_dropout
    > 
    >         #对输入词嵌入进行dropout
    > 
    >         self.init_weights()
    > 
    >     def init_weights(self):
    > 
    >         self.encoder.weight.data.normal_(0, 0.01)
    > 
    >         self.decoder.bias.data.fill_(0)
    > 
    >         self.decoder.weight.data.normal_(0, 0.01)
    > 
    >         #进行初始化
    > 
    >     def forward(self, input):
    > 
    >         """Input ought to have dimension (N, C_in, L_in), 
    > 
    >         where L_in is the seq_len; here the input is (N, L, C)"""
    > 
    >         emb = self.drop(self.encoder(input))#编码并进行dropout
    > 
    >         y = self.tcn(emb.transpose(1, 2)).transpose(1, 2)
    > 
    >         #输入到网络进行推断
    > 
    >         y = self.decoder(y)
    > 
    >         #将推断结果解码为词
    > 
    >         return y.contiguous()
    > ```
    > 

- [每天三分钟之Pytorch编程-5：RNN的新对手TCN(完结)](http://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzUzOTkyMDU5Mg%3D%3D%26mid%3D2247483822%26idx%3D2%26sn%3D891fcebca7f6060080fa6d70072f7ff7%26chksm%3Dfac05011cdb7d9079372f7ca10ef6de57b68efbd2619769d64e86caeb9f23d06021f69289105%26scene%3D21%23wechat_redirect)

    > 代码详解与结果
    > 
    > 下面是代码详解与结果部分
    > 
    > 第一部分
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboicPtEpkgHIPUAbyx8ezTDfccm5TVJUhyDcARKY5W0CSJ6OGFHwOibibBjQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 第二部分
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboicE3ic3kIH86pD0dribQakZkHufohIPl4icEDE2K7HNia2ZNcBpfUTUBhOicw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 第三部分：训练
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboiclYWw44Yce74r6XbNyf5iavg71kicM42CQwUZpN00Wfeib4wYD6DJtceiaA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboic7RmZ1YXU4HthIaqllAI1nviaibIdsD4EIA5C64sLc96r1yJb02UAcDvA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > main部分与结果
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboicokFKGyD7643fWdThJW1AicRdibfWcpLtHPGsolO1uKibSlrDMJIXumhCA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboichWMnDt9k8sX5ianDmQj2jIvnX5ZsbIaIUzE2Gdh7iaFYGIWicaNqu1llQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/NvqaDFQAo19tyI7R8ib7fXlTtiaUZsPiboic5v4ow8MfGf6vlASY125FPKjKqRgicR9ZxwNtlPIfZQIOibribEt3sApDw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 具体代码
    > 
    > ```python
    > model = TCN(emsize, n_words, num_chans, dropout=dropout,
    > 
    >             emb_dropout=emb_dropout, kernel_size=k_size, tied_weights=tied)
    > 
    > if cuda:
    > 
    >     model.cuda()
    > 
    > # May use adaptive softmax to speed up training
    > 
    > criterion = nn.CrossEntropyLoss()
    > 
    > #交叉熵损失函数
    > 
    > optimizer = getattr(optim, optimization)(model.parameters(), lr=lr)
    > 
    > #getattr() 函数是用于返回一个对象属性值。
    > 
    > #getattr(object, name[, default])
    > 
    > #object -- 对象
    > 
    > #name -- 字符串，对象属性。
    > 
    > #default -- 默认返回值，如果不提供该参数，在没有对应属性时，将触发 AttributeError。
    > 
    > #model.parameters()是提供给optim的参数
    > 
    > def evaluate(data_source):
    > 
    >     model.eval()
    > 
    >     total_loss = 0
    > 
    >     processed_data_size = 0
    > 
    >     for i in range(0, data_source.size(1) - 1, validseqlen):
    > 
    >         if i + seq_len - validseqlen >= data_source.size(1) - 1:
    > 
    >             continue
    > 
    >         data, targets = get_batch(data_source, i, seq_len, evaluation=True)
    > 
    >         #获得数据
    > 
    >         output = model(data)
    > 
    >         #得到输出值
    > 
    >         # Discard the effective history, just like in training
    > 
    >         eff_history = seq_len - validseqlen
    > 
    >         #eff_history是总序列长度-验证序列的长度
    > 
    >         final_output = output[:, eff_history:].contiguous().view(-1, n_words)
    > 
    >         final_target = targets[:, eff_history:].contiguous().view(-1)
    > 
    >         loss = criterion(final_output, final_target)
    > 
    >         #交叉熵损失函数
    > 
    >         # Note that we don't add TAR loss here
    > 
    >         total_loss += (data.size(1) - e  ff_history) * loss.data
    > 
    >         #总损失
    > 
    >         processed_data_size += data.size(1) - eff_history#大小
    > 
    >     return total_loss[0] / processed_data_size
    > 
    > def train():
    > 
    >     # Turn on training mode which enables dropout.
    > 
    >     global train_data
    > 
    >     model.train()
    > 
    >     total_loss = 0
    > 
    >     start_time = time.time()
    > 
    >     for batch_idx, i in enumerate(range(0, train_data.size(1) - 1, validseqlen)):
    > 
    >         if i + seq_len - validseqlen >= train_data.size(1) - 1:
    > 
    >             continue
    > 
    >         data, targets = get_batch(train_data, i, seq_len)
    > 
    >         optimizer.zero_grad()#梯度清零
    > 
    >         output = model(data)
    > 
    >         # Discard the effective history part
    > 
    >         eff_history = seq_len - validseqlen
    > 
    >         if eff_history < 0:
    > 
    >             raise ValueError("Valid sequence length must be smaller than sequence length!")
    > 
    >         final_target = targets[:, eff_history:].contiguous().view(-1)
    > 
    >         #contiguous是因为view需要tensor的内存是整块的 
    > 
    >         final_output = output[:, eff_history:].contiguous().view(-1, n_words)
    > 
    >         loss = criterion(final_output, final_target)#交叉熵函数
    > 
    >         loss.backward()
    > 
    >         #看似没有传参数，其实是反向求解梯度的过程
    > 
    >         if clip > 0:
    > 
    >             torch.nn.utils.clip_grad_norm(model.parameters(), clip)
    > 
    >             #梯度裁剪，输入是（NN参数，最大梯度范数，范数类型=2) 一般默认为L2 范数
    > 
    >         optimizer.step()
    > 
    >         #使用step方法来对所有参数进行更新
    > 
    >         total_loss += loss.data
    > 
    >         if batch_idx % log_interval == 0 and batch_idx > 0:
    > 
    >             cur_loss = total_loss[0] / log_interval
    > 
    >             elapsed = time.time() - start_time
    > 
    >             print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.5f} | ms/batch {:5.5f} | '
    > 
    >                   'loss {:5.2f} | ppl {:8.2f}'.format(
    > 
    >                 epoch, batch_idx, train_data.size(1) // validseqlen, lr,
    > 
    >                 elapsed * 1000 / log_interval, cur_loss, math.exp(cur_loss)))
    > 
    >             #输出结果，具体结果可查看之后图片
    > 
    >             total_loss = 0
    > 
    >             start_time = time.time()
    > 
    > if __name__ == "__main__":
    > 
    >     best_vloss = 1e8
    > 
    >     # At any point you can hit Ctrl + C to break out of training early.
    > 
    >     try:
    > 
    >         all_vloss = []
    > 
    >         for epoch in range(1, epochs+1):
    > 
    >             epoch_start_time = time.time()
    > 
    >             train()
    > 
    >             val_loss = evaluate(val_data)
    > 
    >             test_loss = evaluate(test_data)
    > 
    >             print('-' * 89)
    > 
    >             print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | '
    > 
    >                     'valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),
    > 
    >                                                val_loss, math.exp(val_loss)))
    > 
    >             print('| end of epoch {:3d} | time: {:5.2f}s | test loss {:5.2f} | '
    > 
    >                   'test ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),
    > 
    >                                             test_loss, math.exp(test_loss)))
    > 
    >             print('-' * 89)
    > 
    >             # Save the model if the validation loss is the best we've seen so far.
    > 
    >             if val_loss < best_vloss:
    > 
    >                 with open("model.pt", 'wb') as f:
    > 
    >                     print('Save model!\n')
    > 
    >                     torch.save(model, f)
    > 
    >                 best_vloss = val_loss
    > 
    >             # Anneal the learning rate if the validation loss plateaus
    > 
    >             if epoch > 5 and val_loss >= max(all_vloss[-5:]):
    > 
    >                 lr = lr / 2.
    > 
    >                 for param_group in optimizer.param_groups:
    > 
    >                     param_group['lr'] = lr
    > 
    >             all_vloss.append(val_loss)
    > 
    >     except KeyboardInterrupt:
    > 
    >         print('-' * 89)
    > 
    >         print('Exiting from training early')
    > 
    >     # Load the best saved model.
    > 
    >     with open("model.pt", 'rb') as f:
    > 
    >         model = torch.load(f)
    > 
    >     # Run on test data.
    > 
    >     test_loss = evaluate(test_data)
    > 
    >     print('=' * 89)
    > 
    >     print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(
    > 
    >         test_loss, math.exp(test_loss)))
    > 
    >     print('=' * 89)
    > ```
    
    
    
    