# 深度學習理論

<!-- toc --> 
[toc]

## Some Ideas

- super resolution for text image



## Theory

### Back Propergation

- [derivative - Backpropagation with Softmax / Cross Entropy - Cross Validated](https://stats.stackexchange.com/questions/235528/backpropagation-with-softmax-cross-entropy)

    The cross entropy error function is

    $$
    E=-\sum_jt_j\log o_j
    $$

    with $t$   and $o$   as the target and output at neuron $j$  , respectively. The sum is over each neuron in the output layer. $o_j$    itself is the result of the softmax function:

    $$
    o_j=softmax(z_j)=\frac{e^{z_j}}{\sum_j e^{z_j}}
    $$

    Again, the sum is over each neuron in the output layer and $z_j$ is the input to neuron $j$:

    $$
    z_j=\sum_i w_{ij}y_i+b_j
    $$

    That is the sum over all neurons in the previous layer with their corresponding output $o_i$ and weight $w_ij$ towards neuron $j$ plus a bias $b$.

    Finally, to get the gradient of $E$ with respect to the weight-matrix $w$, giving the final expression (assuming a one-hot $t$  , i.e. $τ=1$  )

    $$
    \frac{\partial E}{\partial w_{ij}}=y_i(o_j-t_j)
    $$

    where $y$ is the input on the lowest level (of your example).


- [machine learning - Cross entropy function (python) - Stack Overflow](https://stackoverflow.com/questions/47377222/cross-entropy-function-python)

    > ```python
    > def cross_entropy(predictions, targets, epsilon=1e-12):
    >     """
    >     Computes cross entropy between targets (encoded as one-hot vectors)
    >     and predictions. 
    >     Input: predictions (N, k) ndarray
    >            targets (N, k) ndarray        
    >     Returns: scalar
    >     """
    >     predictions = np.clip(predictions, epsilon, 1. - epsilon)
    >     N = predictions.shape[0]
    >     ce = -np.sum(np.sum(targets*np.log(predictions+1e-9)))/N
    >     return ce
    > 
    > predictions = np.array([[0.25,0.25,0.25,0.25],
    >                         [0.01,0.01,0.01,0.96]])
    > targets = np.array([[0,0,0,1],
    >                    [0,0,0,1]])
    > ans = 0.71355817782  #Correct answer
    > x = cross_entropy(predictions, targets)
    > print(np.isclose(x,ans))
    > ```
    > 
    > Here, I think it's a little clearer if you stick with np.sum(). Also, I added 1e-9 into the np.log() to avoid the possibility of having a log(0) in your computation. Hope this helps!


### Activation Function

- sigmoid
- tanh
- relu
- selu


### initializer

#### Xavier
- [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a.html)

#### He
#### Lecun


### optimizer

- Gradient Descent
    $$
    \begin{aligned}
    &\theta_t : \text{目前參數值所成向量}&\\
    &g_t = \nabla_\theta L(\theta_t)&\\
    &\\
    &\theta_{t+1}=\theta_t+\eta g_t&\\
    \end{aligned}
    $$
    
    
- adam

### Regularization

- dropout
- L2 Regularization

通常 dropout, L2 regularization 選⼀個就好


### Convolution

- 公式推導

    $$
    \begin{aligned}
    & L: Origin\ Width &\\
    & p: padding &\\
    & f: filter\ Width &\\
    & s: stride &\\
    & N: New\ Width &\\
    &\\
    &L+2p = f \times N -(f-s)(N-1) &\\
    & \Longrightarrow L = f + s(N-1) - 2p &\\
    & \Longrightarrow N = \frac{L-f+2p}{s}+1 &\\
    \end{aligned}
    $$

    ![](https://screenshotscdn.firefoxusercontent.com/images/4ca43278-1643-4e84-8aa4-b9f4bb8545b1.png)


- [[1603.07285] A guide to convolution arithmetic for deep learning](https://arxiv.org/abs/1603.07285)



## Course

### CS231n
- Notes
    - [CS231n Convolutional Neural Networks for Visual Recognition](https://cs231n.github.io/convolutional-networks/)
    - [Convolutional Neural Networks (CNNs / ConvNets)](https://cs231n.github.io/)
- Slides
    - [Syllabus | CS 231N](http://cs231n.stanford.edu/syllabus.html)
- Lecture Video
    - [Lecture Collection | Convolutional Neural Networks for Visual Recognition (Spring 2017) - YouTube - YouTube](https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)

## Datasets

- [CIFAR-10 and CIFAR-100 datasets](https://www.cs.toronto.edu/~kriz/cifar.html)
- [ImageNet](http://www.image-net.org/)
- [COCO - Common Objects in Context](http://cocodataset.org/#home)
- 

## CNN 

### State of the art

- MNIST, CIFAR-10, CIFAR-100, STL-10, SVHN, ILSVRC2012 task 1 [Classification datasets results](https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)

### Papers

- AlexNet [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)
- VGGNet [[1409.1556] Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)
- GoogLeNet [[1409.4842] Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)
- ResNet [[1512.03385] Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

### Articles

- [#Deep Learning回顾#之LeNet、AlexNet、GoogLeNet、VGG、ResNet - 我爱机器学习 - 博客园](https://www.cnblogs.com/52machinelearning/p/5821591.html)
- [深度学习方法（五）：卷积神经网络CNN经典模型整理Lenet，Alexnet，Googlenet，VGG，Deep Residual Learning - CSDN博客](http://blog.csdn.net/xbinworld/article/details/45619685)
- [残差网络ResNet笔记 - 简书](https://www.jianshu.com/p/e58437f39f65)
- [无需数学背景，读懂 ResNet、Inception 和 Xception 三大变革性架构 | 机器之心](https://www.jiqizhixin.com/articles/2017-08-19-4)
- [The 9 Deep Learning Papers You Need To Know About (Understanding CNNs Part 3) – Adit Deshpande – CS Undergrad at UCLA ('19)](https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html)
- [Exploring Deep Learning & CNNs - RSIP Vision](https://www.rsipvision.com/exploring-deep-learning/)
- [A Beginner's Guide To Understanding Convolutional Neural Networks – Adit Deshpande – CS Undergrad at UCLA ('19)](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)

### Topics

#### 破解 capcha

- [使用深度学习来破解 captcha 验证码](https://zhuanlan.zhihu.com/p/26078299)
    - [ypwhs/captcha_break: 验证码识别](https://github.com/ypwhs/captcha_break)
- [rickyhan/SimGAN-Captcha: Solve captcha without manually labeling a training set](https://github.com/rickyhan/SimGAN-Captcha)
- [JasonLiTW/simple-railway-captcha-solver: 實作基於CNN的台鐵訂票驗證碼辨識以及驗證性高的訓練集產生器 (Simple captcha solver based on CNN and a training set generator by imitating the style of captcha)](https://github.com/JasonLiTW/simple-railway-captcha-solver)
- [裤҉裆҉里҉的҉霸҉气҉/verification-decoder - 碼雲 Gitee.com](https://gitee.com/kdldbq/verification-decoder?from=weekmail)


#### Image Caption

- [karpathy/neuraltalk2: Efficient Image Captioning code in Torch, runs on GPU](https://github.com/karpathy/neuraltalk2)

    <iframe src="https://player.vimeo.com/video/146492001" width="640" height="400" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
    <p><a href="https://vimeo.com/146492001">NeuralTalk and Walk</a> from <a href="https://vimeo.com/kylemcdonald">Kyle McDonald</a> on <a href="https://vimeo.com">Vimeo</a>.</p>

- [[1703.09137] Where to put the Image in an Image Caption Generator](https://arxiv.org/abs/1703.09137)


#### Ultrasound image with deep learning

- [[1710.10006] Deep Learning for Accelerated Ultrasound Imaging](https://arxiv.org/abs/1710.10006)
    - [[1710.06304] Towards CT-quality Ultrasound Imaging using Deep Learning](https://arxiv.org/abs/1710.06304)

- [Ultrasound DL](http://deepultrasound.ai/)
- [Automating Breast Cancer Detection with Deep Learning](https://blog.insightdatascience.com/automating-breast-cancer-detection-with-deep-learning-d8b49da17950)

## GAN

### State of the art

- [the-gan-zoo/gans.tsv at master · hindupuravinash/the-gan-zoo](https://github.com/hindupuravinash/the-gan-zoo/blob/master/gans.tsv)


#### 二次元妹子

- [MakeGirlsMoe - Create Anime Characters with A.I.!](https://make.girls.moe/)
- 


### Papers

- [Timnit Gebru 在 Twitter："Does someone have a list like the 10 or even 20 GAN related papers I should read this year or something like this? I can't keep up. @goodfellow_ian ?"](https://twitter.com/timnitGebru/status/968242968007200769)

    > 1\. Progressive GANs: [ https://arxiv.org/abs/1710.10196  ](https://t.co/UEFhewds2M "https://arxiv.org/abs/1710.10196") (probably the highest quality images so far)
    > 
    > 2\. Spectral normalization: [ https://openreview.net/forum?id=B1QRgziT-&noteId=BkxnM1TrM …](https://t.co/tt2os9H1Py "https://openreview.net/forum?id=B1QRgziT-&noteId=BkxnM1TrM") (got GANs working on lots of classes, which has been hard)
    > 
    > 3\. Projection discriminator: [ https://openreview.net/forum?id=ByS1VpgRZ …](https://t.co/qG1xwu1PuX "https://openreview.net/forum?id=ByS1VpgRZ") (from the same lab as #2, both techniques work well together, overall give very good results with 1000 classes) Here's the video of putting the two methods together: [https://www.youtube.com/watch?time_continue=3&v=r6zZPn-6dPY](https://www.youtube.com/watch?time_continue=3&v=r6zZPn-6dPY)
    > 
    > 4\. pix2pixHD (GANs for 2-megapixel video) [https://arxiv.org/abs/1711.11585](https://arxiv.org/abs/1711.11585)
    > [https://www.youtube.com/watch?v=3AIpPlzM_qs&feature=youtu.be](https://www.youtube.com/watch?v=3AIpPlzM_qs&feature=youtu.be) 
    > 
    > 
    > 5\. Are GANs created equal? [ https://arxiv.org/abs/1711.10337  ](https://t.co/4dIIOjPBC3 "https://arxiv.org/abs/1711.10337") A big empirical study showing the importance of good rigorous empirical work and how a lot of the GAN variants don't seem to actually offer improvements in practice 
    > 
    > 
    > 6\. WGAN-GP [ https://arxiv.org/abs/1704.00028  ](https://t.co/zJ6ZDSdz7w "https://arxiv.org/abs/1704.00028") : probably the most popular GAN variant today and seems to be pretty good in my opinion. Caveat: the baseline GAN variants should not perform nearly as badly as this paper claims, especially the text one
    > 
    > 7\. StackGAN++: [ https://arxiv.org/abs/1710.10916  ](https://t.co/ccOlTNW43F "https://arxiv.org/abs/1710.10916") High quality text-to-image synthesis with GANs
    > 
    > 8\. Making all ML algorithms differentially private by training them on fake private data generated by GANs [https://www.biorxiv.org/content/early/2017/07/05/159756](https://www.biorxiv.org/content/early/2017/07/05/159756)
    > 
    > 9\. You should be a little bit aware of the "GANs with encoders" space, one of my favorites is [ https://arxiv.org/abs/1701.04722](https://t.co/2uWTwu6kes "https://arxiv.org/abs/1701.04722")
    > 
    > 10\. You should be a little bit aware of the "theory of GAN convergence" space, one of my favorites is [ https://arxiv.org/abs/1706.04156](https://t.co/JpCKaHy9im "https://arxiv.org/abs/1706.04156")
    > 
    > [name=Ian Goodfellow]


#### 對抗樣本

- [[1412.6572] Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)

- [[1801.02610] Generating Adversarial Examples with Adversarial Networks](https://arxiv.org/abs/1801.02610)

#### 防禦對抗樣本

- [Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models | OpenReview](https://openreview.net/forum?id=BkJ3ibb0-&noteId=SJwPXJaHG)

#### Convergence and Stability

- [[1705.07215] On Convergence and Stability of GANs](https://arxiv.org/abs/1705.07215)

- [[1703.10717] BEGAN: Boundary Equilibrium Generative Adversarial Networks](https://arxiv.org/abs/1703.10717)

#### GAN + RL



- [Learning to write programs that generate images | DeepMind](https://deepmind.com/blog/learning-to-generate-images/)

    - [DeepMind提出SPIRAL：使用強化對抗學習，實現會用畫筆的智能體 - 幫趣](http://bangqu.com/Sr63zI.html)




### Articles

- [Gan的数学推导 | Sherlock Blog](https://sherlockliao.github.io/2017/06/20/gan_math/)

- [amazing_gans_pycon2017 - Google 簡報](https://docs.google.com/presentation/d/14jJL6MR2uf4CD7PmsgMtivX8WfK-QMdKdwrLEYH9qDA/edit#slide=id.g22c42edce6_0_644)

- [[1701.04862] Towards Principled Methods for Training Generative Adversarial Networks](https://arxiv.org/abs/1701.04862)



#### Training giude

- [soumith/ganhacks: starter from "How to Train a GAN?" at NIPS2016](https://github.com/soumith/ganhacks)

- [[1701.00160] NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
- 

#### Mode colapse

<iframe width="560" height="315" src="https://www.youtube.com/embed/ktxhiKhWoEE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

- [Mode collapse in GANs - Aiden Nibali](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/)

    > Addressing mode collapse
    > ------------------------
    > 
    > Mode collapse is a well-recognised problem, and researchers have made a few attempts at addressing it. I have identified 4 broad approaches to tackling mode collapse, which are described below.
    > 
    > ### Directly encourage diversity
    > 
    > It is impossible to determine output diversity by considering individual samples in isolation. This leads to a very logical next step of using batches of samples to directly assess diversity. Minibatch discrimination and feature mapping [1](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/#fn:imprgan) are two techniques which fall into this category.
    > 
    > Minibatch discrimination gives the discriminator the power of comparing samples across a batch to help determine whether the batch is real or fake.
    > 
    > Feature matching modifies the generator cost function to factor in the diversity of generated batches. It does this by matching statistics of discriminator features for fake batches to those of real batches. I had some success combining feature matching with the traditional GAN generator loss function to form a hybrid objective.
    > 
    > ### Anticipate counterplay
    > 
    > One way to prevent the cat-and-mouse game of hopping between modes is to peek into the future and anticipate counterplay when updating parameters. This approach should be familiar to those who know a bit about game theory (eg [minimax](https://en.wikipedia.org/wiki/Minimax)). Intuitively, this prevents players of the GAN game from making moves which are easily countered.
    > 
    > Unrolled GANs [2](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/#fn:unrolled) take this kind of approach by allowing the generator to “unroll” updates of the discriminator in a fully differentiable way. Now instead of the generator learning to fool the current discriminator, it learns to maximally fool the discriminator _after it has a chance to respond_, thus taking counterplay into account. Downsides of this approach are increased training time (each generator update has to simulate multiple discriminator updates) and a more complicated gradient calculation (backprop through an optimiser update step can be difficult).
    > 
    > ### Use experience replay
    > 
    > Hopping back and forth between modes can be minimised by showing old fake samples to the discriminator every so often. This prevents the discriminator from becoming too exploitable, but only for modes that have already been explored by the generator in the past.
    > 
    > A similar kind of effect can be achieved by occasionally substituting in an old discriminator/generator for a few iterations.
    > 
    > ### Use multiple GANs
    > 
    > Rather than fight mode collapse we could simply accept that the GAN will cover only a subset of the modes in the dataset, and train multiple GANs for different modes. When combined, these GANs cover all of the modes. AdaGAN [3](http://aiden.nibali.org/blog/2017-01-18-mode-collapse-gans/#fn:adagan) takes this approach. The major downside here is that training multiple GANs takes a lot of time. Furthermore, using a combination of GANs is generally more unwieldy than working with just one.




### Topics

#### Variational Autoencoder

- [[1606.05908] Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)


#### WGAN

- [[1701.07875] Wasserstein GAN](https://arxiv.org/abs/1701.07875)
- [Wasserstein GAN and the Kantorovich-Rubinstein Duality - Vincent Herrmann](https://vincentherrmann.github.io/blog/wasserstein/)
- [A Hitchhikers guide to Wasserstein.pdf](http://n.ethz.ch/~gbasso/download/A%20Hitchhikers%20guide%20to%20Wasserstein/A%20Hitchhikers%20guide%20to%20Wasserstein.pdf)
- [f-divergence - Wikiwand](https://www.wikiwand.com/en/F-divergence)

- [ComputationalOT.pdf](https://optimaltransport.github.io/pdf/ComputationalOT.pdf)

- [Duality (optimization) - Wikiwand](https://www.wikiwand.com/en/Duality_(optimization))

- [[1704.00028] Improved Training of Wasserstein GANs](https://arxiv.org/abs/1704.00028)

#### LSGAN

- [[1611.04076] Least Squares Generative Adversarial Networks](https://arxiv.org/abs/1611.04076)




#### Nash equilibrium

- [[1706.08500] GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500)

- [[1705.02894] Geometric GAN](https://arxiv.org/abs/1705.02894)

- [[1708.08819] Coulomb GANs: Provably Optimal Nash Equilibria via Potential Fields](https://arxiv.org/abs/1708.08819)

#### image style transfer

- [NVIDIA/FastPhotoStyle: Style transfer, deep learning, feature transform](https://github.com/NVIDIA/FastPhotoStyle)

#### 2D to 3D

- [Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression](http://aaronsplace.co.uk/papers/jackson2017recon/)
    - [AaronJackson/vrn: Code for "Large Pose 3D Face Reconstruction from a Single Image via Direct Volumetric CNN Regression"](https://github.com/AaronJackson/vrn)


#### sample code

- [tjwei/DIY_AI](https://github.com/tjwei/DIY_AI)

- [tjwei/GANotebooks: wgan, wgan2(improved, gp), infogan, and dcgan implementation in lasagne, keras, pytorch](https://github.com/tjwei/GANotebooks)


## RNN

### State of the art

### Papers

### Articles

- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/)
    - [The unreasonable effectiveness of Character-level Language Models (and why RNNs are still cool) - Jupyter Notebook Viewer](https://nbviewer.jupyter.org/gist/yoavg/d76121dfde2618422139)
    - [The Unreasonable Effectiveness of Recurrent Neural Networks：MachineLearning](https://www.reddit.com/r/MachineLearning/comments/36s673/the_unreasonable_effectiveness_of_recurrent/)

        > > In particular, setting temperature very near zero will give the most likely thing that Paul Graham might say:
        > > 
        > > "is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same thing that was a startup is that they were all the same"
        > > 
        > > looks like we've reached an infinite loop about startups.
        > 
        > Great article, but this part is fundamentally incorrect, and probably the reason the sample is so loopy.
        > 
        > It may be counter-intuitive, but if you pick the most likely next character at every step, you will not necessarily end up with the most likely sequence. In other words, the greedy solution is not necessarily optimal.
        > 
        > Consider:
        > 
        > ```
        > P(00) = 0.4
        > P(01) = 0.0
        > P(10) = 0.3
        > P(11) = 0.3
        > 
        > ```
        > 
        > `1` is the most likely first character, but `00` is the most likely sequence.
        > 
        > Back in college, my differential equations professor had this to say: If you eat as much as you can every single day, you probably won't maximize your total food consumption.


- [Understanding LSTM Networks -- colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

- [LSTM RNN 循环神经网络 (LSTM) - 有趣的机器学习 | 莫烦Python](https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/2-4-LSTM/)

- [(33 条消息)CNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)的内部网络结构有什么区别？ - 知乎](https://www.zhihu.com/question/34681168)

- [遞歸神經網路和長短期記憶模型 RNN & LSTM · 資料科學・機器・人](https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_rnns_lstm_work.html)

- [A Beginner's Guide to Recurrent Networks and LSTMs - Deeplearning4j: Open-source, Distributed Deep Learning for the JVM](https://deeplearning4j.org/lstm.html)

#### Recursive NN

- [用 Recursive Neural Networks 得到分析树 - 简书](https://www.jianshu.com/p/403665b55cd4)

- [Recursive (not Recurrent!) Neural Networks in TensorFlow](https://www.kdnuggets.com/2016/06/recursive-neural-networks-tensorflow.html)

    > In RNNs, at each time step the network takes as input its previous state s(t-1) and its current input x(t) and produces an output y(t) and a new hidden state s(t). TreeNets, on the other hand, don’t have a simple linear structure like that. With RNNs, you can ‘unroll’ the net and think of it as a large feedforward net with inputs x(0), x(1), …, x(T), initial state s(0), and outputs y(0),y(1),…,y(T), with T varying depending on the input data stream, and the weights in each of the cells tied with each other. You can also think of TreeNets by unrolling them – the weights in each branch node are tied with each other, and the weights in each leaf node are tied with each other. The TreeNet illustrated above has different numbers of inputs in the branch nodes. Usually, we just restrict the TreeNet to be a binary tree – each node either has one or two input nodes. There may be different _types_ of branch nodes, but branch nodes of the same type have tied weights.
    > 
    > The advantage of TreeNets is that they can be very powerful in learning hierarchical, tree-like structure.
    > 
    > The disadvantages are, firstly, that the tree structure of every input sample must be known at training time. We will represent the tree structure like this (lisp-like notation):
    >
    > (S (NP that movie) (VP was) (ADJP cool))
    >
    > In each sub-expression, the _type_ of the sub-expression must be given – in this case, we are parsing a sentence, and the type of the sub-expression is simply the part-of-speech (POS) tag.
    >
    > The second disadvantage of TreeNets is that training is hard because the tree structure changes for each training sample and it’s not easy to map training to mini-batches and so on.
    > 
    - [Implementation in TensorFlow - subexpr.py](https://gist.github.com/anj1/504768e05fda49a6e3338e798ae1cddd)


- [machine learning - Recurrent vs Recursive Neural Networks: Which is better for NLP? - Cross Validated](https://stats.stackexchange.com/questions/153599/recurrent-vs-recursive-neural-networks-which-is-better-for-nlp)




### Topics

#### NLP

- [下一步研究目標：盤點NLP領域最具潛力的六大方向 - 幫趣](http://bangqu.com/TTN8wD.html)

- [从文本生成看Seq2Seq模型](https://zhuanlan.zhihu.com/p/29967933)

- [中美两位 AI 大师的“巅峰对话”：为何 NLP 领域难以出现“独角兽”？ | 独家](https://zhuanlan.zhihu.com/p/33970936)

- [deep-learning-with-keras-notebooks/8.0-using-word-embeddings.ipynb at master · erhwenkuo/deep-learning-with-keras-notebooks](https://github.com/erhwenkuo/deep-learning-with-keras-notebooks/blob/master/8.0-using-word-embeddings.ipynb)

- [Understanding Convolutional Neural Networks for NLP – WildML](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)

- [從零開始的 Sequence to Sequence | 雷德麥的藏書閣](https://zake7749.github.io/2017/09/28/Sequence-to-Sequence-tutorial/)

#### Adversiral lstm

- [Recurrent Generative Adversarial Networks?：MachineLearning](https://www.reddit.com/r/MachineLearning/comments/2ttq4g/recurrent_generative_adversarial_networks/)

- [對抗式神經翻譯機 Adversarial Neural Machine Translation | Learning by Hacking](https://data-sci.info/2017/04/30/adversarial-neural-machine-translation/)

#### 英文 word stem 

- [Word stem - Wikiwand](https://www.wikiwand.com/en/Word_stem)
    The stem of the [verb](https://www.wikiwand.com/en/Verb) **wait** is **wait**: it is the part that is common to all its inflected variants.

#### 有毒留言分析

- [rnn_tutorial/toxic_tutorial.ipynb at master · IKMLab/rnn_tutorial](https://github.com/IKMLab/rnn_tutorial/blob/master/toxic_tutorial.ipynb)

#### Word2Vec

- [理解 Word2Vec 之 Skip-Gram 模型](https://zhuanlan.zhihu.com/p/27234078)

- Skip-gram: 給定中間的字來預測上下文
    - [skipgram/Skip-Gram Practice.ipynb at master · IKMLab/skipgram](https://github.com/IKMLab/skipgram/blob/master/Skip-Gram%20Practice.ipynb)

- Con.nuous Bag of Words (CBOW): 給定前後文來預測中間的字


#### 中文斷詞

[中研院 - 中文斷詞系統](http://ckipsvr.iis.sinica.edu.tw/)

#### 情意分析

- [Deep-Learning-MOOC/04-1. 用RNN做情意分析.ipynb at master · yenlung/Deep-Learning-MOOC](https://github.com/yenlung/Deep-Learning-MOOC/blob/master/04-1.%20%E7%94%A8RNN%E5%81%9A%E6%83%85%E6%84%8F%E5%88%86%E6%9E%90.ipynb)

#### 自然語言推論

- [IKMLab/arct: Code for NLITrans at SemEval18 Task12](https://github.com/IKMLab/arct)


#### 無須平行文本之無監督翻譯

- [Notes on Unsupervised Neural Machine Translation](https://zhuanlan.zhihu.com/p/30649985)
    - [《UNSUPERVISED MACHINE TRANSLATION USING MONOLINGUAL CORPORA ONLY》阅读笔记](https://zhuanlan.zhihu.com/p/32375955)
    - [Machine Translation Without the Data – buZZrobot](https://buzzrobot.com/machine-translation-without-the-data-21846fecc4c0)
    - [【Science】無監督式機器翻譯，不需要人類干預和平行文本 - 壹讀](https://read01.com/Rnzx84N.html)
    - [[1711.00043] Unsupervised Machine Translation Using Monolingual Corpora Only](https://arxiv.org/abs/1711.00043)
    - [[1710.11041] Unsupervised Neural Machine Translation](https://arxiv.org/abs/1710.11041)


- [无平行文本照样破解密码，CipherGAN有望提升机器翻译水平](https://zhuanlan.zhihu.com/p/33672256)
    - [[1801.04883] Unsupervised Cipher Cracking Using Discrete GANs](https://arxiv.org/abs/1801.04883)
- [密码学家百年来无法辨认，500年前古怪手稿的加密希伯来语被AI算法破译](https://zhuanlan.zhihu.com/p/34063499)
    - [Decoding Anagrammed Texts Written in an Unknown Language and Script | Hauer | Transactions of the Association for Computational Linguistics](https://transacl.org/ojs/index.php/tacl/article/view/821)

#### 語音合成

##### WaveNet

- [[1712.05884] Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)
    - [谷歌新一代WaveNet ：深度學習怎麼生成語音？ | 2分鐘論文 - 幫趣](http://bangqu.com/3C6864.html)
        在原先Google的WaveNet論文中，我們爲了解決語音合成難題，創造了擴張卷積，這個網絡結構跳躍性地輸入數據，由此使我們我們有了更好的全局視野。這有點像增加我們眼睛的感受野，讓我們能夠感受整個景觀，而不是照片中只有樹的狹窄的視角。
    
        新框架利用梅爾聲譜作爲WaveNet的輸入，這種聲譜是一種基於人類感知的中間媒介，它不僅記錄了不同的單詞如何發音，而且還記錄了預期的音量和語調。

    - [r9y9/wavenet_vocoder: WaveNet vocoder](https://github.com/r9y9/wavenet_vocoder)

- [[1609.03499] WaveNet: A Generative Model for Raw Audio](https://arxiv.org/abs/1609.03499)
    - [(1) WaveNet by Google DeepMind | Two Minute Papers #93 - YouTube](https://www.youtube.com/watch?v=CqFIVCD1WWo)
    - [WaveNet: A Generative Model for Raw Audio | DeepMind](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)
    - [WaveNet launches in the Google Assistant | DeepMind](https://deepmind.com/blog/wavenet-launches-google-assistant/)
    - [DeepMind: WaveNet - A Generative Model for Raw Audio：MachineLearning](https://www.reddit.com/r/MachineLearning/comments/51sr9t/deepmind_wavenet_a_generative_model_for_raw_audio/)
    - [Deepmind 打造語音生成模型 WaveNet，比傳統音檔生成速度快 1000 倍，聲音更擬真？ | TechOrange](https://buzzorange.com/techorange/2017/10/11/deepmind-wavenet-1000-times-faster/)

- [ibab/tensorflow-wavenet: A TensorFlow implementation of DeepMind's WaveNet paper](https://github.com/ibab/tensorflow-wavenet)
- [tomlepaine/fast-wavenet: Speedy Wavenet generation using dynamic programming](https://github.com/tomlepaine/fast-wavenet)
- [buriburisuri/speech-to-text-wavenet: Speech-to-Text-WaveNet : End-to-end sentence level English speech recognition based on DeepMind's WaveNet and tensorflow](https://github.com/buriburisuri/speech-to-text-wavenet)

#### 音樂生成

- [821760408-sp/the-wavenet-pianist: A Wavenet generative model in TensorFlow, trained with Western Classical solo piano canon with global and local conditioning](https://github.com/821760408-sp/the-wavenet-pianist)

- [Can music be generated using generative adversarial networks? - Quora](https://www.quora.com/Can-music-be-generated-using-generative-adversarial-networks)
    > Yes. Just this AAAI, [Sequence Generative Adversarial Nets with Policy Gradient](https://arxiv.org/abs/1609.05473) combines GANs with Policy gradient (reinforcement learning) to generate music.
    > 
    > The remaining answer might be useful/useless for different audience:
    > 
    > However, unlike images where GANs clearly beat RNNs in generation quality IMO, [\[1612.04357\] Stacked Generative Adversarial Networks](https://arxiv.org/abs/1612.04357) vs [openai/pixel-cnn](https://github.com/openai/pixel-cnn) , it appears the other way round in music.
    > 
    > Check out these RNN modifications:
    > 
    > [An Unconditional End-to-End Neural Audio Generation Model](https://arxiv.org/abs/1612.07837)
    > 
    > [soroushmehr/sampleRNN_ICLR2017](https://github.com/soroushmehr/sampleRNN_ICLR2017)
    > 
    > [SampleRNN](https://soundcloud.com/samplernn)
    > 
    > and
    > 
    > [WaveNet: A Generative Model for Raw Audio | DeepMind](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)


- [CodePen - Neural Drum Machine](https://codepen.io/allenyllee/full/ZxGBXP/)
- [CodePen - Deep Roll](https://codepen.io/allenyllee/full/zWGRRg/)

- [Learning to generate lyrics and music with Recurrent Neural Networks](https://warmspringwinds.github.io/pytorch/rnns/2018/01/27/learning-to-generate-lyrics-and-music-with-recurrent-neural-networks/)

- [`pretty_midi` tutorial](https://nbviewer.jupyter.org/github/craffel/pretty-midi/blob/master/Tutorial.ipynb)

- [MusicVAE: Creating a palette for musical scores with machine learning.](https://magenta.tensorflow.org/music-vae)



#### 股價預測

- [lucko515/tesla-stocks-prediction: The implementation of LSTM in TensorFlow used for the stock prediction.](https://github.com/lucko515/tesla-stocks-prediction)




## Reinforcement Learning

### State of the art

### Papers

- [Actor-Critic Algorithms](https://papers.nips.cc/paper/1786-actor-critic-algorithms)
- 

### Articles

- [RL Course by David Silver - Lecture 2: Markov Decision Process - YouTube](https://www.youtube.com/watch?v=lfHX2hHRMVQ&index=2&list=PL7-jPKtc4r78-wCZcQn5IqyuWhBZ8fOxT)
- [强化学习 Reinforcement Learning 教程系列 | 莫烦Python](https://morvanzhou.github.io/tutorials/machine-learning/reinforcement-learning/)
- [106 Fall - ADL x MLDS, NTU](https://www.csie.ntu.edu.tw/~yvchen/f106-adl/syllabus.html)

#### DQN

- [DQN从入门到放弃6 DQN的各种改进 - 知乎](https://zhuanlan.zhihu.com/p/21547911)
- 

### Topics

###### tags: `execrise`
- [Deep RL Bootcamp - Labs](https://sites.google.com/view/deep-rl-bootcamp/labs)

#### 下棋
- [Zeta36/chess-alpha-zero: Chess reinforcement learning by AlphaGo Zero methods.](https://github.com/Zeta36/chess-alpha-zero)

#### System ML

- [SysML Conference](http://www.sysml.cc/)



## Computer Vision

### State of the art

### Papers

#### Action and gesture recognition
- [Learning Adaptive Hidden Layers for Mobile Gesture Recognition
](http://cvlab.citi.sinica.edu.tw/ProjectWeb/AHL/#top)

### Articles

#### CNN 架構比較
- [LeNet、AlexNet、GoogLeNet、VGG、ResNetInception-ResNet-v2、FractalNet、DenseNet - 程序园](http://www.voidcn.com/article/p-rewgmeze-bcq.html)

- [VGGNet | 简说](http://simtalk.cn/2016/09/25/VGGNet/)

- [比ResNet更加有效的網路架構 DenseNet: Densely Connected Convolutional Networks | Learning by Hacking](https://data-sci.info/2017/07/26/%E6%AF%94resnet%E6%9B%B4%E5%8A%A0%E6%9C%89%E6%95%88%E7%9A%84%E7%B6%B2%E8%B7%AF%E6%9E%B6%E6%A7%8B-densenet-densely-connected-convolutional-networks/)

- [adl_1103 - 161103_ConvolutionalNN.pdf](https://www.csie.ntu.edu.tw/~yvchen/f105-adl/doc/161103_ConvolutionalNN.pdf)

### Topics

#### Image matching and alignment

###### tags `SIFT`
- [SIFT特征提取分析 - CSDN博客](http://blog.csdn.net/abcjennifer/article/details/7639681)

###### tags `complementary descriptor`

- [shamangary/DeepCD: [ICCV17] DeepCD: Learning Deep Complementary Descriptors for Patch Representations](https://github.com/shamangary/DeepCD)



#### Image Inpainting

- [基于CNN的图像修复（CNN-based Image Inpainting） - CSDN博客](http://blog.csdn.net/YhL_Leo/article/details/56674833)

#### Image style transfer

###### tags: `Gram matrices`

- [[1701.01036] Demystifying Neural Style Transfer](https://arxiv.org/abs/1701.01036)
    the Gram matrices of feature maps is equivalent to minimize the Maximum Mean Discrepancy (MMD) with the second order polynomial kernel


- [Neural Artistic Style Transfer: A Comprehensive Look](https://medium.com/artists-and-machine-intelligence/neural-artistic-style-transfer-a-comprehensive-look-f54d8649c199)


#### Object Detection

- [COCO - Common Objects in Context](http://cocodataset.org/#detections-leaderboard)

- [[1711.07240] MegDet: A Large Mini-Batch Object Detector](https://arxiv.org/abs/1711.07240)

- [政府在看你，2000萬個攝影機時刻監視，中國最大AI獨角獸商湯：這樣更安全｜產業｜科技｜2018-01-17｜即時｜天下雜誌](https://www.cw.com.tw/article/article.action?id=5087696)

###### tags: `RCNN`
- [Selective Search for Object Recognition](https://ivi.fnwi.uva.nl/isis/publications/bibtexbrowser.php?key=UijlingsIJCV2013&bib=all.bib)
- [【目标检测】RCNN算法详解 - CSDN博客](http://blog.csdn.net/shenxiaolu1984/article/details/51066975)
- [RCNN- 将CNN引入目标检测的开山之作 - 知乎](https://zhuanlan.zhihu.com/p/23006190)
- [CS231n Lecture 8 - Localization and Detection - YouTube](https://www.youtube.com/watch?v=_GfPYLNQank&t=574s)

###### tags: `Fast RCNN`
- [【目标检测】Fast RCNN算法详解 - CSDN博客](http://blog.csdn.net/shenxiaolu1984/article/details/51036677)
- [fast-rcnn - fast-rcnn-slides.pdf](http://www.robots.ox.ac.uk/~tvg/publications/talks/fast-rcnn-slides.pdf)

###### tags: `Faster RCNN`
- [Tutorial: Deep Learning for Objects and Scenes - Part 1 - YouTube](https://www.youtube.com/watch?v=jHv37mKAhV4)
- [目标检测之RCNN，SPP-NET，Fast-RCNN，Faster-RCNN | 冰蓝记录思考的地方](http://lanbing510.info/2017/08/24/RCNN-FastRCNN-FasterRCNN.html)
- [keras版faster-rcnn算法详解（1.RPN计算） - 知乎](https://zhuanlan.zhihu.com/p/28585873)
- [How does the region proposal network (RPN) in Faster R-CNN work? - Quora](https://www.quora.com/How-does-the-region-proposal-network-RPN-in-Faster-R-CNN-work)


###### tags: `YOLO`

- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/)

- [[1506.02640] You Only Look Once: Unified, Real-Time Object Detection](https://arxiv.org/abs/1506.02640)
- [[1612.08242] YOLO9000: Better, Faster, Stronger](https://arxiv.org/abs/1612.08242)

- [YOLO 升級到 v3 版，速度相比 RetinaNet 快 3.8 倍 - 幫趣](http://bangqu.com/zLN4cl.html)


#### Image segmentation

###### tags: `U-Net`

- [[1505.04597] U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
- [[1605.06211] Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1605.06211)


## 新聞

- [深度學習專家很缺嗎？ - EE Times Taiwan 電子工程專輯網](https://www.eettaiwan.com/news/article/20180410NT01-Are-We-Short-of-Deep-Learning-Experts?utm_source=EETT%20Article%20Alert&utm_medium=Email&utm_campaign=2018-04-12)

    > 深度學習「可說是一門跨學科的領域，你不僅要有數學和演算法方面的專家，也需要知道如何在平台上建置軟體的電腦系統專家。然後，我們也會需要熟悉資料管線的專家來調整和管理資料組合。」