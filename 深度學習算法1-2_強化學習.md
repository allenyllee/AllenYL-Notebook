# 深度學習算法1-2_強化學習

[toc]
<!-- toc --> 

# Reinforcement Learning

## Books

### Reinforcement Learning: An Introduction
- [Sutton & Barto Book: Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book-2nd.html)
    - [ShangtongZhang/reinforcement-learning-an-introduction: Python Implementation of Reinforcement Learning: An Introduction](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)

## Articles

### 20篇强化学习论文总结

- [20篇强化学习论文总结 | 机器之心](https://www.jiqizhixin.com/articles/2018-10-23-3)



## Q Learning

- [走近流行強化學習算法：最優Q-Learning - 幫趣](http://bangqu.com/96pyt4.html#utm_source=Facebook_PicSee&utm_medium=Social)



## AlphaGO

- [Tencent/PhoenixGo: Go AI program which implement the AlphaGo Zero paper](https://github.com/Tencent/PhoenixGo)

## papers

### Solving the Rubik's Cube Without Human Knowledge

- [A machine has figured out Rubik’s Cube all by itself - MIT Technology Review](https://www.technologyreview.com/s/611281/a-machine-has-figured-out-rubiks-cube-all-by-itself/)

    - [[1805.07470] Solving the Rubik's Cube Without Human Knowledge](https://arxiv.org/abs/1805.07470)

        > 重點就是反向思考，從最終狀態(已解好的狀態) 慢慢轉亂，每次轉一步，產生一連串未解好的狀態，用這些未解好的狀態送進神經網路，由網路產生目前狀態的 value 跟下一步該採取行動的 policy。一開始這些值由網路隨機初始化決定，下一個狀態的reward 只有1跟-1，只有完成狀態的reward 是1，其他狀態都是-1。
        > 
        > 找出最大化reward + value的policy。這組value 跟 policy 當做訓練target，於是我們有很多訓練target，讓神經網路反覆訓練。如此，雖然只有一個reward，仍然能夠教網路學會朝向最終狀態，解決了Reinforcement Learning 中間狀態缺乏明確獎勵函數的問題。
        > 
        > [name=Ya-Lun Li] 



### Learning Montezuma's Revenge from a Single Demonstration



- [Learning Montezuma's Revenge from a Single Demonstration](https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration/)

    > ![](https://blog.openai.com/content/images/2018/06/montezuma_graphic@2x.png)

    > inspireation: 從結果反推
    > [name=Ya Lun Li]





### [1707.06347] Proximal Policy Optimization Algorithms

- [[1707.06347] Proximal Policy Optimization Algorithms](https://arxiv.org/abs/1707.06347)

- [Proximal Policy Optimization](https://blog.openai.com/openai-baselines-ppo/)

- [A technical deep-dive into Proximal Policy Optimization, a state-of-the-art algorithm for Deep Reinforcement Learning. | Arxiv Insights on Patreon](https://www.patreon.com/posts/technical-deep-21924248?utm_medium=post_notification_email&utm_source=post_link&utm_campaign=patron_engagement)

    <iframe width="560" height="315" src="https://www.youtube.com/embed/5P7I-xPq8u8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

### Learning Synergies between Pushing and Grasping with Self-supervised Deep Reinforcement Learning

- [Learning Synergies between Pushing and Grasping with Self-supervised Deep Reinforcement Learning](http://vpg.cs.princeton.edu/)

    <iframe width="560" height="315" src="https://www.youtube.com/embed/txHQoYKaSUk" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
    
### [1806.00630] DAQN: Deep Auto-encoder and Q-Network

- [[1806.00630] DAQN: Deep Auto-encoder and Q-Network](https://arxiv.org/abs/1806.00630)

### Deep Auto-Encoder Neural Networks in Reinforcement Learning

- [Deep Auto-Encoder Neural Networks in Reinforcement Learning](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.172.1873&rep=rep1&type=pdf)




## 神經生物學

### DeepMind發Nature子刊：通過元強化學習重新理解多巴胺

- [DeepMind發Nature子刊：通過元強化學習重新理解多巴胺 - 幫趣](http://bangqu.com/9T4M59.html)


### DeepMind大突破！AI模擬大腦導航功能，學會像動物一樣「抄近路」

- [DeepMind大突破！AI模擬大腦導航功能，學會像動物一樣「抄近路」 - 幫趣](http://bangqu.com/article/showArt.shtml?id=gV5Vg3&fbclid=IwAR18su0cTilMtod3kx0b3nz43WW1EqoMd4KCFmuXiSvtaTAIpol7Dd3S68E)




## RL 論文復現

- [Lessons Learned Reproducing a Deep Reinforcement Learning Paper](http://amid.fish/reproducing-deep-rl)




