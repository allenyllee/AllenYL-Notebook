# XAI__資料蒐集

## 可解釋性

- [深度学习的可解释性研究（一）—— 让模型具备说人话的能力](https://zhuanlan.zhihu.com/p/37223341)

- [AI.Why: A new architecture for creating AI models with interpretability from scratch (Part 1) | LinkedIn](https://www.linkedin.com/pulse/aiwhy-new-architecture-creating-ai-models-from-part-1-figurelli/?lipi=urn%3Ali%3Apage%3Ad_flagship3_pulse_read%3BgSQgo6WFQ%2Fy6K28sPHjiiA%3D%3D&licu=urn%3Ali%3Acontrol%3Ad_flagship3_pulse_read-related)

## LIME 

- [[1602.04938] "Why Should I Trust You?": Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938)

- [Introduction to Local Interpretable Model-Agnostic Explanations (LIME) - O'Reilly Media](https://www.oreilly.com/learning/introduction-to-local-interpretable-model-agnostic-explanations-lime)

- [凭什么相信你，我的CNN模型？（篇二：万金油LIME)](https://bindog.github.io/blog/2018/02/11/model-explanation-2/)

    > ## 0x01 LIME
    > 
    > [LIME](http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf)是KDD 2016上一篇非常漂亮的论文，思路简洁明了，适用性广，理论上可以解释任何分类器给出的结果。其核心思想是：对一个复杂的分类模型(黑盒)，在**局部**拟合出一个简单的可解释模型，例如线性模型、决策树等等。这样说比较笼统，我们从论文中的一张示例图来解释：
    > 
    > ![LIME](http://lc-cf2bfs1v.cn-n1.lcfile.com/f4682022fc64aa470120.png)
    > 
    > 如图所示，红色和蓝色区域表示一个复杂的分类模型（黑盒），图中加粗的红色十字表示需要解释的样本，显然，我们很难从全局用一个可解释的模型（例如线性模型）去逼近拟合它。但是，当我们把关注点从全局放到局部时，可以看到在某些局部是可以用线性模型去拟合的。具体来说，我们从加粗的红色十字样本周围采样，所谓采样就是对原始样本的特征做一些扰动，将采样出的样本用分类模型分类并得到结果（红十字和蓝色点），同时根据采样样本与加粗红十字的距离赋予权重（权重以标志的大小表示）。虚线表示通过这些采样样本学到的局部可解释模型，在这个例子中就是一个简单的线性分类器。在此基础上，我们就可以依据这个局部的可解释模型对这个分类结果进行解释了。
    > 
    > 一个看似复杂的模型通过我们巧妙的转换，就能够从局部上得到一个让人类理解的解释模型，光这样说还是显得有些空洞，具体来看看LIME在图像识别上的应用。我们希望LIME最好能生成和Grad-CAM一样的热力图解释。但是由于LIME不介入模型的内部，需要不断的扰动样本特征，这里所谓的样本特征就是指图片中一个一个的像素了。仔细一想就知道存在一个问题，LIME采样的特征空间太大的话，效率会非常低，而一张普通图片的像素少说也有上万个。若直接把每个像素视为一个特征，采样的空间过于庞大，严重影响效率；如果少采样一些，最终效果又会比较差。
    > 
    > 所以针对图像任务使用LIME时还需要一些特别的技巧，也就是考虑图像的空间相关和连续的特性。不考虑一些极小特例的情况下，图片中的物体一般都是由一个或几个连续的像素块构成，所谓像素块是指具有相似纹理、颜色、亮度等特征的相邻像素构成的有一定视觉意义的不规则像素块，我们称之为**超像素**。相应的，将图片分割成一个个超像素的算法称为**超像素分割算法**，比较典型的有SLIC超像素分割算法还有quickshit等，这些算法在`scikit-image`库中都已经实现好了，quickshit分割后如图所示：
    > 
    > ![mm](http://lc-cf2bfs1v.cn-n1.lcfile.com/e343bec75b31b7bbcd33.png)
    > 
    > 从特征的角度考虑，实际上就不再以单个像素为特征，而是以超像素为特征，整个图片的特征空间就小了很多，采样的过程也变的简单了许多。更具体的说，图像上的采样过程就是随机保留一部分超像素，隐藏另一部分超像素，如下所示：
    > 
    > ![light](http://lc-cf2bfs1v.cn-n1.lcfile.com/85a16c0af003b1dfe4d8.png)
    > 
    > 从图中可以很直观的看出这么做的意义：找出对分类结果影响最大的几个超像素，也就是说模型仅通过这几个像素块就已经能够自信的做出预测。这里还涉及到一个特征选择的问题，毕竟我们不可能穷举特征空间所有可能的样本，所以需要在有限个样本中找出那些关键的超像素块。虽然这部分没有在论文中过多提及，但在LIME的[代码实现](https://github.com/marcotcr/lime)中是一个重要部分，实现了前向搜索（forward selection）、Lasso和岭回归（ridge regression）等特征选择方式，默认当特征数小于等于6时采用前向搜索，其他情况采用岭回归。
    > 
    > 整体流程如图所示：
    > 
    > ![flow](http://lc-cf2bfs1v.cn-n1.lcfile.com/7f5f62a0ab431169c75d.png)
    > 
    > 和Grad-CAM一样，LIME同样可以对其他可能的分类结果进行解释。
    > 
    > ![effect](http://lc-cf2bfs1v.cn-n1.lcfile.com/6bb64a832e2cce97dc39.png)
    > 
    > LIME除了能够对图像的分类结果进行解释外，还可以应用到自然语言处理的相关任务中，如主题分类、词性标注等。因为LIME本身的出发点就是模型无关的，具有广泛的适用性。
    > 
    > 虽然LIME方法虽然有着很强的通用性，效果也挺好，但是在速度上却远远不如Grad-CAM那些方法来的快。当然这也是可以理解的，毕竟LIME在采样完成后，每张采样出来的图片都要通过原模型预测一次结果。
    > 
    > 说来也巧，在写这篇文章的时候，AAAI 2018的论文放出来了，其中有LIME作者的最新研究成果[Anchors](http://sameersingh.org/files/papers/anchors-aaai18.pdf)，顺道去了解了一下。Anchors指的是复杂模型在局部所呈现出来的很强的规则性的规律，注意和LIME的区别，LIME是在局部建立一个可理解的线性可分模型，而Anchors的目的是建立一套更精细的规则系统。不过看过论文以后感觉更多是在和文本相关的任务上有不错的表现，在图像相关的任务上并没有什么特别另人耳目一新的东西，只是说明了在Anchor（图像中指若干个超像素）固定的情况下，其他像素无论替换为什么，现有的模型都会罔顾人类常识，自信的做出错误判断。这部分内容由于前几年看多了Adversarial Samples，已经见怪不怪了。
    > 
    > ## 0x02 小结
    > 
    > 实际上在模型可解释性这块还有其他很多相关研究，包括最近的AAAI 2018上也有几篇这方面的文章，如[Beyond Sparsity: Tree Regularization of Deep Models for Interpretability](https://arxiv.org/abs/1711.06178)，这都在一定程度上说明，业内还是重视这个方向的。尤其在涉及到医疗、自动驾驶等人命关天的应用场合，可解释性显得尤为重要，最后也希望更多感兴趣的同学加入到这个行列来~
    > 


## PLNN

- [裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡 - 幫趣](http://bangqu.com/HqmsS6.html#utm_source=Facebook_PicSee&utm_medium=Social)

    > 這篇論文研究了以**分段線性函數**爲激活函數的**分段線性神經網絡（Piecewise Linear Neural Network， PLNN）**。分段線性函數在不同的定義域區間內對應不同的線性函數。經典的 MaxOut 、ReLU 以及 ReLU 的一些變體都是分段線性函數。從微分學的角度來看，只要分段數目足夠多，連續光滑的 sigmoid 、tanh 等激活函數也都可以用分段線性函數來無限逼近。
    > 
    > 與現有的規範做法一樣，**該論文通過求解一個分段線性神經網絡 *N* 的決策特徵來解釋 *N* 的決策行爲。但與現有方法大爲不同的是，論文對 *N* 的解釋具有如下兩個獨特的優點**：
    > 
    > 1\. **準確性（Exactness）**：該論文構造了一個具有簡潔**解析形式**的新模型 *M* ，並證明了 *M* 和 *N* 在數學上等價。因此，*M* 的決策特徵能夠**準確**描述 *N* 的真實決策行爲。
    > 
    > 2\. **一致性（Consistency）**：該論文證明了 *M* 是一個分段線性函數，並以**解析形式**給出了 *M* 在其定義域中的各個分段區間，以及 *M* 在每個區間上的線性決策函數。因爲在相同分段區間中的所有輸入實例共享同一個線性決策函數的決策特徵，所以由模型 *M* 對這些輸入實例所提供的解釋是**完全一致**的。
    > 
    > ### OpenBox - 通向準確性和一致性的金鑰匙
    > 
    > 該論文的作者們提出了全新的 OpenBox 方法對分段線性神經網絡（PLNN）的決策行爲提供準確、一致的解釋。「OpenBox」 這個名字也很貼切地描述了作者們使用簡潔的解析方法「打開」深度神經網絡這個「黑盒子」的過程。
    > 
    > OpenBox 方法適用於所有 PLNN。本文將用以 PReLU 爲激活函數的 PLNN 爲例子詳細介紹 OpenBox 方法的技術要點。
    > 
    > **1\. 對單個輸入實例的準確解釋方法**
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b306184692f5.jpg)
    > 
    > ##### 圖 2：隱層神經元的激活狀態（status）
    > 
    > 如圖 2 所示，對於以 PReLU 爲激活函數的隱層神經元，其**激活狀態（status）**分爲兩種情況：（1）當 status = 0 時，*z* < 0，該神經元使用左半段的線性函數來建立輸入 *z* 和輸出 *a* 之間的映射關係；（2）當 status = 1 時，*z* >= 0，該神經元使用右半段的線性函數來建立 *z* 到 *a* 的映射。**值得注意的是，不論神經元處於何種激活狀態，*z* 和 *a* 之間的映射關係始終是線性的**。
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b3062540b557.jpg)
    > 
    > ##### 圖 3：一個 PLNN 和其隱層神經元的激活狀態
    > 
    > 如圖 3 所示，給定一個輸入實例 *x* ，我們可以將所有隱層神經元的激活狀態按綠色虛線所示的順序排列成一個向量 Conf(*x*)。這個向量被稱作 PLNN 對輸入實例 *x* 的**配置（Configuration）**。
    > 
    > 由於 PLNN 的網絡結構和參數都是給定的，所有神經元的激活狀態都唯一依賴於輸入實例 *x*，因此 Conf(*x*) 由輸入實例 *x* 唯一決定。因爲 *x* 本身是一個給定的常量，所以 Conf(*x*) 也是一個常量。因此，圖 3 中 PLNN 的每個隱層神經元的運算實質上都是由常量 Conf(*x*) 所確定的線性運算。因爲一系列線性運算的嵌套依然是線性運算，**所以在 Conf(*x*) 爲常量的情況下，PLNN 中所有隱藏層的運算整體等價於一個簡單的線性運算 *Wx+b***。
    > 
    > **綜上所述，對於任意給定的輸入實例 *x*，整個 PLNN 嚴格等價於如公式 1 所示的線性分類器。其中，二元組 (*W*, *b*) 以解析形式準確地給出了該 PLNN 對於輸入實例 x 的決策平面。**（注：證明及求解過程請參見原文）
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b306575eaffa.jpg)
    > 
    > ##### 公式 1
    > 
    > 顯然，解釋 PLNN 在單個輸入實例上的決策行爲並不能很好地解釋 PLNN 的總體行爲。下面我們將介紹 OpenBox 如何解釋 PLNN 的總體行爲。
    > 
    > **2\. 對一個分段線性神經網絡的準確、一致解釋方法**
    > 
    > 作者們發現，在 PLNN 的網絡結構和參數給定的情況下，公式 1 中的線性分類器 *F(x)* 由 Conf(*x*) 決定。**這意味着對於任意兩個不同的輸入實例 *x* 和 *x'* 而言，只要 Conf(*x*)＝Conf(*x'*)，*x* 和 *x'* 就共享同一個線性分類器，而且對 *x* 和 *x'* 的解釋也將完全一致**。
    > 
    > 那麼，輸入實例 *x* 和 *x'* 需要滿足什麼條件，才能使 Conf(*x*)＝Conf(*x'*) 呢？ 
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b3065f3c1251.jpg)
    > 
    > ##### 圖 4：在 Conf(*x*) 給定的情況下，每一個隱層神經元的輸入 *z* 所必須滿足的不等式約束
    > 
    > 通過進一步推導，作者們發現在 Conf(*x*) 給定的情況下，每一個隱層神經元的輸入 *z* 都必須滿足由該神經元激活狀態所決定的不等式約束。圖 4 給出了當 Conf(x) = [1, 0, 1, 0, 0, 1, 1] 時， PLNN 的所有隱層神經元的輸入 z 必須滿足的一組**線性不等式約束**。
    > 
    > 因爲每個隱層神經元的輸入 *z* 都是輸入實例 *x* 的線性函數，所以這組關於輸入 *z* 的線性不等式約束實質上是對輸入實例 *x* 的一組線性不等式約束。我們將這組線性不等式約束的集合定義爲 *P*。
    > 
    > **很顯然，所有滿足 *P* 中線性不等式約束的輸入實例 *x* 都具有相同的 Conf(*x*)，因此這些實例共享同一個線性分類器，並具有完全一致的解釋。**
    > 
    > 實質上，*P* 中的每一個不等式都定義了一個線性邊界，所有線性邊界一起組成了一個**凸多面體（Convex Polytope，CP）**。在凸多面體中的所有輸入實例都滿足 *P* 中的所有不等式，因此這些輸入實例 *x* 都具有相同的 Conf(*x*)，並且共享同一個線性分類器。我們把這個存在於局部區域的凸多面體和它所對應的線性分類器統稱爲**局部線性分類器（Local Linear Classifier，LLC）**。
    > 
    > **對於任意給定的 PLNN，不同的隱層神經元激活狀態對應着不同的 Conf(*x*)，而每一個 Conf(*x*) 都確定了一個局部線性分類器。因此，一個 PLNN 嚴格等價於一組局部線性分類器。我們把這組局部線性分類器的集合標記爲 *M*，並將其作爲 PLNN 的解釋模型。**
    > 
    > **因爲 *M* 和 PLNN 是等價的，而且同一個凸多面體中的所有實例都共享同樣的解釋，所以由 *M* 所得到的解釋是準確且一致的。**
    > 
    > 給定一個輸入實例 *x*，我們如何使用 *M* 來解釋 PLNN 對 *x* 的決策行爲呢？
    > 
    > 首先，我們從 *M* 中找到 *x* 所屬的局部線性分類器。然後，我們解析出該局部線性分類器的**決策特徵（Decision Feature）**以及其凸多面體的**邊界特徵（Polytope Boundary Feature，PBF）**。最後，我們使用決策特徵來解釋 PLNN 對 *x* 的決策行爲，並使用邊界特徵來解釋 *x* 被當前局部線性分類器包含的原因。
    > 
    > 論文還對計算 *M* 的時間複雜度進行了嚴格的理論分析和證明。**對於 *n* 個不同的輸入實例，若每個輸入實例的特徵維數爲 *d*，OpenBox 解釋所有輸入實例的時間複雜度僅爲 O(*nd*)。因爲特徵維數 *d* 通常被看作常量，所以 OpenBox 的時間複雜度是線性的。**
    > 
    > ### 實驗部分
    > 
    > 作者們把 OpenBox 和目前最頂級的解釋方法 LIME［Ribeiro *et al*. KDD 2016］做了實驗對比。實驗重點關注以下五個問題：
    > 
    > 1\. 局部線性分類器長什麼樣？
    > 
    > 2\. LIME 和 OpenBox 給出的解釋是否準確、一致？
    > 
    > 3\. 局部線性分類器的決策特徵易於理解嗎？如果附加非負、稀疏約束，能繼續提升這些決策特徵的語義特性嗎？
    > 
    > 4\. 如何解釋局部線性分類器的邊界特徵（PBF）？
    > 
    > 5\. 利用 OpenBox 提供的解釋，我們能否構造新樣本來欺騙 PLNN？能否查出 PLNN 在某些樣本上做出錯誤決策的原因？
    > 
    > **實驗一：合成數據集可視化局部線性分類器**
    > 
    > 如圖 5(a) 所示，作者們通過二維歐式空間中的均勻採樣生成了一個包含 20,000 個實例的合成數據集 SYN。其中，紅色和藍色樣本點分別代表正例和負例。
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b307e27943ca.jpg)
    > 
    > 圖 5：OpenBox 在合成數據集 SYN 上的實驗結果
    > 
    > 由於實驗目標是可視化模型 *M* 中的所有局部線性分類器，整個實驗過程無需使用測試數據，因此作者們使用 SYN 中的所有樣本來訓練 PLNN。圖 5(b) 顯示了 PLNN 在 SYN 上的預測結果。
    > 
    > 圖 5(c) 可視化了模型 *M* 中每一個局部線性分類器對應的凸多面體。 作者們用相同的顏色標出了屬於同一個局部線性分類器的所有實例，發現屬於相同局部線性分類器的實例都包含於同一個凸多面體（在二維空間中表現爲凸多邊形）。顯然，這個結果完全符合論文的理論分析。
    > 
    > 圖 5(d) 展示了構成模型 *M* 的決策邊界的所有局部線性分類器。圖中的每一條實線都表示一個局部線性分類器的決策邊界，這些局部線性分類器共同構成了模型 *M* 的總體決策邊界。對比圖 5(b) 和 5(d) 可以發現模型 *M* 的總體決策邊界和 PLNN 的決策邊界完全一致。這個結果證實了模型 *M* 和 PLNN 之間的等價性。
    > 
    > **實驗二：FMNIST 數據集驗證解釋的準確性和一致性**
    > 
    > 該實驗在 FMNIST 數據集上對比了 LIME 和 OpenBox（模型M）所提供解釋的準確性和一致性。
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b307e430525a.jpg)
    > 
    > ##### 圖 6: OpenBox 和 LIME 在 FMNIST-2 數據集上的準確性（Exactness）和一致性（Consistency）
    > 
    > 首先，作者們通過比較 LIME、OpenBox（模型 *M*）和 PLNN 對 FMNIST-2 數據集中 600 個測試樣本的決策輸出來衡量 LIME 和 OpenBox 各自解釋模型的準確性。如圖 6(a) 所示，LIME 的決策輸出和 PLNN 的決策輸出有着很大不同，這說明 LIME 的解釋模型和 PLNN 非常不同，因此它無法準確解釋 PLNN 的決策行爲。相比之下，OpenBox 計算出的模型 *M* 和 PLNN 對於所有測試樣本的決策輸出完全相同，這說明模型 M 等價於 PLNN，因此它能夠準確地解釋 PLNN 的決策行爲。
    > 
    > 隨後，作者們使用輸入實例 *x* 和其最近鄰實例 *x'* 的解釋結果的餘弦相似度（Cosine Similarity）來衡量 LIME 和 OpenBox 所提供解釋的一致性。餘弦相似度越高，解釋模型所提供解釋的一致性就越高。如圖 6(b) 所示，由於模型 *M* 對同一凸多面體內的實例提供完全相同的解釋，OpenBox 的餘弦相似度幾乎總保持爲 1。但是最近鄰實例 *x'* 與 輸入實例 *x*  並不總是屬於同一個凸多面體，因此 OpenBox 在某些實例上的餘弦相似度小於 1。相比之下，LIME 的餘弦相似度遠低於 OpenBox，這說明 OpenBox 所提供解釋的一致性遠高於 LIME。
    > 
    > **實驗三：OpenBox 提取的決策特徵具有人類可理解的強語義特點**
    > 
    > 除了準確性和一致性，一個好的解釋還必須具有人類可理解的強語義特點。在本實驗中，作者們將 OpenBox 在 FMNIST-1 數據集上提取的決策特徵可視化，發現這些特徵具有易於理解的強語義特點。
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b306b12f3205.jpg)
    > 
    > 圖 7: OpenBox 和邏輯迴歸（Logistic Regression，LR）在 FMNIST-1 數據集上的決策特徵（Decision Feature，DF）
    > 
    > 圖 7(a) 和 7(f) 給出了 FMNIST-1 中的兩類圖像的平均圖（Average Image）。其中，圖 7(a) 對應正例樣本**短靴（Ankle Boot）**，圖 7(f) 對應負例樣本**包包（Bag）**。
    > 
    > 作者們訓練了多個羅輯迴歸模型（Logistic Regression，LR）作爲基線（Baseline）。其中，LR 模型是以短靴爲正樣本訓練得到的，LR-F 模型是以包包爲正樣本訓練得到的，LR-NS 和 LR-NSF 分別是在 LR 和 LR-F 的基礎上附加稀疏、非負約束得到的。此外，作者們還訓練了兩個 PLNN 模型作爲 OpenBox 的解釋對象。其中，PLNN 是以短靴爲正樣本訓練得到的，PLNN-NS 是在 PLNN 的基礎上附加稀疏、非負約束得到的。
    > 
    > 圖 7 給出了上述所有模型的決策特徵，其中 PLNN 和 PLNN-NS 的決策特徵由 OpenBox 提供。很明顯，PLNN 的決策特徵與 LR 和LR-F 的決策特徵具有極爲相似語義。將這些決策特徵與圖 7(a) 和 7(f) 中的平均圖仔細對比可以發現，這些決策特徵準確地描述了短靴和包包之間的差別。更有趣的是，PLNN 的決策特徵比 LR 和 LR-F 的決策特徵包含了更多細節信息。這是因爲 PLNN 的每一個局部線性分類器僅需區分包含於凸多面體中的一小部分樣本，所以 PLNN 能夠使用大量的局部線性分類器捕捉更多細節特徵。然而，LR 和 LR-F 只能使用一個線性平面劃分所有正負例樣本，因此它們只能捕捉大量樣本的平均差異。因爲 PLNN 捕捉到了更多細節特徵，所以它取得了比 LR 和 LR-F 好得多的分類精度。
    > 
    > 通過對比 PLNN-NS，LR-NS 和 LR-NSF 的決策特徵，我們發現非負、稀疏約束對於增強 PLNN-NS 決策特徵的語義同樣有效。我們還觀察到 PLNN-NS 捕獲了比 LR-NS 和 LR-NSF 多得多的細節特徵，也因此取得了相對較高的分類精度。
    > 
    > **實驗四：OpenBox 提取的邊界特徵也具有很強的語義特性**
    > 
    > 關於 OpenBox 所提取的局部線性分類器，不僅其決策特徵具有很強的語義特點，其凸多面體的邊界特徵也具有很強的語義特性。
    > 
    > ![裴健團隊KDD新作：革命性的新方法，準確、一致地解釋深度神經網絡](http://i2.bangqu.com/lf1/news/20180629/5b306b8ccf418.jpg)
    > 
    > ##### 圖 8: OpenBox 在 FMNIST-1 數據集上提取的邊界特徵（Polytope Boundary Feature，PBF）
    > 
    > 在本實驗中，作者們在 FMNIST-1 上訓練了一個 PLNN，並用 OpenBox 解析出該 PLNN 的三個局部線性分類器對應的凸多面體。圖 8(a)-(d) 給出了這些凸多面體的邊界特徵，它們分別對應了｛包包，短靴，包包，包包｝。圖 8(e) 給出了定義這些邊界特徵的線性不等式，以及其對應的凸多面體中所包含的各類別樣本數量。關於圖 8(e) 中的線性不等式，「／」代表該不等式定義的邊界爲無效邊界；「> 0」代表凸多面體內的樣本與該不等式的邊界特徵具有很強的相關性；「<= 0」 代表凸多面體內的樣本與該不等式的邊界特徵沒有強相關性。
    > 
    > 以圖 8(e) 中的第一個凸多面體爲例，由其線性不等式的狀態可知該凸多面體所包含的樣本與圖 8(b)-(c) 中短靴和包包的邊界特徵有強相關性。因此，第一個凸多面體中包含了大量的短靴和包包。類似的，對圖 8(e) 中的第二個凸多面體而言，其中的樣本僅與短靴的邊界特徵呈正相關，因此該凸多面體中的樣本僅有短靴而沒有包包。通過上述實驗結果不難看出，**OpenBox 提取的邊界特徵具有很強的語義特性**。
    > 
    > 除了上述精彩實驗，作者們還利用 OpenBox 提供的解釋來構造欺騙 PLNN 的新樣本，以及查找 PLNN 在某些樣本上做出錯誤決策的原因。在這些有趣的任務上，論文中的實驗也給出了明顯優於現有方法的結果。
    > 
    > ### 結論
    > 
    > 作者們通過證明分段線性神經網絡嚴格等價於一組局部線性分類器，以簡潔的解析形式給出了一種準確、一致且高效的神經網絡解釋方法------OpenBox。大量實驗結果表明，OpenBox 不僅可以準確、一致地描述分段線性神經網絡的總體行爲，還能夠對分段線性神經網絡進行有效的欺騙攻擊和錯誤查找。作者們談到，他們將繼續拓展這一方法，使其能夠有效地解釋使用連續、光滑激活函數（如：sigmoid、tanh）的深度神經網絡。
    > 
    > 詳細內容請參見原論文：<https://arxiv.org/abs/1802.06259>
