# NLP__資料收集1-1

[toc]
<!-- toc --> 


# 資料集

## 康乃爾NLP

- [Cornell NLP :: Data](http://nlp.cornell.edu/data/)

## SemEval-2018 語意理解任務資料集

- [Tasks < SemEval-2018](http://alt.qcri.org/semeval2018/index.php?id=tasks)

## DART: a Dataset of Arguments and their Relations on Twitter

- [DART: a Dataset of Arguments and their Relations on Twitter - Semantic Scholar](https://www.semanticscholar.org/paper/DART%3A-a-Dataset-of-Arguments-and-their-Relations-on-Bosc-Cabrio/9b71b307a2f99fb404c6f6159b146547a0dc1cbc)



# Reference




## 我爱自然语言处理

- [自然语言处理 | 我爱自然语言处理](http://www.52nlp.cn/category/nlp)

## eisenstein nlp notes

- [gt-nlp-class/notes at master · jacobeisenstein/gt-nlp-class](https://github.com/jacobeisenstein/gt-nlp-class/tree/master/notes)


## Text Classification using Neural Networks

- [Text Classification using Neural Networks – Machine Learnings](https://machinelearnings.co/text-classification-using-neural-networks-f5cd7b8765c6)

## Supervised Sequence Labelling

- [Supervised Sequence Labelling | SpringerLink](https://link.springer.com/chapter/10.1007/978-3-642-24797-2_2)

## Deep Learning for Natural Language Processing

- [Deep Learning For Natural Language Processing](https://machinelearningmastery.com/deep-learning-for-nlp/)

## google word2vec 小遊戲 Semantris

- [讓你看見 AI 自然語言處理多強大！Google 發表一款搜尋引擎和兩個文字遊戲 - INSIDE 硬塞的網路趨勢觀察](https://www.inside.com.tw/2018/04/16/google-introducing-semantic-experiences-with-talk-to-book)

    - [Semantris](https://research.google.com/semantris/)


## How to get started in NLP – Towards Data Science

- [How to get started in NLP – Towards Data Science](https://towardsdatascience.com/how-to-get-started-in-nlp-6a62aa4eaeff)

## 如何学习自然语言处理：一本书和一门课 | 我爱自然语言处理

- [如何学习自然语言处理：一本书和一门课 | 我爱自然语言处理](http://www.52nlp.cn/%e5%a6%82%e4%bd%95%e5%ad%a6%e4%b9%a0%e8%87%aa%e7%84%b6%e8%af%ad%e8%a8%80%e5%a4%84%e7%90%86%e4%b8%80%e6%9c%ac%e4%b9%a6%e5%92%8c%e4%b8%80%e9%97%a8%e8%af%be/comment-page-1#comment-280074)

## NLP應該如何學、如何教？斯坦福大學大牛Dan Jurafsky教授專訪

- [NLP應該如何學、如何教？斯坦福大學大牛Dan Jurafsky教授專訪 - 幫趣](http://bangqu.com/9J773U.html)

    - [NLP Pedagogy Interview: Dan Jurafsky (Stanford) – David Jurgens – Medium](https://medium.com/@jurgens_24580/nlp-pedagogy-interview-dan-jurafsky-stanford-c0075a16d877)

## ML Resources

- [ML Resources](https://sgfin.github.io/learning-resources/?fbclid=IwAR2IDjRWme3pbZCsFN6uQ2lM67XCK5_SvX4G6JdMZiDROf978zkvWUmMQvU)




# Course

## NLP 入門路線

參考修課順序

- [CS 124 - Edusalsa: From Languages to Information (LINGUIST 180, LINGUIST 280)](https://edusalsa.com/course?c=CS%20124)





### CS124 - From Languages to Information (Winter 2017)

- [CS124 - From Languages to Information (Winter 2017)](http://web.stanford.edu/class/cs124/) (no video)

    #### Or

- [[Coursera] Natural Language Processing (Stanford University) (nlp) - Academic Torrents](http://academictorrents.com/details/d2c8f8f1651740520b7dfab23438d89bc8c0c0ab) (video and slide)

    ##### next --> 

### CS224n: Natural Language Processing with Deep Learning

- [CS224n: Natural Language Processing with Deep Learning](http://web.stanford.edu/class/cs224n/index.html) 

- *video* [CS224N - YouTube](https://www.youtube.com/playlist?list=PLqdrfNEc5QnuV9RwUAhoJcoQvu4Q46Lja)

### CS224U: Natural Language Understanding - Spring 2018

- [CS224U: Natural Language Understanding - Spring 2018](http://web.stanford.edu/class/cs224u/)

- *video* [CS224u - YouTube](https://www.youtube.com/playlist?list=PLfmUaIBTH8exY7fZnJss508Bp8k1R8ASG)

### CS224S / LINGUIST285 - Spoken Language Processing (Spring 2017)

- [CS224S / LINGUIST285 - Spoken Language Processing (Spring 2017)](http://web.stanford.edu/class/cs224s/)

### CS 276: Information Retrieval and Web Search

- [CS 276: Information Retrieval and Web Search](http://web.stanford.edu/class/cs276/)




## Textbook

### Dan Jurafsky and James H. Martin, Speech and Language Processing
- [Speech and Language Processing](https://web.stanford.edu/~jurafsky/slp3/)



# Tutorial

## CNN也能用于NLP任务，一文简述文本分类任务的7个模型

- [CNN也能用于NLP任务，一文简述文本分类任务的7个模型](https://zhuanlan.zhihu.com/p/39054002)


# Tools

## NLPIR

- [推荐NLPIR大数据语义智能分析平台 | 我爱自然语言处理](http://www.52nlp.cn/%e6%8e%a8%e8%8d%90nlpir%e5%a4%a7%e6%95%b0%e6%8d%ae%e8%af%ad%e4%b9%89%e6%99%ba%e8%83%bd%e5%88%86%e6%9e%90%e5%b9%b3%e5%8f%b0)

    - [NLPIR/NLPIR-Parser at master · NLPIR-team/NLPIR](https://github.com/NLPIR-team/NLPIR/tree/master/NLPIR-Parser)

    > 1、精准采集：对境内外互联网海量信息实时精准采集，有主题采集（按照信息需求的主题采集）与站点采集两种模式（给定网址列表的站内定点采集功能）。
    > 
    > 2、文档抽取：对doc、excel、pdf与ppt等多种主流文档格式，进行文本信息抽取，信息抽取准确，效率达到大数据处理的要求。
    > 
    > 3、新词发现：从文本中挖掘出新词、新概念，用户可以用于专业词典的编撰，还可以进一步编辑标注，导入分词词典中，提高分词系统的准确度，并适应新的语言变化。
    > 
    > 4、批量分词：对原始语料进行分词，自动识别人名地名机构名等未登录词，新词标注以及词性标注。并可在分析过程中，导入用户定义的词典。
    > 
    > 5、语言统计：针对切分标注结果，系统可以自动地进行一元词频统计、二元词语转移概率统计。针对常用的术语，会自动给出相应的英文解释。
    > 
    > 6、文本聚类：能够从大规模数据中自动分析出热点事件，并提供事件话题的关键特征描述。同时适用于长文本和短信、微博等短文本的热点分析。
    > 
    > 7、文本分类：根据规则或训练的方法对大量文本进行分类，可用于新闻分类、简历分类、邮件分类、办公文档分类、区域分类等诸多方面。
    > 
    > 8、摘要实体：对单篇或多篇文章，自动提炼出内容摘要，抽取人名、地名、机构名、时间及主题关键词；方便用户快速浏览文本内容。
    > 
    > 9、智能过滤：对文本内容的语义智能过滤审查，内置国内最全词库，智能识别多种变种：形变、音变、繁简等多种变形，语义精准排歧。
    > 
    > 10、情感分析：针对事先指定的分析对象，系统自动分析海量文档的情感倾向：情感极性及情感值测量，并在原文中给出正负面的得分和句子样例。
    > 
    > 11、文档去重：快速准确地判断文件集合或数据库中是否存在相同或相似内容的记录，同时找出所有的重复记录。
    > 
    > 12、全文检索：支持文本、数字、日期、字符串等各种数据类型，多字段的高效搜索，支持AND/OR/NOT以及NEAR邻近等查询语法，支持维语、藏语、蒙语、阿拉伯、韩语等多种少数民族语言的检索。
    > 
    > 13、编码转换：自动识别内容的编码，并把编码统一转换为其他编码。
    > 

## CytonMT: an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++

- [arthurxlw/cytonMt: CytonMT: an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++](https://github.com/arthurxlw/cytonMt)

- [[1802.07170] CytonMT: an Efficient Neural Machine Translation Open-source Toolkit Implemented in C++](https://arxiv.org/abs/1802.07170)

    > This paper presents an open-source neural machine translation toolkit named CytonMT (this https URL). The toolkit is built from scratch only using C++ and NVIDIA's GPU-accelerated libraries. The toolkit features training efficiency, code simplicity and translation quality. Benchmarks show that CytonMT accelerates the training speed by 64.5% to 110.8% on neural networks of various sizes, and achieves competitive translation quality. 

## AllenNLP - Demo

- [AllenNLP - Demo](https://demo.allennlp.org/machine-comprehension)

## Stanford corenlp

- [Stanford corenlp](http://corenlp.run/)

## Stanford parser

- [Stanford Parser](http://nlp.stanford.edu:8080/parser/index.jsp)

## 哈工大 LTP

- [语言技术平台（ Language Technology Plantform | LTP ）](http://ltp.ai/demo.html)

- [HIT-SCIR/ltp: Language Technology Platform](https://github.com/HIT-SCIR/ltp)





# 相關新聞

## 寫稿機器人

- [百度AI开放平台-全球领先的人工智能服务平台](https://ai.baidu.com/support/news?action=detail&id=140)

- [只好跟著抄了！PTT 創世神的 AI Labs 為「記者快抄」打造寫稿機器人 | TechNews 科技新報](http://technews.tw/2017/08/09/ai-labs-is-using-ai-to-cover-ptt-news/)

## 語音助理

- [個人語音助理時代已經來臨！ - EE Times Taiwan 電子工程專輯網](https://www.eettaiwan.com/news/article/20180416NT31-season-voice-based-personal-assistants?utm_source=EETT%20Article%20Alert&utm_medium=Email&utm_campaign=2018-04-17)

    > 過程和原理
    > 
    > 作為一名開發者和設計師，要充份使用這項技術，重要的是瞭解如下的完整命令互動過程：
    > 
    > * 虛擬助理使用一個觸發詞(如‘Ok Google’、‘Hey Siri’)來「喚醒」，以確保它只在命令下達時才執行。
    > * 音訊被記錄在設備上，經過壓縮並透過Wi-Fi傳輸到雲端。通常會採用降噪演算法來記錄音訊，以便雲端「大腦」更容易理解用戶的命令。
    > * 使用專有的「語音轉文本」(voice-to-text)平台將音訊轉換成文本命令。透過指定的頻率對類比訊號進行採樣，將類比聲波轉換為數位資料。分析數位資料以確定英語音素(‘bb’、‘oo’、‘sh’等)的出現位置。 一旦辨識別出音素，就使用統計建模演算法(如Hidden Markhov模型)來確定特定單詞的可能性。
    > * 使用自然語言處理技術來處理文本以確定所需的操作。 該演算法首先使用詞性標註來確定哪些詞是形容詞、動詞和名詞等，然後將這種標記與統計機器學習模型相結合起來，推斷句子的含義。
    > * 如果命令操作需要進一步的搜尋，系統將立即進行搜尋。例如，「嘿！Siri，什麼是Snapdragon行動平台？」將觸發網際網路搜尋，並返回所得到的資訊。如果該命令類似於「Ok Google，傳簡訊給媽媽」，那麼命令資料(操作：發送簡訊；收件人：媽媽)就會被直接傳送到虛擬助理。
    > 
    > 




# NLP 理論


## 最大熵原理

- [A Maximum Entropy Approach to Natural Language Processing Adam ... www.cs.cornell.edu/courses/cs5740/2016sp/resources/maxent.pdf](http://www.cs.cornell.edu/courses/cs5740/2016sp/resources/maxent.pdf)

- [關於最大熵原理的一些想法 – Allenyl Lee – Medium](https://medium.com/@allenyllee/%E9%80%99%E8%A3%A1%E7%9C%8B%E4%BA%86%E5%BE%88%E4%B9%85-%E5%9B%A0%E7%82%BA%E6%88%91%E6%83%B3-%E7%86%B5%E4%B8%8D%E6%98%AF%E4%BB%A3%E8%A1%A8%E4%B8%8D%E7%A2%BA%E5%AE%9A%E6%80%A7%E5%97%8E-%E9%82%A3%E7%82%BA%E4%BB%80%E9%BA%BC%E6%98%AF%E6%89%BE%E6%9C%80%E5%A4%A7-%E8%80%8C%E4%B8%8D%E6%98%AF%E6%9C%80%E5%B0%8F-%E7%9C%8B%E5%88%B0%E4%B8%80%E7%AF%87%E6%96%87%E7%AB%A0%E9%80%99%E6%A8%A3%E5%AF%AB-e59db689490b)

    > - [我們要找的是其中最有可能的一種劃分，在這裡就是找出一種熵最大的劃分](https://medium.com/pyladies-taiwan/%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B-maxent-%E5%AF%A6%E8%B8%90%E7%9F%AD%E5%AD%97%E8%A9%9E%E5%88%86%E9%A1%9E-b925665d9082#dfd9)
    > 
    > 關於最大熵原理的一些想法
    > ============
    > 
    > 這裡看了很久，因為我想，熵不是代表不確定性嗎？那為什麼是找最大，而不是最小？看到一篇文章這樣寫：
    > 
    > * * * * *
    > 
    > > 有一句俗话说的是"不要把鸡蛋都放到一个篮子里"，这是因为如果这个篮子出了问题，那么所有鸡蛋都没了。也就是当我们在作考虑的时候，不要人为的人为哪件事出现的概率会高一点，一句话，不要添加任何人为因素，要使不确定性最大。这就是最大熵原理，在一篇文章上这样说到：
    > 
    > > Information theory provides a constructive criterion for setting up probability distributions on the basis of partial knowledge, and leads to a type of statistical inference which is called the maximum entropy estimate. It is least biased estimate possible on the given information; i.e., it is maximally noncommittal with regard to missing information.
    > > 
    > > [Phys. Rev. 106, 620 (1957) - Information Theory and Statistical Mechanics](https://journals.aps.org/pr/abstract/10.1103/PhysRev.106.620)
    > 
    > > 科学网 --- 最大熵模型（MaxEnt） --- 何孝松的博文\
    > > <http://blog.sciencenet.cn/blog-802219-667105.html>
    > 
    > * * * * *
    > 
    > 就短語分類的例子來說好了，我的想法是，未分類前的不確定性是最大的，因此具有最大的熵；然而分類後，由於必須滿足一定的約束條件，不確定性必然減少，因此熵會比未分類時來的小。
    > 
    > 現在假設我們人為設計幾條分類規則，而這些規則其實就是額外的約束條件，讓最後結果的熵變得更小。因此，可以知道當規則越多，最後結果的熵就愈小。
    > 
    > 如果我們希望在規則盡可能少的情況下完成我們的分類任務，就要盡可能在原始約束條件上最大化熵，這樣就可確定分類結果僅僅是受到原始約束條件的限制，模型沒有"學到"其他規則(Overfitting 正好相反，是模型學到太多完成任務不必要的規則)。在NLP任務中，原始約束條件可能來自大量語料統計出來的詞頻，以及有標註過的data。
    > 
    > 這樣看來，最大熵模型其實就是避免Overfitting的模型。現在想想貓狗辨識之類的圖片分類問題，什麼是他的原始約束條件呢？我們只給了有標註的data，這些標註以及data本身的統計特性，就成為這個任務的約束條件。
    > 
    > 而模型的功能，就是從data中取出盡可能少的feature 來完成指定的任務。為了滿足最大熵原理，模型本身不能對data做太多假設，但是也應該避免模型使用太多參數來"窮舉"出所有可能的feature，反而違反最大熵原則，造成overfitting的狀況。這也就是為什麼CNN 模型對圖片分類特別有效，因為它對圖片做了一些簡單假設，能夠有效避免模型為了達成任務而"窮舉"許多feature，而導致overfitting的情況。
    > 
    > 從另個角度來看，這也或許就是為何neural network 的深度比寬度來的重要的原因。因為寬度代表的是對前一層取feature的能力，寬度越寬，就越容易學到更多feature。假設有一個訓練完的單層寬度為M的網路，現在增加寬度到2M，等於在同一層中新增M個neural，由於這M個neural 跟前面M個是獨立的，而梯度下降會強迫它取出feature，因此它取出的feature 也是獨立於前面M個的，其中可能就有許多是達成任務不必要的feature(不必要的約束條件，也許只是某種圖片特有的pattern，但與解決任務無關)，因此違反了最大熵的原則，泛化性能反而較低；而深度則代表如何利用前幾層有限的feature 組合出能解決任務的feature。假設訓練網路時，都是先訓練完前面的N-1層，再加上第N層，那麼對第N層來說，它的約束條件就是第N-1層，透過梯度下降法找到最有效的組合，並沒有引入額外的約束條件，因此整個過程符合最大熵原則，泛化性能較高。
    > 
    > 一般來說，當Neural network 受限於參數量，寬度有限時，顯然無法窮舉出所有features，只能被迫擠出幾種最有效的features；但是當資料太簡單時，就有可能窮舉出所有features，造成overfitting。(所謂太簡單，就是data 在除了任務相關的feature上，相似度太高，例如來源太單一，造成某些只有該來源才有的feature 也被當成任務相關。通常在資料量少的情況下，容易找出出這種相似性；當資料來源多，資料量大時，就越難建立起這種相似性。因此，在最大熵原則下，我們希望data 在任務以外的features 越不像越好，表示我們沒有在蒐集data程中，引入額外的約束條件。)
    > [name=Ya-Lun Li]
    > 





























# 詞性標註（POS）/詞語組快分析（Chunking）/命名實體識別（NER）/語意角色標註（SRL）

## Natural Language Processing (almost) from Scratch

- [[1103.0398] Natural Language Processing (almost) from Scratch](https://arxiv.org/abs/1103.0398)

- [【每周一文】Natural Language Processing (almost) From Scratch - CSDN博客](https://blog.csdn.net/fangqingan_java/article/details/50493948)

    > 概述
    > ==
    > 
    > 本文介绍了一个统一的神经网络架构用于解决自然语言处理各种的各种任务，主要是序列标注任务，包括词性标注（POS）、词语组块分析（Chunking）、命名实体识别（NER）以及语义角色标注（SRL）等。本文主要介绍如何构建这个统一的神经网络以及如何运用一些技巧去提高效果，结论是不需要特殊构建特征工程就可以得到State-of-art结果。

- [Natural language understanding (almost) from scratch | the morning paper](https://blog.acolyer.org/2016/07/04/natural-language-understanding-almost-from-scratch/)

    > ### Four foundational NLP tasks
    > 
    > **Part-of-speech** tagging (POS), labels each word with a tag that indicates its syntactic role in a sentence: for example, noun, verb, adverb and so on. We're pretty good at POS tagging, with the system of Shen et al. 2007 achieving 97.33% accuracy. The overall system built by the authors in this paper is called SENNA (Semantic/Syntactic Extraction using a Neural Network Architecture). SENNA ultimately achieves 97.29% accuracy, but does over the benchmark in 4s using 32MB of RAM, whereas Shen et al.'s system needs 833s and 2.2GB of RAM.
    > 
    > **Chunking** labels *phrases* or segments within a sentence with tags that indicate their syntactic role: for example, *noun phrase* (NP) or *verb phrase* (VP).
    > 
    > > Each word is assigned only one unique tag, often encoded as a begin-chunk (e.g. B-NP) or inside-chunk tag (e.g. I-NP)..
    > 
    > On the CoNLL benchmark, Shen and Sarkar (2005) achieved an "F1" score of 95.23% in 2005. SENNA achieves 94.32%.
    > 
    > **Named-entity Recognition** (NER) labels recognised entities within the sentence. For example, as a person, location, date, time, company and so on. "As in the chunking task, each word is assigned a tag prefixed by the beginning or inside of an entity." Ando and Zhang (2005) achieved an F1 score of 89.31%. SENNA achieves 89.59%.
    > 
    > **Semantic-role labeling** (SRL) "gives a semantic role to a syntactic constituent of a sentence."
    > 
    > > In the PropBank (Palmer et al., 2005) formalism one assigns roles ARG0-5 to words that are arguments of a verb (or more technically, a predicate) in the sentence, e.g. the following sentence might be tagged "[John]ARG0 [ate]REL [the apple]ARG1", where "ate" is the predicate. The precise arguments depend on a verb's frame and if there are multiple verbs in a sentence some words might have multiple tags. In addition to the ARG0-5 tags, there there are several modifier tags such as ARGM-LOC (locational) and ARGM-TMP (temporal) that operate in a similar way for all verbs.
    > 
    > A typical SRL system may involve several stages: producing a parse tree, identifying which parse tree nodes represent the arguments of a given verb, and then classifying them to compute the final labels. Koomen et al. (2005) achieved a 77.92% F1 score. SENNA achieves 75.49%, but 10x faster and using an order-of-magnitude less RAM.
    > 
    > POS is the simplest of these tasks, and SRL the most complex. The more complex the task, the more feature engineering has traditionally been required to perform well in it.
    > 
    > ### Doing away with hand-engineered features
    > 
    > > All the NLP tasks above can be seen as tasks assigning labels to words. The traditional NLP approach is: extract from the sentence a rich set of hand-designed features which are then fed to a standard classification algorithm, e.g. a Support Vector Machine (SVM), often with a linear kernel. The choice of features is a completely empirical process, mainly based first on linguistic intuition, and then trial and error, and the feature selection is task dependent, implying additional research for each new NLP task. Complex tasks like SRL then require a large number of possibly complex features (e.g., extracted from a parse tree) which can impact the computational cost which might be important for large-scale applications or applications requiring real-time response. *Instead, we advocate a radically different approach: as input we will try to pre-process our features as little as possible and then use a multilayer neural network (NN) architecture, trained in an end-to-end fashion*.
    > 
    > ---
    > 
    > ### Network Architecture
    > 
    > 
    > The windowing approach assumes that the tag of a word depends mostly on the words surrounding it, and creates a combined feature vector by concatenating the feature vector of the target word and its *k* neighbours on each side. The overall network looks like this:
    > 
    > ![](https://adriancolyer.files.wordpress.com/2016/07/nlu-from-scratch-fig-1.png?w=303)
    > 
    > The final layer of the network has one node for each candidate tag, each output is interpreted as the score for the associated tag.
    > 
    > The windowing approach performs well for the first three tasks, but does not do so well for SRL. The issue here is that the correct tag for a word may depend on a verb in the sentence outside of the current window. The convolutional network architecture is introduced to try and address this:
    > 
    > > It successively takes the complete sentence, passes it through the lookup table layer (1), produces local features around each word of the sentence thanks to convolutional layers, combines these feature into a global feature vector which can then be fed to standard affine layers (4). In the semantic role labeling case, this operation is performed for each word in the sentence, and for each verb in the sentence. It is thus necessary to encode in the network architecture which verb we are considering in the sentence, and which word we want to tag.
    > 
    > (We'll see tomorrow an approach that uses LSTMs to provide the needed memory).
    > 
    > ![](https://adriancolyer.files.wordpress.com/2016/07/nlu-from-scratch-fig-2.png?w=434)
    > 
    > During training, we need a scoring function to tell the network how well it is doing. A simple approach (described in the paper as 'word-level log-likelihood') is just to look at the scores for each word independently. However...
    > 
    > > In tasks like chunking, NER or SRL we know that there are dependencies between word tags in a sentence: not only are tags organized in chunks, but some tags cannot follow other tags. Training using a word-level approach discards this kind of labeling information. We consider a training scheme which takes into account the sentence structure: given the predictions of all tags by our network for all words in a sentence, and given a score for going from one tag to another tag, we want to encourage valid paths of tags during training, while discouraging all other paths.
    > 
    > This scoring system is called 'sentence-level log-likelihood.'




- [attardi/deepnl: Deep Learning for Natural Language Processing](https://github.com/attardi/deepnl)

    > `deepnl` is a Python library for Natural Language Processing tasks based on a Deep Learning neural network architecture.
    > 
    > The library currently provides tools for performing part-of-speech tagging, Named Entity tagging and Semantic Role Labeling.
    > 
    > `deepnl` also provides code for creating *word embeddings* from text, using either the Language Model approach by [[Collobert11]](https://github.com/attardi/deepnl#collobert11), or Hellinger PCA, as in [[Lebret14]](https://github.com/attardi/deepnl#lebret14).
    > 
    > It can also create *sentiment specific word embeddings* from a corpus of annotated Tweets.

## Entity extraction: 實體抽取 

- [Entity extraction using Deep Learning – Towards Data Science](https://towardsdatascience.com/entity-extraction-using-deep-learning-8014acac6bb8)

- [Sequence Tagging with Tensorflow](https://guillaumegenthial.github.io/sequence-tagging-with-tensorflow.html)

- [dlnd-other/embeddings at master · dkarunakaran/dlnd-other](https://github.com/dkarunakaran/dlnd-other/tree/master/embeddings)

- [Pretrained Character Embeddings for Deep Learning and Automatic Text Generation](http://minimaxir.com/2017/04/char-embeddings/)

- [Introduction to Conditional Random Fields](http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/)

## Lattice LSTM: 中文實體識別


- [[1805.02023] Chinese NER Using Lattice LSTM](https://arxiv.org/abs/1805.02023)

    - [ACL 2018 | 利用Lattice LSTM的最优中文命名实体识别方法](https://zhuanlan.zhihu.com/p/38941381)







# 語法解析

## Bi-LSTM-CRF

- [[1508.01991] Bidirectional LSTM-CRF Models for Sequence Tagging](https://arxiv.org/abs/1508.01991)

- [词法分析之Bi-LSTM-CRF框架 - CSDN博客](https://blog.csdn.net/qrlhl/article/details/78561342)




## Stack-augmented Parser-Interpreter Neural Network (SPINN)

- [[1603.06021] A Fast Unified Model for Parsing and Sentence Understanding](https://arxiv.org/abs/1603.06021)

- [Recursive Neural Networks with PyTorch | NVIDIA Developer Blog](https://devblogs.nvidia.com/recursive-neural-networks-pytorch/)

    - [如何用PyTorch實現遞歸神經網絡？ - 壹讀](https://read01.com/kdQym4.html)

    > The dataset comes with machine-generated syntactic parse trees, which group the words in each sentence into phrases and clauses that all have independent meaning and are each composed of two words or sub-phrases. Many linguists believe that humans understand language by combining meanings in a hierarchical way as described by trees like these, so it might be worth trying to build a neural network that works the same way. Here’s an example of a sentence from the dataset, with its parse tree represented by nested parentheses:
    > 
    > ```
    >     ( ( The church ) ( ( has ( cracks ( in ( the ceiling ) ) ) ) . ) )
    > ```
    > 
    > One way to encode this sentence using a neural network that takes the parse tree into account would be to build a neural network layer Reduce that combines pairs of words (represented by word embeddings like [GloVe](http://nlp.stanford.edu/projects/glove/)) and/or phrases, then apply this layer recursively, taking the result of the last Reduce operation as the encoding of the sentence:
    > 
    > ```
    > X = Reduce(“the”, “ceiling”)
    > Y = Reduce(“in”, X)
    > ... etc.
    > ```
    > 
    > But what if I want the network to work in an even more humanlike way, reading from left to right and maintaining sentence context while still combining phrases using the parse tree? Or, what if I want to train a network to construct its own parse tree as it reads the sentence, based on the words it sees? Here’s the same parse tree written a slightly different way:
    > 
    > ```
    >     The church ) has cracks in the ceiling ) ) ) ) . ) )
    > ```
    > 
    > Or a third way, again equivalent:
    > 
    > ```
    > WORDS:  The church   has cracks in the ceiling         .
    > PARSES: S   S      R S   S      S  S   S       R R R R S R R
    > ```
    > 
    > All I did was remove open parentheses, then tag words with “S” for “shift” and replace close parentheses with “R” for “reduce.” But now the information can be read from left to right as a set of instructions for manipulating a stack and a stack-like buffer, with exactly the same results as the recursive method described above:
    > 
    > 1.  Place the words into the buffer.
    > 2.  Pop “The” from the front of the buffer and push it onto stack, followed by “church”.
    > 3.  Pop top two stack values, apply Reduce, then push the result back to the stack.
    > 4.  Pop “has” from buffer and push to stack, then “cracks”, then “in”, then “the”, then “ceiling”.
    > 5.  Repeat four times: pop top two stack values, apply Reduce, then push the result.
    > 6.  Pop “.” from buffer and push onto stack.
    > 7.  Repeat two times: pop top two stack values, apply Reduce, then push the result.
    > 8.  Pop the remaining stack value and return it as the sentence encoding.
    > 
    > I also want to maintain sentence context to take into account information about the parts of the sentence the system has already read when performing Reduce operations on later parts of the sentence. So I’ll replace the two-argument `Reduce` function with a three-argument function that takes a left child phrase, a right child phrase, and the current sentence context state. This state is created by a second neural network layer, a recurrent unit called the `Tracker`. The `Tracker` produces a new state at every step of the stack manipulation (i.e., after reading each word or close parenthesis) given the current sentence context state, the top entry *b* in the buffer, and the top two entries *s1*, *s2* in the stack:
    > 
    > ```
    > context\[t+1\] = Tracker(context\[t\], b, s1, s2)
    > ```
    > 

## SLING

- [google/sling: SLING - A natural language frame semantics parser](https://github.com/google/sling)

- [自然語言理解技術大進展！免斷詞，Google語意框架剖析器SLING能自動找出語句架構 | iThome](https://www.ithome.com.tw/news/118415)

    > [Google最近開源釋出實驗性的語意框架剖析器（Parsing）SLING，](https://research.googleblog.com/2017/11/sling-natural-language-frame-semantic.html)有別於以往用斷詞的方式，SLING不需要靠人工的方式標註語句，而是可以透過語意框架（Frame Semantic Parsing）的方式自動抽取出文字所要描述的語意結構，再以語意框架圖（Semantic frame graph）的方式呈現，Google研究團隊表示，SLING是透過Tensorflow和Dragnn訓練過的標註語料庫，這是自然語言理解技術的一大進展，語意分析不再靠斷詞，而是從語言意義層面，自動標註出語句的結構。
    > 
    > SLING是採用一個特定用途的遞歸神經網路（Recurrent neural network，RNN）模型，在該框架圖上，透過輸入文字的遞增編輯動作，來計算輸出值，也就是說，該框架圖因為靈活的特性，可以擷取多個語意任務，SLING的語意剖析器只用了輸入詞句來訓練，沒有採用額外的生成的標註，像是語句相依性分析產生的標註。
    > 
    > ![](https://s4.itho.me/sites/default/files/images/sling.png)
    > 
    > 大部分的自然語言理解系統都是採用一種分析流程，從詞性標註 （Part-of-speech tagging），到透過語句相依性分析（Dependency parsing）來計算輸入的文字語意。這種模型較容易將不同的方析階段模組化，但是往往也導致一個問題，一旦產生錯誤將會影響整個模型的預測。
    > 
    > SLING輸出的語意框架圖可以直接擷取使用者感興趣的語意標示（Semantic annotation），也能避免系統流程中的設計缺陷，還能避免不必要的計算。
    > 
    > 舉例來說，傳統的自然語言理解系統會先執行語句相依性分析的工作，最後才會執行指代消解（Coreference resolution），指代消解是將指定代名詞還原為被替換的名詞，來避免重要的字詞因被替換為指定代名詞，而在計算權重時降低的問題，如果語句相依性分析過程若有錯誤，將會連帶影響最終輸出的結果。
    > 
    > ### 語意框架剖析的機制
    > 
    > 語意框架代表語句的意義，也是一個描述，每個描述都被稱為一個框架，該框架可被視為知識或是意義的單元，也包含了與其相關的概念或是框架的相互關係。SLING將每個框架組織成一個Slot的清單，每個Slot都有自己的角色或是名稱，以及代表的值，該代表值可以是個字詞的原意，或是與其他框架的連結。
    > 
    > 例如，Many people now claim to have predicted Black Monday這句話，SLING先辨識語句的實體、測量值和其他概念，實體像是人物、地點，事件，測量值像是時間、距離，其他概念則包含動詞，接著，將這些辨識出來的字詞分類到正確的語意角色，當作輸入值，因此，SLING會先將people視為人物框架、predicted是動詞類別框架、Black Monday是事件框架，predicted這個動詞表示為PREDICT-01框架，PREDICT-01框架與預測的主詞Slot有相互關係，因此，PREDICT-01與PERSON框架連接，除此之外，PREDICT-01框架也與被預測的受詞有相互關係，與Black Monday的EVENT框架連接。
    > 
    > ![](https://s4.itho.me/sites/default/files/images/%E7%AF%84%E4%BE%8B.PNG)
    > 
    > Google研究團隊認為，SLING透過語意框架，來訓練並優化遞歸神經網路。神經網路在隱藏層中學習到的知識，可以取代了人工標註特徵。
    > 
    > 該語意剖析器的輸入是以雙向長短記憶單元（Bi-directional LSTMs）演算法為基礎的轉換語意框架剖析方法，使用Transition Based Recurrent Unit (TBRU)來輸出，結合成一個訓練過的模型，只需要文字標註當作輸入，經過轉換系統，輸出語意框架圖形，不需要中間產生的標註（Intervening symbolic representation）。
    > 
    > 輸出層的文字在輸出後，還會經過轉換系統（Transition system），再重新進入輸入層，其中，轉換系統的一項關鍵機制是採用了固定大小的框架來記錄字詞對上下文預測的重要程度，也就是說，該框架是用來表示最近提及，或是在語句中被增強的關鍵字。Google研究團隊發現，透過這個簡單的機制，在擷取大量語意框架的關聯上，效率提升有非常多。
    > 
    > 目前，Google的研究團隊表示，SLING是研究語意剖析的實驗，Google已在Github將SLING開源釋出，提供開發人員預先訓練完成的語意剖析模型，可應用於知識萃取、解析複雜引用（Resolving complex references），以及對話理解等工作，未來，Google將會持續擴增SLING的功能。

# 文法改錯

## DeepFix

- [DeepFix: Fixing Common C Language Errors by Deep Learning - 13921](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14603/13921)

















# 閱讀理解

## SQuAD

- [机器这次击败人之后，争论一直没平息 | SQuAD风云](https://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247493419&idx=1&sn=73425fec04482f14f6b9b7316e425e63&chksm=e8d05059dfa7d94fc1457a36d4f62cb1b8a057ce18388fbad448aa6b53f4dbb1299cfd697724&scene=21#wechat_redirect)


    > SQuAD被称为行业公认的机器阅读理解顶级水平测试，可以理解为机器阅读理解领域的ImageNet。它们同样出自斯坦福，同样是一个数据集，搭配一个竞争激烈的竞赛。
    > 
    > 这个竞赛基于SQuAD问答数据集，考察两个指标：EM和F1。
    > 
    > EM是指精确匹配，也就是模型给出的答案与标准答案一模一样；F1，是根据模型给出的答案和标准答案之间的重合度计算出来的，也就是结合了召回率和精确率。
    > 
    > 目前阿里、微软团队并列第一，其中EM得分微软（r-net+融合模型）更高，F1得分阿里（SLQA+融合模型）更高。但是他们在EM成绩上都击败了“人类表现”。
    > 
    > ---
    > 
    > 2016年，斯坦福大学从维基百科上随机选取了536篇文章，随后采用众包的方式，由人类阅读这些文章后，提出问题并人工标注出答案，构成了包含10万多个问题的阅读理解数据集SQuAD。
    > 
    > 对于这样一个数据集，以色列巴伊兰大学的著名NLP研究者Yoav Goldberg的评价是太局限（restricted）了。
    > 
    > 
    > 早在好几个月之前，AI在SQuAD上接近人类得分的时候，Goldberg就专门写了个PPT，把SQuAD批判了一番。
    > 
    > ![](http://mmbiz.qpic.cn/mmbiz_jpg/YicUhk5aAGtD6fFYcb6DzyJFYv9qXbIXrhnSnicBCVRib5QEQ9QvplO5Jb1gicibv4xfnK4VOlxMTBImGVvcnuAlibPQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1)
    > 
    > 他列举了SQuAD的三大不足：
    > 
    > -   受限于可以选择span来回答的问题；
    > 
    > -   需要在给定的段落里寻找答案；
    > 
    > -   段落里保证有答案。
    > 
    > 对于这些不足，DeepMind前不久发布的[NarrativeQA论文](http://mp.weixin.qq.com/s?__biz=MzIzNjc1NzUzMw==&mid=2247492423&idx=2&sn=c02f90e09a49c5c41d7aac3472573b94&chksm=e8d05435dfa7dd235aeb66aae46bc619f3cb6940d88b5d00b34204c3e38757f48480de2c6f6f&scene=21#wechat_redirect)做了更详细的说明。
    > 
    > ---
    > 
    > 他们认为，由于SQuAD问题的答案必须是给定段落中的内容，这就导致很多评估阅读理解能力应该用到的合情合理的问题，根本没法问。
    > 
    > 同时，这种简单的答案通过文档表面的信号就能提取出来，对于无法用文中短语来回答、或者需要用文中几个不连续短语来回答的问题，SQuAD训练出来的模型无法泛化。
    > 
    > 另外，SQuAD虽然问题很多，但其实用到的文章又少又短，这就限制了整个数据集词汇和话题的多样性。
    > 
    > 因此，SQuAD上表现不错的模型，如果要用到更复杂的问题上，可扩展性和适用性都很成问题。
    > 


# 論證推理 Argument Reasoning



## SemEval-2018 Task 12

- [[1708.01425] The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants](https://arxiv.org/abs/1708.01425)

- [UKPLab/argument-reasoning-comprehension-task: The Argument Reasoning Comprehension Task: Source codes & Datasets](https://github.com/UKPLab/argument-reasoning-comprehension-task)

- [SemEval-2018 Task 12 - The Argument Reasoning Comprehension Task](https://competitions.codalab.org/competitions/17327)

- [habernal/semeval2018-task12-results: Official results of the SemEval 2018 Task 12: The Argument Reasoning Comprehension Task](https://github.com/habernal/semeval2018-task12-results)



# 論述挖掘、事實抽取、來源分類


## Argument Mining on Twitter

- [Argument Mining on Twitter: Arguments, Facts and Sources - D17-1245](http://aclweb.org/anthology/D17-1245)

- [mihaidusmanu/twitter-opinion-detection](https://github.com/mihaidusmanu/twitter-opinion-detection)



# 空間關係

## SLIM 空間語言編碼

- [[1807.01670] Encoding Spatial Relations from Natural Language](https://arxiv.org/abs/1807.01670)

- [DeepMind提出空間語言集成模型SLIM，有效編碼自然語言的空間關係 - 幫趣](http://bangqu.com/Q59Yc2.html#utm_source=Facebook_PicSee&utm_medium=Social)

    > **3 模型描述**
    > 
    > 我們提出了一種模型，該模型學習將單個底層輸入的多種描述集成到單個表徵中，隨後在多模態設置中利用該表徵生成新數據。
    > 
    > 我們將該模型稱爲空間語言集成模型（Spatial Language Integrating Model，SLIM）。其靈感來自於生成查詢網絡（Generative Query Network，Eslami et al. 2018），該網絡集成了多個視覺輸入，可用於生成相同環境的新視圖。爲了讓表徵能編碼視點無關的場景描述，設置該模型使之在構建表徵之前不知道哪個視點會被解碼。在我們的例子裏，向模型輸入從 n 個不同視點所看到的場景的文本描述，以編碼成場景表徵向量。然後，利用該向量重建從新視點看到的場景圖像。
    > 
    > 如圖 2 所示，我們提出的模型由兩部分組成：一個表徵網絡，它從多視點場景的文本描述中生成聚合表徵（aggregated representation）；一個以場景表徵爲條件的生成網絡，它將場景渲染爲新視點下的圖像。我們對這兩個網絡進行了如下描述（詳見附錄 A）。
    > 
    > ![](http://i2.bangqu.com/j/news/20180724/Q59Yc21532408446134293qI.png)
    > 
    > *圖 2：模型圖示。表徵網絡解析多個攝像機座標拍攝的多視點場景的多個描述和文本描述。所有視點的表徵被聚合成一個場景表徵向量 r，然後生成網絡使用該向量 r 來重建從新的相機座標看到的場景的圖像。*
    > 
    > ![](http://i2.bangqu.com/j/news/20180724/Q59Yc215324084485682GE36.png)
    > 
    > *圖 3：從合成語言（頂部）和自然語言（底部）模型生成的樣本。相應的描述是：「There is a pink cone to the left of a red torus. There is a pink cone close to a purple cone. The cone is to the left of the cone. There is a red torus to the right of a purple cone.」；「There are two objects in the image. In the back left corner is a light green cone, about half the height of the wall. On the right side of the image is a bright red capsule. It is about the same height as the cone, but it is more forward in the plane of the image.」*




# 文章分類


## 垃圾郵件偵測

- [How To Build a Simple Spam-Detecting Machine Learning Classifier](https://hackernoon.com/how-to-build-a-simple-spam-detecting-machine-learning-classifier-4471fe6b816e)

- [Spam detection using neural networks in Python – Emergent // Future – Medium](https://medium.com/emergent-future/spam-detection-using-neural-networks-in-python-9b2b2a062272)


- [Spam Classification | Kaggle](https://www.kaggle.com/benvozza/spam-classification/notebook)

- [[1606.01042] Machine Learning for E-mail Spam Filtering: Review,Techniques and Trends](https://arxiv.org/abs/1606.01042)



### 垃圾郵件 dataset

- [UCI Machine Learning Repository: Spambase Data Set](https://archive.ics.uci.edu/ml/datasets/Spambase)

- [SMS Spam Collection Dataset | Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset/kernels)

- [Fraudulent E-mail Corpus | Kaggle](https://www.kaggle.com/rtatman/fraudulent-email-corpus/data)





# 文字生成

- [Neural text generation – Phrasee – Medium](https://medium.com/phrasee/neural-text-generation-generating-text-using-conditional-language-models-a37b69c7cd4b)

## char-rnn

- [Tensorflow lyrics generation · Lei's Blog](http://leix.me/2016/11/28/tensorflow-lyrics-generation/)

    - [leido/char-rnn-cn: 基于char-rnn和tensorflow生成周杰伦歌词](https://github.com/leido/char-rnn-cn)

- [從字符級的語言建模開始，瞭解語言模型與序列建模的基本概念 - 幫趣](http://bangqu.com/24EJ36.html)


## google smart compose

- [未來Email將預測你的心思自動寫完？Google大腦首席工程師在官方部落格詳細介紹了原理 - INSIDE 硬塞的網路趨勢觀察](https://www.inside.com.tw/2018/06/20/smart-compose)

    - [Google AI Blog: Smart Compose: Using Neural Networks to Help Write Emails](https://ai.googleblog.com/2018/05/smart-compose-using-neural-networks-to.html)


    > Google 的方法是包含利用額外語境的一個方法，該方法是將問題轉換成一個序列到序列（seq2seq）的機器翻譯任務，其中源序列是郵件主題和上封郵件正文（假設存在上封郵件）的串聯，使用者正在寫的郵件是目標序列。儘管該方法在預測品質上表現良好，但它的延遲要比 Google 嚴苛的延遲標準超出了好幾個量級
    > 
    > 為了提高預測品質， Google 將一個 RNN-LM 神經網路與一個 BoW 模型結合起來，結合後的模型在速度上比 seq2seq 模型要快，且只輕微犧牲了預測品質。在該混合演算法中， Google 通過把詞嵌套們平均分配在每個區域內，來對郵件主題和此前的郵件內容進行編碼。隨後 Google 將這些平均分配後的嵌套連接在一起，並在每次執行解碼步驟時將它們提供給目標序列 RNN-LM，過程如下面的模型圖解。
    > 
    >  Smart Compose RNN-LM 模型架構。將郵件主題和此前郵件訊息進行編碼，採用的方法是將它們的詞嵌套平均分配在每一個區域內。隨後，平均後的嵌套會在每次執行解碼步驟時提供給目標序列 RNN-LM。
    > 
    > ![](https://i0.wp.com/www.inside.com.tw/wp-content/uploads/2018/06/model3.png?resize=640%2C236)
    > 

# 自動標籤(auto tagging)

- [memray/seq2seq-keyphrase](https://github.com/memray/seq2seq-keyphrase)

- [udibr/headlines: Automatically generate headlines to short articles](https://github.com/udibr/headlines)

- [fudannlp16/KeyPhrase-Extraction](https://github.com/fudannlp16/KeyPhrase-Extraction)

- [Tensorflow：基于LSTM轻松生成各种古诗 - CSDN博客](https://blog.csdn.net/meyh0x5vdtk48p2/article/details/78987402)

- [[代码]基于RNN的文本生成算法 - CSDN博客](https://blog.csdn.net/clayanddev/article/details/53955850)

- [How can I use machine learning to propose tags for content? - Quora](https://www.quora.com/How-can-I-use-machine-learning-to-propose-tags-for-content)

- [Deep Learning for Text Understanding from Scratch](https://www.kdnuggets.com/2015/03/deep-learning-text-understanding-from-scratch.html)

- [neural network - Keyword/phrase extraction from Text using Deep Learning libraries - Data Science Stack Exchange](https://datascience.stackexchange.com/questions/10077/keyword-phrase-extraction-from-text-using-deep-learning-libraries)

- [attardi/deepnl: Deep Learning for Natural Language Processing](https://github.com/attardi/deepnl)

- [Intro to text classification with Keras: automatically tagging Stack Overflow posts | Google Cloud Big Data and Machine Learning Blog  |  Google Cloud](https://cloud.google.com/blog/big-data/2017/10/intro-to-text-classification-with-keras-automatically-tagging-stack-overflow-posts)

- [snkim/AutomaticKeyphraseExtraction: Data for Automatic Keyphrase Extraction Task](https://github.com/snkim/AutomaticKeyphraseExtraction)

- [lvsh/keywordfinder: Automatic keyword extraction - no alchemy required!](https://github.com/lvsh/keywordfinder)

- [Natural Language Toolkit — NLTK 3.2.5 documentation](http://www.nltk.org/)

- [nlp - How to auto-tag content, algorithms and suggestions needed - Stack Overflow](https://stackoverflow.com/questions/6039238/how-to-auto-tag-content-algorithms-and-suggestions-needed)




# 機器問答

## NTM+CGNN

- [[1806.09105] One-shot Learning for Question-Answering in Gaokao History Challenge](https://arxiv.org/abs/1806.09105)

    - [我一个理科生造的AI，怎么就去做历史高考题了呢？](https://zhuanlan.zhihu.com/p/38772246)








# 深度好奇

- [深度好奇 (DeeplyCurious.AI) - 让机器善解人意](http://deeplycurious.ai/#/)



- [神經符號系統: 讓機器善解人意 - 幫趣](http://bangqu.com/eDroC7.html)

    > 按：本文原作者爲深度好奇研究組，原發表於公衆號 **「深度好奇AI」（deeplycurious）** 。
    > 
    > ### 1\. 通往語言理解之路
    > 
    > **什麼是理解**
    > 
    > 自然語言理解是人工智能的核心課題之一，也被廣泛認爲是最困難和最具標誌性的任務。最經典的兩個人工智能思想實驗------圖靈測試和中文房間，都是圍繞自然語言理解來構建的。自然語言理解在人工智能技術體系中的重要性不言而喻，它一方面承載着機器和人的交流，另一方面直達知識和邏輯。自然語言理解也是人工智能學者孜孜以求的聖盃，機器學習的巨擘Michael I. Jordan就曾經在Reddit上的AMA（Ask Me Anything）欄目中暢想用十億美元建立一個專門用於自然語言理解的實驗室。
    > 
    > 那麼究竟什麼是自然語言理解呢？我們可以認爲，理解是從自然語言到語義的映射，但是這個定義只是把問題轉移到了「語義」的定義上，而關於語義，一直缺乏在形式和功能上都普遍適用的定義。事實上，語義往往需要被放在特定領域和特定語境下去考量，比如一句「你開心就好」，可以在不同的場景下傳達鄙視和祝願等多種意思。關於理解或者語義，我們不得不採取了下面兩種耍賴式的定義來刻畫它們的不同側面：
    > 
    > -   語義是特定語境下的語用，也就是說一句話的功效纔是對它含義的最終表徵；
    > 
    > -   理解一個語言對象（如一段話），等價於可以回答關於這個對象的所有問題。
    > 
    > 不幸的是，這兩個定義都不具有完全的可操作性，也就是說，很難用這個定義來自動化地衡量對語義的映射是否準確，或者理解是否恰當。從某種意義上，語義理解在定義上就有點「難以捉摸」和不確定。
    > 
    > 這種不確定也導致了人工智能中語義相關的系統在形式和功能上的多樣性。比如說，在神經網絡機器翻譯（NMT）中，所有的語義表示都是通過固定長度的實數值向量來完成。在第一代NMT系統中用一個很長的向量來表示和總結待翻譯的句子（確切地說是混合了語法和語義的信息），這個向量雖然不可解釋，但確實是一個形式和功能上都完整的表示（關於用向量表示語義一直有很多爭論，正面的比如G. Hinton的thought vector, 反面的比如R. Mooney的著名論斷）。而在第二代的基於注意力機制的NMT系統中，這種表示完整語義的設計已被淘汰，取而代之的是一個實數向量序列來表述多個片段的語義，從而在取得翻譯效果的大幅度進步的同時，也在語義表示層面上後撤了一大步。同時我們注意到，連續的不可解釋的語義表示在另一些需要和有清晰的語義規範對象互動的時候則非常彆扭，當我們去做基於知識庫的問答或者基於罪行的描述做審判預測時，需要將語義表示和知識庫或者規則系統做對接。這種時候，我們會選擇符號化的語義表示，如邏輯表達式、圖或者其他離散的數據結構。在本文接下來的討論中，我們會假定我們期望的語義表示中至少包含可解釋的離散結構。
    > 
    > **理解之難**
    > 
    > 自然語言理解的困難也是有目共睹，所以當前自然語言理解通常是粗粒度、淺層或者是局部的。在常見的和理解相關的例子中，情感分析往往只是判斷感情是正面還是負面，而命名實體識別等只是標出實體（比如人、組織、地名等）的名稱，但即使是這樣，準確率也往往在達到一定水平之後裹足不前。相比而言，機器翻譯的快速發展反而是因爲它對理解的繞道而行，採取了一種「不懂裝懂」（pretend to understand）的模式。
    > 
    > 那麼自然語言理解爲什麼如此困難呢？ 我們認爲，主要有以下四個原因：
    > 
    > **1.自然語言中含有複雜靈活的表達方式**
    > 
    > 我們經常用不同的語句表達同一個意思，這些不同體現在風格、語態、對缺省的選擇等衆多方面。比如，下面意思非常接近的兩句話就採用了不同的語序和風格。
    > 
    > A：這裏和購物中心的距離大約是兩公里，如果坐出租車的話，路上不堵的情況下大概十分鐘就到了
    > 
    > B：這兒離購物中心不遠，打車也就十分鐘，不堵車的話，其實也就兩公里吧
    > 
    > **2.長距離的邏輯關聯**
    > 
    > 自然語言形成的文本中，常常有長距離的邏輯關聯。這種邏輯關聯既包含來自語言結構的依存關係，也包含語義層面上的邏輯關係，而且二者互相滲透。以下面的句子爲例，它包含了一個語義信息「這裏距離購物中心兩公里」，但是要做出這個判斷，需要跨越句頭和句尾中間的距離，依靠語義上的連續性來發現前後的邏輯關聯。這種邏輯關聯，往往很難靠類似循環神經網絡（RNN）這樣的簡單序列處理模型來發現和利用。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57c6c699.png)
    > 
    > **3.對知識（包含常識的）的大量依賴**
    > 
    > 在文本的理解中，我們往往需要依賴大量的知識，這些知識既包括領域知識和常識這種長期知識，也包括在前文中建立的短期知識。我們通常說的「語境」也可以被認爲是短期知識的一種。
    > 
    > A：張三偷了一臺iPhone X，一臺iPhone 6S和一臺P20，其中兩臺蘋果手機都已經轉手
    > 
    > B：車庫裏有一輛17年的雅閣和一輛09年的凱美瑞，結果反而是舊車被偷了
    > 
    > 在例A中，在理解「兩臺蘋果手機都已經轉手」中的具體指代時，我們需要利用以下的知識：
    > 
    > -   iPhone X是蘋果手機
    > 
    > -   iPhone 6S是蘋果手機
    > 
    > -   P20是華爲手機。
    > 
    > 而在例B中，在理解「舊車被偷了」時，我們不僅需要使用前半句中建立的
    > 
    > -   雅閣是17年的
    > 
    > -   凱美瑞是09年的
    > 
    > 這兩條知識，我們同時需要使用「09年的車比17年的車更舊」這一常識。準確利用這些知識則需要對知識進行有效的獲取、表示和調用。
    > 
    > **4.語義表示形式設計的困難**
    > 
    > 語義表示的形式一直以來是語義解析這個問題上爭論的核心之一。簡單來說，「完備的」語義表示需要能夠包含精確知識（如「張三殺了李四」），也需要承載語言中的模糊性、不確定性、程度和情感的極性等問題。同時我們期望語義的表示能夠和其他知識（如語境）進行完美的對接以完成聯合的表示和推理，比如一句「這水挺燙的」，在水的用途是飲用、泡麪、泡腳等不同場景下就可能導致不同的語義（如極性和程度等）。同時，語義表示也需要考慮到實際的用途和技術邊界，這種平衡本身就是非常困難和持續變化的。
    > 
    > 我們可以看到，上述困難中有些是深度學習所擅長的，比如神經網絡的方法就可以利用其向量式的「模糊表示」來處理複雜靈活的表達方式；有些是符號邏輯所擅長的，比如長距離的邏輯關聯；而有些顯然是需要二者合力的，比如對知識的依賴，就既需要神經網絡的參數來記住和運用各種瑣細靈活的知識，又需要把一些可以被明晰表達的知識用符號性的方式來存儲和調用。據此，我們認爲，神經網絡和符號智能的深度結合纔是解決上述困難唯一正確的道路。對此我們將會在本文餘下的部分做詳盡的闡釋。
    > 
    > ### 2.神經+符號
    > 
    > **爲什麼神經+符號是正確的道路**
    > 
    > 正如上文中所闡釋的，人類語言理解的過程、機制和形態，充滿了符號性和連續性的雙重特性，而在人工智能的實踐中，我們也發現了二者各自的優勢。在人工智能的歷史上，這就是符號主義（Symbolism）和聯結主義（Connectionism）之爭。我們先來解釋下神經和符號的概念，以及各自的特點、優勢和劣勢。這些討論將會在以下三個層面上展開：
    > 
    > -   表示層  : 語言對象的語義表示，如詞、句子乃至長文本的語義表示，也包含系統中和語義相關的中間狀態
    > 
    > -   運算層 ：對不同類型和尺度的語言對象的操作和轉化，如生成、映射、轉換、分類、預測、查詢、更新等
    > 
    > -   知識層 ：包括語言學知識、領域知識和常識這類的「長期知識」，也包括在理解過程中對文本建立的「短期知識」。
    > 
    > 總體來說，
    > 
    > -   神經網絡用來處理連續的表示、操作以及知識，具有模糊、可學習、不確定、靈活、無需設計、不可解釋的特性，不擅於處理圖結構、變量、遞歸和指代等；
    > 
    > -   符號系統用來處理離散的、結構性的表示、操作以及知識（包括圖結構、變量、遞歸和指代等），具有清晰、精確、高執行效率、可解釋的優點。
    > 
    > 從系統設計的角度，神經網絡正因爲犧牲了微觀和主動意義上的可解釋性（如設定某個節點或者某個參數的含義），轉向架構和機制上的設計， 從而獲得了系統描述能力（expressiveness）上的靈活性。從數學的角度，神經網絡可以認爲是用大量參數近似地描述了大量可能符號模式的分佈，從而可以用基於梯度的方法(gradient-based methods) 來訓練，但是也失去了對特定符號模式的清晰刻畫的能力。我們可以用圖1來形象地說明神經網絡和符號系統是如何去近似解決同一個真實的任務的。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57327bbe.png)
    > 
    > 圖1：神經網絡和符號智能任務處理上的比較
    > 
    > 我們用下表來總結神經網絡和符號智能在表示、運算和知識三個層面上的區別。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57d4b4f2.png)
    > 
    > **神經符號主義的歷史**
    > 
    > 人工智能領域長期有兩種思想佔據主流地位：符號主義和聯結主義。符號主義使用基於規則的符號做推理，致力於用計算機的符號操作來模擬邏輯思維和認知過程，實現人工智能。聯結主義強調智能起源於高度互聯的簡單機制，其偏向於模仿腦結構的研究，更側重神經網絡中的聯結機制與學習算法。規則系統具有可解釋性強和精確度高的特點，而神經網絡靈活性高、泛化能力強、魯棒性好，因此人工智能之父馬文-明斯基（Marvin Minsky）總結到：「符號知識和聯結主義各有優缺點，我們需要一個系統能夠將它們的優點集成起來」  [1]。自1980年，很多有遠見的人工智能學者就試圖將神經網絡和符號智能結合，這個包含了無數不同嘗試的方向被稱爲神經符號主義（Neural-symbolism）。
    > 
    > 一些先驅者對神經符號主義進行了初步的探索。早在1990年，Towell等人便提出了KBANN（基於知識的人工神經網絡）[2]，採用已有的經驗知識去構建人工神經網絡的結構和網絡中的連接權重。Garcez等人在1999年提出了CILP系統[3]，他們將背景知識轉化爲命題邏輯，並基於此構建前向人工神經網絡，並從例子中歸納新的知識去更新已有的知識。Garcez等人在2001年提出了一種在訓練好的神經網絡中抽取邏輯知識的方法[4]，可以增強神經網絡的可解釋性。Richardson等人在2006年對一階符號邏輯和概率圖模型結合的方式進行了探索，提出了馬爾科夫邏輯網絡[5]，該網絡是一個一階符號邏輯的知識庫，其中每一個公式都有對應的權重。受限於當時機器學習技術和自然語言處理技術的制約，這些探索並不能充分利用神經網絡的優勢，因而沒有取得更近一步的成功。
    > 
    > 隨着層數更深、更多樣、表達能力更強的深度神經網絡的崛起，越來越多的學者加入了對神經網絡和符號智能進行結合的探索中。Jaeger提出了一種用「Conceptors」控制循環神經網絡的方式[6]，使得整個網絡具有幾何特性，並且可以和布爾邏輯進行有效結合。Graves等人提出了神經圖靈機（Neural Turing Machines）[7]，Sukhbaatar等人提出了記憶網絡[8]，他們都引入了記憶機制來解決對推理過程中間結果的存儲問題。上述方法對神經符號系統進行了進一步的探索，賦予了神經網絡符號化的結構，對後續的研究有着重要的啓發意義。
    > 
    > 近年來，一些研究者致力於藉助神經網絡來實現符號推理。Neelakantan等人提出了「Neural Programmer」[9]，基於自然語言理解實現數據庫查詢。Liang等人進一步引入了符號化的記憶機制[10]，幫助神經網絡更好地完成複雜推理。Mou等人用神經網絡和符號操作共同決策，提出瞭解決自然語言推理查詢的新途徑[11]。
    > 
    > 還有一些工作希望能用符號邏輯幫助神經網絡訓練、學習和推理。Hu等人提出了Teacher-Student網絡[12]，讓神經網絡（Student）擬合符號規則（Teacher）的結果，使得神經網絡在規則的指導下訓練學習。Goyal等人採用先驗知識改進了字符級的循環神經網絡用於自然語言生成問題（NLG）[13]。Luo等人探索了在不同層面上，正則表達式規則和神經網絡的結合手段，希望用正則表達式規則提供的豐富信息提升神經網絡的表現[14]。這些方法本質上是用符號知識給神經網絡提供更多的信息，神經網絡和符號智能的結合較爲粗糙。同時，這些將神經網絡和符號智能結合的嘗試往往只是針對某個非常限定的任務，而且往往只有空間上對某個層面的處理。
    > 
    > ### 3\. 我們的想法和嘗試
    > 
    > **通向神經系統和符號智能的融合**
    > 
    > 我們認爲神經網絡和符號智能融合的理想形態，應該遵循以下的原則/方向：
    > 
    > -   原則-I：形成神經和符號的連接
    > 
    > 簡言之，我們需要建立神經和符號交流的界面、路徑和機制。二者的交流主要有兩種，1）互相控制和調用，2）互爲輸入和輸出。對於1），一個例子是Neural Programmer [9],  它用連續信號來調用和驅動符號運算，而二者的界面就是符號預算的向量索引。 對於2），我們期望神經運算的輸出可以成爲符號運算的輸入，而同時符號運算的輸出（在「嵌入」之後）也可以成爲神經運算的輸入（如圖2），這形成了表示層-運算層的神經-符號閉環。舉例說明，對於下面的例句
    > 
    >       三郎仁真與澤旺、洛爾伊在大學旁邊的快捷酒店住了三個晚上
    > 
    > 神經網絡利用當前的狀態（向量表示）預測「三郎仁真」 是人名，這個符號化的信息可以作爲下面一條規則
    > 
    > **RULE-9527: **在同一個list中的語言對象應該有同樣的類型
    > 
    > 的輸入，從而預測「澤旺」也是人名。而這個來自符號運算的輸出，在嵌入之後，會和其他的原始輸入一起，再次進入神經網絡，而其進入的形式可以是作爲建議（從而需要神經網絡的進一步綜合判定），也可以是作爲確定的結論。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a572e7d20.png)
    > 
    > 圖2：神經（連續）信號和符號信號的閉環
    > 
    > -   原則-II：形成神經和符號間的並列和對應
    > 
    > 神經符號系統可以在表示、運算、知識三個層面上，形成神經和符號間的並列和對應。這裏，並列是指同時存在功能重合的神經和符號兩種狀態，這形成了某種程度的冗餘，可以被系統擇優使用或者同時使用（見原則-III）；而對應則意味着神經和符號兩種狀態之間存在設計的信息交互，這種交互可以幫助一種形態轉換成另一種形態，也可以同時促進兩種形態的共同訓練（co-training）（這裏的co-training是從multi-view learning的角度來鼓勵兩個或更多通路的一致性，而非強調在其半監督學習場景下的應用）。 這三個層面上的並列和對應可以有多種方式，下面僅舉兩例。我們在2017年提出的神經-符號雙通路的問題解析模型 [11]（見圖3-a）：對一個問題（如「北京奧運會是哪一年舉行的？」），系統會有包含解析和運算的神經通路，也會有一個近乎對稱的符號通路。兩條通路殊途同歸，同時會有密集的信息交換。神經通路可以高效地利用後向傳播算法學習，而符號通路則通過符號化的總結而具有高執行效率和很好的泛化性能。通過在訓練中鼓勵兩條通路的一致性，我們可以獲得比單一通路更好的學習效率、執行效率以及泛化性能。我們最新的一項技術（見下文中的Nerual Rule Engine），則可以部分地完成知識層上的轉換（見圖3-b），從而利用神經網絡天然的泛化能力克服規則系統的脆弱性。圖3-b也描述了上述轉換的逆過程，即神經網絡中的參數知識被總結成爲規則，這個過程通常被稱爲規則抽取（rule extraction）。
    > 
    >  ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57291f97.png)
    > 
    > 圖3：神經和符號間的並列和對應
    > 
    > -   原則-III：完備的中央調控機制去選擇、控制和規劃
    > 
    > 爲了有效地訓練和執行，神經符號系統需要一箇中央控制系統在表示、運算、知識三個層面上做選擇、控制和規劃（見圖4）。如果存在表示、運算甚至知識層面上的並列（見原則-II），那麼在執行階段，中控系統會在某個特定時刻根據情況在這三個層面上選擇使用神經、符號還是它們的組合。比如說，在閱讀和理解某個句子的過程中，中控系統在某時刻決定探測句子餘下的部分是否含有並列結構。這個探測的決定本身是符號性的，但是這個探測的行爲本身可以是由一個神經網絡模塊來完成的。同樣，分管訓練的更長期的中控系統會規劃神經通路和符號通路的交流的具體節奏，控制轉換和促進的機制等。接着用上面的例子，這個探測並列結構的神經網絡模塊可能原先來源於一個簡單的規則，但是在使用過程中不斷地吸收來自任務的監督信號，最終被中控系統確定取代對應的規則。很顯然，原則-III的意義來源於原則-I和II帶來的神經和符號複雜交融的可能，而原則-III的實現也需要以原則-I和II爲基礎。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a5747aa27.png)
    > 
    > 圖4：對神經網絡系統的調控
    > 
    > 這三個方向上的融合，既相對獨立，又有很強的關聯，同時可以以多種方式嵌套使用，給出了無限的架構和機制設計上的可能性。可以認爲，一個相對「完備」的神經符號系統應該綜合了這三個方向，從而可以將神經系統和符號系統各自的優點做深層次融合，使得文本理解達到前所未有的深度。雖然在特定任務的神經符號系統上，我們往往只會實現神經符號系統的特定方面，這些可以從深度好奇最近的工作爲例來說明。
    > 

    > **深度好奇的工作**
    > 
    > 深度好奇正是遵循以上的融合神經網絡和符號智能的原則，針對不同類型的自然語言理解任務，設計了一系列的模型。我們介紹下面三個工作，1）神經規則引擎，2）變焦神經網絡，和 3）神經實體推理,  來作爲其中的代表。
    > 
    > -   **神經規則引擎（Neural Rule Engine）**
    > 
    > 規則作爲人類知識的具體體現，是一種簡單但是極爲可靠的快速構建工業應用的手段，也是符號性知識的通用形式。規則雖然極其精確，但是其僵硬脆弱的特點又經常被詬病，比如規則可以查找「騎自行車上班」，但是語義相似的「騎小黃車上班」卻無法匹配，傳統的規則需要大量擴充才能涵蓋這些在語義上相近的表達。我們提出的神經規則引擎（NRE），將符號性的規則知識轉化爲神經網絡的知識形式，並輔以對應的運算。NRE吸收了神經網絡靈活性高、泛化能力強、魯棒性好的優勢，同時也維持了規則的精確性和可解釋性。它可以從規則中學習知識，同時又通過神經網絡來泛化知識，與人類學習知識的方式有異曲同工之妙。神經規則引擎由基礎的操作和解析器來表示規則。操作和解析器根據需求既可以選用神經網絡也採取符號算法來實現。具體來說，神經規則引擎先對規則用解析器進行解析，生成層級操作序列，之後依照順序來組裝模塊，最後將組裝好的規則應用於具體的事例，判斷是否符合規則（圖5給出了一個簡略的示意圖）。實驗表明，藉助神經網絡的優勢，神經規則引擎對符號知識進行了學習和擴展，可以大幅提升規則的召回率，同時還能維持較高的精確率使規則本身的特性得以保留。神經規則引擎不僅是一種新的神經符號學習範式，同時也爲現有的工業應用帶來了一種高效的改進，它可以被用來對已有的規則系統進行升級，或者在訓練數據不大的情況下快速開發出神經規則系統  (論文見 arxiv.org/abs/1808.10326)。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a577901b0.png)圖5：神經規則引擎的示意圖
    > 
    > -   **變焦神經網絡（Zooming-Net）**
    > 
    > 段落、列表等文本結構蘊涵着信息輸出者的表達策略，對於準確抓取、理解文本內容有着重要的意義。這種文本結構有符號化的骨架，但是又需要和局部的語義有深度的耦合。我們提出了變焦神經網絡（Zooming-Net）來完成這種偏符號性的文本結構和神經性的局部語義表示的結合。Zooming-Net可以利用Policy-Net靈活地選擇在特定文本粒度（字、句、段）上執行讀取、更新、跳轉、預測等一系列操作，這種獨特的變焦處理方式高度類似人類閱讀過程，利用文本結構，其在信息稀疏部分進行泛讀，確保不引入過多噪聲，在信息密集部分進行精讀，確保有用信息不被丟失。我們引入了符號化推理模塊對模型的輸出加以解釋，並進行定向的干預。變焦神經網絡由層次化編碼器、變焦控制器和符號化推理模塊三個部分完成對文本的處理並以序列標註的形式找出文本中的關鍵片段（圖6給出了一個簡略的示意圖）。具體地說，在每個時刻，層次化編碼器配合變焦控制器有策略地選擇建立層次化特徵，讀取特定層級的信息，結合符號化推理模塊給出的臨時性離散信息預測出一定長度的標籤序列。在讀取整篇文本之後，將各時刻輸出的標籤序列進行組裝，並取出對應的關鍵信息片段。實驗表明，藉助句段結構信息，變焦神經網絡很好地結合了泛讀與精讀過程，其可以更好地對長時依賴特徵進行建模，並引入大跨度動作提高效率，在關鍵信息的抽取任務上，f1值較經典序列標註模型（biLSTM+CRF）有10%以上的提升，預測行爲頻次減少50%以上。變焦神經網絡非常適合應用在各類長文本處理任務當中，其使用的編解碼方式也可結合其他技術推廣到各類自然語言處理任務過程中 (論文見 arxiv.org/abs/1810.02114 )。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a5769b233.png)
    > 
    > 圖6：變焦神經網絡的基本原理
    > 
    > -   **神經實體推理（Neural Entity Reasoner）**
    > 
    > 命名實體識別（Named Entity Recognition）被認爲文本理解的基礎和底層任務，因爲它的職能就是發現和標識文本中的人名、地名等。傳統的NER方法依賴局部和底層的語言特徵，但是當出現有歧義的說法或者少見的人名時，這類方法往往會遇到困難。而人在這種情況下，往往可以通過縱覽全文，打通和融合局部的知識，來擺脫這種困境。我們正是受到人的思維模型的啓發，爲NER這個看似低級的任務引入了高級的「推理」機制，將符號化的命名實體信息「取之於網絡，用之於網絡」，從而可以在深度學習的框架內融合同一文本中的命名實體的決策。命名實體神經推理機（NE-Reasoner）整體上是一個多層的架構，每一層都獨立完成一次NER（圖7給出了一個簡略的示意圖）。每層的NER結果，會通過一個符號化的「緩存」存儲起來，作爲下一層NER的參考：這種參考是通過一個交互式的池化神經網絡來實現，本質上是一個基於多個事實的推理模型。由於這樣的設計，在做每個局部的決策時，模型都可以「看見」並參考別處相關決策，從而做出更加明智的決定。實驗表明，通過在神經網絡的推理過程中，引入符號化的緩存記憶，以及在緩存基礎上的多事實全局推理，可以顯著提高命名實體識別的準確率，尤其是在傳統方法容易犯錯的歧義和少見人名上有更好的表現。命名實體神經推理機作爲神經符號推理機在NER任務上應用的一個實例，不僅打開了之前神經網絡推理決策的黑箱，使得推理過程中的關鍵步驟對人類可見和可理解，而且給予了人工進一步干預推理過程的可能性及有效的接口 (論文見 arxiv.org/abs/1810.00347)。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a578dbc88.png)
    > 
    > 圖7：神經實體推理（NE-Reasoner）工作原理圖
    > 
    > ### 4\. 新的框架: 面向對象的神經規劃（OONP）
    > 
    > 不同於之前介紹的三項相對專門的技術，面向對象的神經規劃（Object-oriented Neural Programing,  OONP）是一個用於複雜語言對象理解的新框架。作爲神經符號系統的實例，OONP不但有大量神經符號主義的具體實現，而且也爲神經網絡和符號的更多和更充分的融合留下充分的空間。
    > 
    > OONP借用面向對象編程（OOP）的思想，利用解析出來的實體組成對象和對象間關係（如圖8），構成結構清晰的本體圖。每個對象（object）都是一個類（class）的實例化，類的概念規定了其具有的內部屬性、外部關係和可執行的操作，以及與其他對象的關係類型。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57689f70.png)
    > 
    > 圖8：OONP的解析示意圖，左側的每一個小框代表了一個對象（object），框的顏色標識了類（class）
    > 
    > 如圖9所示，OONP由三部分組成，分別是主控模塊閱讀器（Reader）、表徵文檔的行間記憶（Inline Memory）模塊、以及總結對之前文本的理解的攜帶記憶（Carry-on Memory）模塊。而攜帶記憶（Carry-on Memory）模塊又可分爲表徵圖結構的對象記憶（Object Memory）、存儲連續狀態的矩陣記憶 (Matrix Memory) 和記錄離散動作的動作歷史 (Action History) 三部分。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a5797ecbf.png)
    > 
    > 圖9：OONP的整體架構
    > 
    > 在解析文本時，OONP模仿了人理解文本時一邊閱讀一邊理解的方式。OONP框架將解析過程轉化爲決策序列：OONP閱讀器按照文本順序讀文檔，同時不斷豐富本體圖結構來增進對文檔的理解，該圖結構被決策過程的操作序列創建和更新，並在解析的結尾作爲最終的文本語義表示。對於某個待解析的文檔，OONP首先將預處理之後的文檔放入行間記憶模塊，閱讀器順序讀取行間記憶中的符號表示和連續表示，結合攜帶記憶，產生各種操作來增加和豐富本體圖，更新攜帶記憶模塊。這些操作包含可微分操作（作用於對象記憶的連續部分和矩陣記憶）和離散操作（作用於對象記憶和行間記憶的符號部分）。這些連續和離散操作互相依賴，構成了彼此的輸入，共同形成了圖10中複雜而靈活的信息流。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57a226d6.png)
    > 
    > 圖10：閱讀器（Reader）的架構細節以及信息流
    > 
    > 在OONP框架內，連續和離散的表示、運算、知識相互緊密結合，形成信息閉環。這使得OONP可以靈活地將各種先驗知識用不同形式加入到行間記憶和策略網絡。具體來說：
    > 
    > -   整體來說，OONP解析的決策過程本身就是從神經網絡到離散結構（本體圖）映射的過程，而這個離散結構又成爲神經網絡控制的決策過程的輸入，從而形成了大的神經-符號的信息閉環。而在OONP的具體模塊上，這種閉環還大量存在；
    > 
    > -   在行間記憶和對象記憶裏，存在大量離散和連續並列的表示，比如說，對象記憶中的圖狀離散結構上會附有不同類型的連續向量表示。同時在OONP的運算層，每個動作的決定都需要融合來自規則引擎以及神經網絡的輸出。比如會有獨立的規則引擎來分析動作歷史，發掘大範圍的動作的模式，從而給出下一步的決策建議，而這些建議會和其他來自神經運算的結果一起匯入策略網絡的輸入；
    > 
    > -   在OONP的框架內，允許符號知識（如規則）轉換成爲功能接近的神經模塊，而這些神經模塊可以作爲OONP組件進行聯合訓練。
    > 
    > ### 5\. 從技術到產品
    > 
    > 以神經符號系統爲核心技術思想，深度好奇構建了以OONP爲核心技術框架的包括多個技術模塊的自然語言理解技術平臺。以此爲基礎，我們設計製造了公安案情結構化、智能視頻審覈、法律文書解析、語音視頻調度等一系列產品（見圖11）。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a5780451f.png)
    > 
    > 圖11：深度好奇的技術架構
    > 
    > 這裏我們以公安案情結構化和智能視頻審覈爲例：
    > 
    > -   **公安案情結構化：**這個系統對公安偵破過程中的文本信息進行解析，構建關於案情的人-事-物-時-地的知識圖譜（見圖12），讓機器「懂」案情，從而爲刑偵人員提供串併案、犯罪預測、信息比對及融合等決策輔助。公安案情結構化是OONP的一個成功應用，充分發揮了神經符號系統在解析複雜文本上的優勢。公安案情結構化任務的複雜性體現在多個方面，其相關文本形式多樣，敘述邏輯繁複曲折，而且最終的知識表示是包含多事件、多實體、多標籤以及時空關係的龐雜圖譜。爲了將文本中特定的敘述習慣等知識作爲規則嵌入OONP並獲得泛化能力，我們利用了Neural Rule Engine來處理理解過程中的特定子任務，取得了較小數據量下的顯著效果。
    > 
    > ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57b474e0.png)
    > 
    > 圖12：公安案情結構化示意圖
    > 
    > -   **智能視頻審覈：**該場景是對借款人進行視頻面試，從而基於交互過程進行信息審覈和欺詐檢測（見圖13）。深度好奇的智能視頻審覈系統依靠對語音對話的理解來構建對話系統，在溝通過程中根據用戶信息判定高欺詐風險的信息點，並進行主動的問詢。例如，當借款人提供的職業信息是「養生會所的工作人員」時，該系統就會追問「你們公司的客流量有多大」 、「你們公司的主要設備是什麼」 這類的問題。完整的對話過程將會被用來評估及判定借款人騙貸和逃貸等風險。
    > 
    >     ![神經符號系統: 讓機器善解人意](http://i2.bangqu.com/lf1/news/20181017/5bc6a57a2df96.png)
    > 
    > 圖13：智能視頻審覈示意圖

## 神經規則引擎（Neural Rule Engine）

- [[1808.10326] Generalize Symbolic Knowledge With Neural Rule Engine](https://arxiv.org/abs/1808.10326)

- [神經規則引擎：讓符號規則學會變通 - 幫趣](http://bangqu.com/9Xns9a.html)

    > 按：本文原作者爲深度好奇研究組，原發表於公衆號「深度好奇AI」（deeplycurious）。
    > 
    > 論文題目：Generalize Symbolic Knowledge With Neural Rule Engine
    > 
    > 論文地址：[（請戳此處）](https://arxiv.org/abs/1808.10326)
    > 
    > 目前的自然語言處理任務中，神經網絡模型在學術界佔據了絕對的優勢，然而，基於符號知識的規則系統仍然在工業界大有用武之地。人類語言是一種非常複雜的現象，爲了更好地構建語言智能系統，可以將神經網絡和符號知識融合使用，集成二者的優勢。
    > 
    > 近兩年來，神經符號學習（Neural Symbolic Learning）成爲一個非常熱門的方向，不少優秀的科研工作把符號知識引入神經網絡模型，增強了模型的學習能力和可解釋性，在一些經典的NLP任務上都取得了不錯的效果。與這種融合方式相反，近日，深度好奇的研究者們提出了一種全新的融合策略------利用NN模型來改進規則的效果。NN模型的優點是靈活性高、泛化能力強、魯棒性好，如果將NN模型的這些優勢賦予規則系統，會產生出怎樣的火花呢？
    > 
    > 本文介紹了一種神經規則引擎（Neural Rule Engine，NRE），NRE可以從規則中學習知識，同時又通過神經網絡來泛化知識，這與人類學習知識的方式有異曲同工之妙。
    > 
    > 具體來說，NRE由神經模塊網絡（Neural Module Networks）構成，其中的每一個模塊代表了規則中的一種操作，而模塊的實現形式既可以是神經網絡，也可以是符號算法。並且，給定少量的標註樣本，可以使用強化學習來微調（Finetune）學習效果。實驗證明，NRE可以大幅提升規則的召回率（Recall），同時還能將精確率（Precision）維持在較高的水準。
    > 
    > 舉個具體的規則例子，對於一個判斷案件類型的分類任務來說，案件內容如下：
    > 
    > 「2003年12月21日中午12時，東浦村張某與王某某二人到臨西縣遊玩，被三名男子跟蹤，後用刀威逼，搶走手機一隻。」
    > 
    > 根據經驗來看，如果案件表述中有「跟在.*後面|跟蹤」，一般屬於「尾隨作案」，但是如果其中有「事主.*跟隨」的話就不是。所以，針對「尾隨作案」類別，可以寫一條規則：
    > 
    > 「跟在.*後面|跟蹤@@事主.*跟隨」
    > 
    > 其中「@@」左邊藍色的是**正規則**，也就是句子中必須匹配上的內容，「@@」右邊紅色的是**負規則**，也就是句子中不能包含的內容。
    > 
    > 由於正則表達式是有限狀態機的一種，所以可以定義一些操作（Action）來解析正則表達式規則，比如：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a3a7789.png)
    > 
    > 用預先定義好的操作來表示規則，如下圖所示：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82cca00efc.png)
    > 
    > 每一條規則都可以被拆解成樹狀結構，拆解的過程依賴於**Rule Parser**。由於整個系統的設計既考慮了符號性又考慮了神經網絡的特性，所以對於規則的拆解上既可以用符號算法來實現也可以用Neural Rule Parser來實現。由於樹狀結構可以轉變成逆波蘭表達式（Reversed Polish Notation）的形式（如下圖）：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82cce369e2.png)
    > 
    > 因此可以採用一個Seq2Seq的神經網絡模型來實現對規則的拆解。具體如下：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82cccd906f.png)
    > 
    > 給定一條規則，鑑於同時預測模塊和模塊所需參數較爲困難，所以可以採取分步的方式來預測。第一步先預測操作序列，第二步根據規則和已經預測出來的操作來預測每個操作所對應的參數。爲了讓預測的結果更加可靠，在訓練階段，我們加入了微調（Finetune）過程，對於預測出來的操作序列根據在真實事例上的表現用強化學習來進行模型的調整。
    > 
    > 得到rule parsing的結果後，即可對模塊進行組裝。在本文中，Find模塊和And_Ordered模塊都採用了神經網絡的設計。
    > 
    > ### **Find**模塊
    > 
    > Find(x)模塊是用來查找句子中匹配x部分的內容，可以用正則表達式的匹配來實現，也可以用神經網絡來實現。神經網絡的Find模塊如下：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82cc86e419.png)
    > 
    > 對於每一個句子來說，Find(x)操作就是在句子中找到x，x可以是一個字、一個詞或者是一個N-gram。無論用神經網絡實現還是用正則表達式的match(x)來實現，任務都可以看作是對句子做序列標註，也就是對句子中的每一個單位都標註「是否匹配」的標籤。具體來說，對於句子中的每一個單位，先獲取到它滑動窗口的上下文，並令上下文和要查找的x都通過相同的編碼器（Encoder），之後用評價函數來對二者的相似程度進行打分，最後根據每個位置的所有分數來判斷當前位置的標籤。
    > 
    > ### **And_Ordered**模塊
    > 
    > And_Ordered模塊可以採取如下設計：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82cc84327b.png)
    > 
    > And_Ordered操作是用來判斷兩個輸入之間是否滿足一定的距離關係。通常來說，輸入就是子節點給出的標記結果，如r0和r1。爲了讓神經網絡更容易判斷輸入之間的距離，我們可以引入距離標記d0和d1。結合句子原文，And_Ordered模塊可以判斷出兩個子節點的輸入是否滿足距離關係。
    > 
    > ### 模型訓練
    > 
    > 在訓練過程中，模塊和Neural Rule Parser都採取了預訓練+微調的策略。在訓練時，先對數據和規則進行訓練集/驗證集/測試集的劃分，爲了避免數據泄漏，各部分之間不能混用。訓練模塊的時候，先根據數據隨機生成各個模塊的訓練樣本，在訓練到一定程度時，把訓練集中的規則真實應用於訓練集中的數據，按照數據的真實標籤採用強化學習的方式對模塊進行微調。對於Neural Rule Parser也按照類似策略，依前文方式進行訓練。
    > 
    > ### **Neural Rule Engine (NRE)**
    > 
    > NRE集合了上述的組件：NN/算法實現的模塊，NN/算法實現的Rule Parser。NRE的整體架構如下圖所示：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc82ccca0785.png)
    > 
    > 對於給定的一條事例和一條規則，NRE先將規則拆解成由模塊組成的樹狀結構，之後根據樹狀結構將規則應用於具體的語句上，從而給出匹配後的結果。
    > 
    > ### 實驗
    > 
    > 論文在中文案情分類（Chinese crime case classification）任務和SemEval-2010 relation classification任務上進行了實驗。實驗結果如下：
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a4383cf.png)
    > 
    > NRE在中文案情分類數據集上的結果
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a40b6d0.png)
    > 
    > NRE在關係分類數據集上的結果
    > 
    > 上面的結果顯示，RE的Precision很高，但是Recall相對較低。而第二組Baseline是傳統意義上的序列模型，並不能處理好正則表達式，特別是正則表達式除了局部的匹配還需要考慮有層級關係的全局匹配，傳統的序列模型很難處理好這些情況。NRE則能帶來Recall接近翻倍的效果，同時Precision仍維持在較高的水平。需要關注的是，微調（Finetune）對NRE來說是至關重要的，因爲NRE在預訓練階段是單純地在訓練各個模塊，而微調是讓規則在真實場景中調整的關鍵。
    > 
    > 同時，由於NRE可以充分利用神經網絡和符號二者的優勢，爲了探究規則的泛化性從何處而來，我們還進行了額外的實驗。我們通過對不同部分分別採用神經網絡和符號算法，從而得到了混合的模型（見下表）。隨着神經網絡的介入，NRE整體的Recall表現會更好，而Precision在合理的範圍內有所下降。實際上，這是因爲神經網絡的靈活性所帶來的優勢，彌補了規則匹配的僵硬。
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a484ff0.png)
    > 
    > 神經網絡和符號算法的不同組合，其中「_」左邊是神經網絡的實現，右邊是算法實現，「P」是「Find_Positive」，「N」是「Find_Negative」，「A」是「And_Ordered」，「S」是「Rule Parser」。
    > 
    > 另一方面，研究模型給出的結果可以發現，Find模塊帶來了巨大的泛化能力。傳統的正則表達式是對樣式進行匹配，而NRE在一定程度上是對語義進行匹配。如下述兩圖的中英文案例所示，查找「pushed into」會合理地找到「put inside」，而像「進入室內」被「入室」整體匹配上更能說明NRE對詞語的查找會超越樣式本身。
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a46cfd2.png)
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a5663cd.png)
    > 
    > 與此同時，用Neural Rule Parser對規則進行拆解也是對規則本身進行修正。比如下圖中的「落水管」和「不鏽鋼管」被合併成爲了「管」，而且「打牆洞」中的「洞」被刪去。
    > 
    > ![神經規則引擎：讓符號規則學會變通](http://i2.bangqu.com/lf1/news/20181018/5bc844a64e0f1.png)
    > 
    > ### 總結
    > 
    > 我們提出了一種全新的學習策略來對符號規則進行改進，神經規則引擎（Neural Rule Engine）使得規則獲得了神經網絡帶來的靈活性、魯棒性和泛化能力，同時又保持了規則的精確性和可解釋性。
    > 
    > NRE包含了Rule Parser和一系列操作模塊，它們既可以是定製化的神經網絡，又可以是符號算法。對於一條給定的規則，NRE先對規則進行拆解，使其成爲操作序列，之後根據操作序列來裝配模塊，最終給出預測結果。此外，我們還提出了分步的訓練方法使得構建NRE成爲可能，即先對模塊和Rule Parser隨機生成數據進行預訓練，之後根據真實的樣本標註用強化學習進行微調，從而得到具有泛化能力的規則表示。
    > 
    > 實驗表明NRE可以大幅提升規則的Recall，同時還能維持較高的Precision。NRE不僅是一種新的神經符號學習範式，同時也爲現有的工業應用帶來了一種高效的改進，它可以被用來對已有的規則系統進行升級，或者在訓練數據不大的情況下快速開發出神經規則系統。



## 變焦神經網絡（Zooming-Net）

- [[1810.02114] Zooming Network](https://arxiv.org/abs/1810.02114)

- [深度好奇AI](https://mp.weixin.qq.com/s?__biz=MzIzODg2MTU3Mg==&mid=2247483854&idx=1&sn=19464fedd33d7b1ff5f68432fd1a00af&chksm=e933ada5de4424b3167de2469277946d7e4e262f5b8f075246d8da95823067d81ccfafb982de&mpshare=1&scene=24&srcid=1112NnN9kGol8K66vXq0CMHb#rd)

    > **设计动机**
    > 
    > 神经网络模型之所以能够在人工智能的各个领域大放异彩，除了凭借强大的拟合能力和各类梯度下降方法之外，还要依靠网络结构基于数据信息分布特征的针对性设计。比如，多层全连接网络虽然在理论上可以拟合任何函数，实际应用中的效果却往往差强人意；而另一方面，多层卷积神经网络由于采用了类似大脑初级视觉皮层信息处理方法的卷积操作与参数共享方法，对图像信息进行高效的特征提取（充分利用了图像中的平移不变性、局部信息连续性），可以使用少得多的参数在图像处理任务上取得非常好的效果。
    > 
    > 我们认为自然语言处理领域尚无一种类似卷积网络的在图像处理领域具有奠基作用的模型。究其原因，是我们尚未充分利用自然语言数据和任务天然具有的特征进行模型结构的改进。自然语言天然地具有如下特征：1）自然语言（文本）是由一些基本语言单元（如单词、字、词）构成的序列；2）语言单元具有层级特征，低级语言单元可以构成高级语言单元（如多个字可以组成一句或一段文本）；3）语言单元的划分不是随机的，而是包含着语者或作者的信息表达策略；4）不同于图像数据，基本语言单元不具有像素一样的局部连续性，而是高度信息符号化的。
    > 
    > 为了更好地利用上述文本特征，我们提出了变焦网络（Zooming Network）的概念。整体上看，变焦网络由三个主要部分组成：层次化编码模块、变焦控制器模块、符号推理模块，分别完成针对语言单元特点的编码过程、解码过程，以及针对自然语言符号化的推理辅助解码。我们将该网络设计应用到长文本序列标注任务上，取得了非常好的效果（f1 score超过bi-LSTM-crf模型10%以上）。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2Ubktg3jrVujzNfB4k83J4FmHZuibn48SliaOp3KFbZ0HfVtQNEibLsDrX7g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > **层次化编码（Hierarchical Encoder）**
    > 
    > 人在阅读文本时既按照时间顺序累积信息，又伴随着不同级别的信息抽象。这对应着人类语言文字共有的两个重要特征：时序化和分级化。我们对与编码模块的设计就是利用了这两个特征：使用双向长短时记忆层（bi-LSTM）对单一语言单元层级进行顺序地读取、编码；使用最大池化操作（max-pooling）模仿人脑由低级语言单元抽象高级语言单元信息的过程。通过层次化编码，我们赋予每一级每一个语言单元一个向量表示（hierarchical distributed memory），并保留其句段划分的分界信息。
    > 
    > **变焦控制解码（Zooming controller）**
    > 
    > 变焦控制器本质上是一个序列决策模型。不同于经典的循环神经网络（RNN）模型：1）变焦控制器每次不是接收单个基本语言单元的信息，而是接收当前位置上的字、句、段三级信息，这样可以使模型同时掌握细节特征（detailed local feature）和整体特征（global feature），以更好地进行状态更新。2）在每个解码标签序列的时刻，变焦控制器可以选择当前解码长度，可以选择输出任意层级语言单元对应的标签，而不仅限于基本语言单元（字/字符）。3）在预测标签之后，读取位置会自动跳转到与解码层级一致的下一语言单元的开头，而不是直接跳转到下一个基本语言单元。这种解码过程使得变焦控制器对文本表征的阅读方式更加灵活，在信息分布稀疏的部分可以快速略读（Zoom out），在信息分布集中的部分可以逐字精读（Zoom in）。
    > 
    > **符号推理（Symbolic reasoning）**
    > 
    > 在解码过程中，我们可以通过自然语言文本的一些"写作习惯"特征和已经预测出的标签序列，对下文标签规则推理出一些建议标签。例如，在大量的垂直领域文本中，常常出现一些有序列举过程："1. ...... 2. ...... 3. ......"。这些有序符号往往成组出现，而且对应内容是等位并列关系，一般具有相同标签（或者相同结构标签）。在实际使用过程中，我们会综合上个序号内容的处理方式，给出下个序号内容处理的最佳路径并以稀疏向量的形式输入到变焦控制器内，使其可以更加高效地处理数据。  
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbCcQatypLicZic3Tz6tsppDLDBgOicX9gV02QlLmJicWQnzIHs71e7IYMmQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > **实验情况**
    > 
    > 我们将该模型应用到两组数据的序列标注上：
    > 
    > 1）集中式的重点信息抽取：在刑事案件的裁判文书中，对犯罪事件的具体描述提供了整个案件的判决依据，有很重要的分析价值。这些描述往往集中出现，但是由于整个裁判文书的长度多变，案件复杂程度不一，对这些描述的高效抽取既需要快速地略过无关信息，又需要在信息出现的段落进行精细的分析。下图示例中红色及蓝色的文字表示被Zooming Network抽取出来的部分，不同的颜色则代表不同的犯罪事件标签。
    > 
    > > 被告人张三，男，1978年3月17日出生，现因涉嫌犯盗窃罪，于2005年9月21日被羁押，同年10月28日被逮捕，现羁押在北京市海淀区看守所。
    > > 
    > > 
    > > 北京市海淀区人民检察院指控被告人张三犯盗窃罪，于2006年6月9日向本院提起公诉。本院依法组成合议庭，公开开庭审理了本案。北京市海淀区人民检察院指派检察员武军出庭支持公诉，被告人李忠士到庭参加诉讼。现已审理终结。
    > > 
    > > 经审理查明：
    > > 
    > > <font color="red">被告人张三于2001年4月1日，在本市海淀区车道沟10号院东99丙号楼3单元地下室，撬门入室窃取被害人A的现金人民币1 700元，窃取被害人B的诺基亚5110型手机1部、爱立信398型手机1部，共计折合人民币2 667元。赃款、赃物均未起获。</font>
    > > 
    > > <font color="blue">被告人张三于2001年8月13日，在本市海淀区万寿路甄家坟集体宿舍，翻窗入室窃取被害人C的现金人民币7 300元、纯金戒指1枚，共计折合人民币8 400元。现赃款、赃物均未起获。</font>
    > > 
    > > 综上，被告人张三共盗窃作案2次。
    > > 
    > > ---
    > > 
    > > The defendant Zhang San, male, born on March 17, 1978, was detained on September 21, 2005 for suspicion of theft and was arrested on October 28 of the same year. He is now detained at the Haidian District Detention Center in Beijing.
    > > 
    > > Haidian District People's Procuratorate accused the defendant Zhang San guilty of theft, on June 9, 2006 prosecution to this court. Our court formed a collegiate bench and heard the case openly. Beijing Haidian District People's Procuratorate appointed inspector Wu to appear in court to support the prosecution, the defendant Li Zhongshi to attend the proceedings. Now trial ended.
    > > 
    > > After trial found:
    > > 
    > > <font color="red">On April 1, 2001, defendant Zhang San stole the victim's cash of RMB 1,700 in the basement of Unit 3, Building 99, Lane 10, Lane 10, Lane, Haidian, Haidian, to steal the victim's Nokia 5110 A mobile phone, Ericsson 398 mobile phone 1, a total of 2 667 yuan equivalent. Stolen money, stolen goods have not played.</font>
    > > 
    > > <font color="blue">On August 13, 2001, the defendant, Zhang San, stole the victim's C for 7,300 yuan in cash and 1 piece for the pure gold ring in a rented apartment in Zhenjiafen, Wanshou Road, Haidian District, on August 13, 2001. The total amount was equivalent to 8,400 yuan . Now stolen money, have not been stolen goods.</font>
    > > 
    > > To sum up, the defendant Zhang three commoner theft 2 times.
    > 
    > 2）分散式的重点信息抽取：在知识产权纠纷案件的裁判文书中，案件的核心是原被告双方争议的焦点。这些信息随着对纠纷的描述不定位置地出现，出现形式也复杂多变，进一步要求模型对处理路径的灵活选择。下图示例中红色及蓝色的文字表示被Zooming Network抽取出来的部分，不同的颜色则代表不同的争议焦点标签。
    > 
    > > 本院认为，原告张三是涉案发明专利的专利权人，该专利至今在有效期限内，法律状态稳定，应受法律保护。任何单位或者个人未经专利权人许可不得实施该专利，否则应承担相应法律责任。
    > > 
    > > 综合本案当事人的诉辩意见，本案争议焦点主要在于以下两个方面：<font color="red">1.被控侵权产品是否落入涉案专利权利要求1的保护范围；</font><font color="blue">2.被告的侵权责任应如何承担。</font>
    > > 
    > > ---
    > > 
    > > The court held that the plaintiff Zhang San was the patentee of the invention patent involved in the patent so far, and the patent so far has a stable legal status and should be protected by law. Any unit or individual may not implement the patent without the permission of the patentee, or shall bear the corresponding legal responsibility.
    > > 
    > > Based on the opinions of the parties involved in this case, the focus of the dispute in this case lies mainly in the following two aspects: <font color="red">1\. Whether the accused infringing product falls into the protection scope of Claim 1 of the patent involved;</font> <font color="blue">2\. How the defendant's tort liability should be borne.</font>
    > 
    > 我们使用序列标注经典最优模型bi-LSTM-crf作为baseline model来比较模型的处理性能，实验结果如下（模型参数数量为同一量级）：
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbgBpH9dkVtf1yQlxeHAf3z67C3wSFT3b4slnHFAO47oVicecLw1rjPuw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 其中，WA指word-level的整体准确率，wlar指模型使用的逐字读取行为占全部处理行为的数量比例。可以看出，变焦网络的性能远超基线模型，而且具有很高的处理效率（大量地使用句、段级别的标签预测行为）。这个过程的具体示例如下：
    > 
    > > <font color="blue">
    > > 被告人张三，男，1978年3月17日出生，现因涉嫌犯盗窃罪，于2005年9月21日被羁押，同年10月28日被逮捕，现羁押在北京市海淀区看守所。
    > > 
    > > 北京市海淀区人民检察院指控被告人张三犯盗窃罪，于2006年6月9日向本院提起公诉。本院依法组成合议庭，公开开庭审理了本案。北京市海淀区人民检察院指派检察员武军出庭支持公诉，被告人李忠士到庭参加诉讼。现已审理终结。
    > > 
    > > <font color="red">经审理查明：
    > > 
    > > 被告人张三于2001年4月1日，在本市海淀区车道沟10号院东99丙号楼3单元地下室，撬门入室窃取被害人A的现金人民币1 700元，窃取被害人B的诺基亚5110型手机1部、爱立信398型手机1部，共计折合人民币2667元。</font>赃款、赃物均未起获。
    > > 
    > > <font color="red">被告人张三于2001年8月13日，在本市海淀区万寿路甄家坟集体宿舍，翻窗入室窃取被害人C的现金人民币7 300元、纯金戒指1枚，共计折合人民币8400元。</font>现赃款、赃物均未起获。
    > > 
    > > 综上，被告人张三共盗窃作案2次。
    > > 
    > > 上述事实，被告人张三在开庭审理过程中亦无异议，且有物证涉案物品价格鉴定（认证）结论书，被告人的供述等证据证实，足以认定。
    > > 
    > > 本院认为，被告人张三以非法占有为目的，多次秘密窃取他人财物，数额较大，其行为已构成盗窃罪。公诉机关指控的事实、罪名成立，本院予以确认。据此，为保护公私财产权利不受侵犯，惩罚犯罪，依照《中华人民共和国刑法》，判决如下：
    > > 
    > > 被告人张三犯盗窃罪，判处有期徒刑一年。
    > > 
    > > 审判长  张某某
    > > 
    > > 人民陪审员  曲某某
    > > 
    > > 人民陪审员  杨某某
    > > </font>
    > 
    > 其中，蓝色部分表示模型使用了句级、段级的预测，红色部分表示模型使用了字级的预测。可以看出，在信息意义不大的部分，模型选择了略读，而在关键信息出现的地方，模型采用了精读的方式处理。另外一个有意思的现象是，模型对于"经审理查明"等带有指示功能的语句一样采用了精读方式处理。
    > 
    > **总结**
    > 
    > 借助句段结构信息，变焦神经网络很好地结合了泛读与精读过程，可以更好地对长时依赖特征进行建模，引入大跨度动作提高效率，尤其在篇幅很长的文本处理中表现得更为明显，在关键信息的抽取任务上，f1值较经典序列标注模型（biLSTM+CRF）有10%以上的提升。在此基础上引入神经符号化推理模块后，其处理效率又有了一个显著提升。变焦神经网络非常适合应用于各类长文本处理任务当中，其使用的编解码方式也可结合其他技术推广到各类自然语言处理任务中，产生新的火花。
    > 



## 神經實體推理（Neural Entity Reasoner）

- [[1810.00347] Neural Entity Reasoner for Global Consistency in NER](https://arxiv.org/abs/1810.00347)

- [成果 | 用神经推理来帮助命名实体识别](https://mp.weixin.qq.com/s?__biz=MzIzODg2MTU3Mg==&mid=2247483858&idx=1&sn=3fc1d01481993ca44a1066e93d3b3210&chksm=e933adb9de4424afb0490dc2123b7f62affe14abce34b3cf50307ec9b11555606dc8746136d9&mpshare=1&scene=24&srcid=1110DBsIPiJ9JuCe1kFC7yco#rd)

    > 命名实体识别（Named Entity Recognition）被认为是文本理解的基础和底层任务，因为它的职能就是发现和标识文本中的人名、地名等。传统的NER方法依赖局部和底层的语言特征，近年来神经网络结构对局部语言特征的掌握取得令人瞩目的效果，以至于NER很多时候被当成"已解决"的任务。但现有的方法与研究往往局限于底层的分析和计算，忽视实体本身对文本理解过程的影响，引入CRF进行解码的成功也正是因为如此。
    > 
    > 当出现有歧义的说法或者少见的人名时，现有方法往往会遇到困难。而人在这种情况下，往往可以通过纵览全文，打通和融合局部的知识，来摆脱这种困境。所以，NER任务本质是模型对抽取实体进行理解的任务。本文正是受到人的思维模型的启发，为NER这个看似低级的任务引入了高级的"推理"机制，将符号化的命名实体信息"**取之于网络，用之于网络**"，从而可以在深度学习的框架内融合同一文本中的命名实体的决策。
    > 
    > 命名实体神经推理机（NE-Reasoner）从实体对象这一更高层次的角度出发，分析实体识别的运算过程，引入可人工设计的推理框架，通过以下三点完成实体的理解和推理：1）在现有方法的基础上，得到对于实体的完整表示；2）引入符号化缓存记忆，对实体信息进行存储；3）通过符号化的操作和推理模型，避免复杂化的处理，以端到端的形式轻松完成训练。
    > 
    > **概述**
    > 
    > NE-Reasoner整体上是一个多层的架构，每一层都由三部分组成，编码器对输入文本进行编码以捕捉语义等信息，推理单元通过编码信息和缓存记忆，得到实体间的推理信息，解码器综合这两部分信息得出最后的结果。在编码器与解码器保持不变的情况下，缓存记忆在层之间根据识别出的实体动态的变化，通过推理单元达到逐步推理的效果。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2Ub43o93FyeNQxxsC3LsTOeLgcvwNoD3ZuPmNNOBdRG72Xo9XPKSYY5NQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图1 NE-Reasoner整体多层架构
    > 
    > 具体来讲，每一层都独立完成一次NER；每层的NER结果，会通过一个符号化的"缓存"存储起来，作为下一层NER的参考；这种参考是通过一个交互式的池化神经网络来实现，它其实是一个基于多个事实的推理模型。通过这样的设计，在做每个局部的决策时，模型都可以"看见"目前识别出的所有实体信息并参考别处相关决策，从而做出更加明智的决定。
    > 
    > **实体的表示**
    > 
    > 探究实体的预测过程，首先要清楚实体出现的语言模式。每一个实体的确定，都存在决定性的标识，这种标识来自两方面，一个是字词本身的信息，比如"张某某"这种词汇，没有任何上下文的情况下，会优先将它作为人名处理；另外一方面是前后文的模式，比如"我和XX是好朋友"，我们可以推断XX处为人名。从这两方面信息，我们可以对实体模式进行如下的解构：
    > 
    > 前文信息-实体-后文信息
    > 
    > 这样一种结构可以完整地描述一个实体。在神经网络中，现有的方法也是通过这些局部的语言特征进行识别，所以可以轻易地从编码信息中找到实体的表示。
    > 
    > 对于本文使用的Bi-LSTM编码器，分别从前后两个方向对一个字进行上下文的编码，而解码器通过这些信息得到对于实体的决定性信息。所以，在实体的第一个字，前向的LSTM的编码信息一定包含实体的前文信息，最后一个字的后向LSTM编码信息一定包含实体的后向信息，而另外两部分都包含完整的实体字符信息。对于每一个实体，我们都可以将它的编码信息做这样的分解，以得到这样四个不同维度对实体的表示：
    > 
    > 前文信息-前向实体信息-后向实体信息-后文信息
    > 
    > 这也刚好符合前面对实体模式的分析。通过每一层最终的预测结果，可以利用这样的符号化信息定位到实体位置，将每一个实体都从这四个方面进行完整的表示，然后存入缓存记忆中。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbW53mpNDqL3B5VPK92oDLyUbZQhRWKlRgicumbHKHOYS2ACFPvn50G7g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图2 利用上下文和前后向信息表示实体
    > 
    > **推理单元**
    > 
    > 通过上面的操作，每一层都可以得到上一层识别出的实体的表示，除此之外，层与层之间没有其他必然的联系。将每一层单独来看，我们相当于得到了该文本中都有哪些是实体以及它们为什么是实体这类非常重要的先验知识。
    > 
    > 不同于以往方法对记忆模块的使用，这里的缓存记忆实际上是由符号化信息指导产生的堆放实体信息的列表，作为外部信息，不需要进行梯度的传导。由于每个实体也都是独立的，所以缓存记忆在这里可以看作由多个事实组成，而推理单元的作用就是从这些事实中得到全局的推理信息。
    > 
    > 解码时，字符的编码信息与每一个实体的表示进行运算以获得与每一个实体的关系，再通过池化操作从中挑选出最具有代表性的关系作为最终的参考。具体到本文的任务来讲，我们通过语义之间的相似性来进行推断，如果存在实体模式与当前所读到的字段相似，那么相似字段在文本中所扮演的角色也应该是相似的，所以可以使用向量距离（如余弦距离）等运算来代表字符编码信息与实体之间的关系，本文使用的是向量内积。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2Ub13FMjIUibxXkDqe2eYTJfZyRQCLrtZicYXtic8zF9FA9wbFgnqAnpnZ6w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图3 利用记忆模块进行实体推理
    > 
    > 之后，每一个实体的四个维度都可以得到一个运算结果，表示在这四个方面的相似度。在实体的推理中，最重要的是是否存在一个实体信息与当前字段信息很相似，而具体哪一个或者有几个这样的信息是不重要的；所以，在四个维度上进行max-pooling可以得到四个值，作为最终的参考信息。将这部分信息与编码信息一起输入到解码器，从而得到这一层的输出。
    > 
    > **训练**
    > 
    > 由于每一层都相对独立且具有单独的输出结果，层与层之间不需要梯度的传导但却通过预测结果进行影响，所以可以有多种训练方式，比如预训练第一层、每一层联合训练或仅利用最后一层输出结果进行训练。本文中所使用的模型的每一层都共享参数，实际上层间的区别只有缓存记忆的实体信息的不同，因此直接对最后一层进行训练就可以在整体上得到好的结果。
    > 
    > **实验**
    > 
    > 本文在英文和中文两个数据集上进行了实验，均取得了明显的提升。由于本方法是一个通用的框架，理论上可以叠加到任意编码-解码形式的网络模型中；并且由于是逐层的输出，可以从不同层之间输出结果的变化看到真实的推理效果，不仅提升了效果，而且符合对推理的预期，有极强的可解释性。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbyedCBj53eTtJUiaBdJYsecHopnttfBbkZPTOP5qQH3Ez0gAoyEXibibzQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图4 NE-Reasoner修正前后典型结果对比
    > 
    > **总结**
    > 
    > 通过在神经网络的推理过程中引入符号化的缓存记忆，以及在缓存基础上的多事实全局推理，可以显著提高命名实体识别的准确率，尤其是在传统方法容易犯错的歧义和少见人名上有更好的表现。命名实体神经推理机作为神经符号推理机在NER任务上应用的一个实例，不仅打开了之前神经网络推理决策的黑箱，使得推理过程中的关键步骤对人类可见和可理解，还给予了人工进一步干预推理过程的可能性以及可用的接口。



## 面向對象的神經規劃（OONP）

- [[1709.08853] Object-oriented Neural Programming (OONP) for Document Understanding](https://arxiv.org/abs/1709.08853)


## 成果 | 强化学习新模型Jumper，让神经网络学习在阅读中何时做决定 

- [[1807.02314] JUMPER: Learning When to Make Classification Decisions in Reading](https://arxiv.org/abs/1807.02314)

- [深度好奇AI](https://mp.weixin.qq.com/s?__biz=MzIzODg2MTU3Mg==&mid=2247483855&idx=1&sn=a6c573571fd61d8ecf42c9b495a477dc&chksm=e933ada4de4424b2dcb6d4ef6734c427f247d1bc89a5425e5608007941f09dc5782c124b2a80&mpshare=1&scene=24&srcid=1110oCByPQnK5IoonooUjgS2#rd)

    > 文本理解是自然语言处理领域的一个核心目标，最近取得了一系列的进展，包括机器翻译、问答等。不过之前的工作大多数是关心最终的效果，而人们对于模型何时做出决定（或做决定的原因）却知之甚少，这是一个对于理论研究和实际应用都非常重要的课题。深度好奇（DeeplyCurious.AI） 最近在IJCAI-2018上展示了一个学习何时做分类决策的强化学习模型：Jumper， 该论文将文本分类问题建模成离散的决策过程，并通过强化学习来优化，符号化表征模型的决策过程具有很好的可解释性，同时分类效果也达到最高水平。
    > 
    > 本文提供了一种新的框架，将文本理解建模为一个离散的决策过程。通常在阅读过程中，人们寻找线索、进行推理，并从文本中获取信息；受到人类认知过程的启发，我们通过将句子逐个地递送到神经网络来模仿这个过程。在每个句子中，网络基于输入做出决策（也称为动作），并且在该过程结束时，该决策序列可以视为是对文本有了一些"理解"。
    > 
    > 特别一提的是，我们专注于几个预定义子任务的文本分类问题。当我们的神经网络读取一个段落时，每个子任务在开始时具有默认值"无"（None）。 在每个决策步骤中，段落的句子按顺序被递送到神经网络；之后，网络来决定是否有足够的信心"跳转"到非默认值作为特定时间的预测。我们施加约束，即每次跳转都是最终决定，它不可以在后面的阅读中被更改。如图1所示，给定一段话，有多个预先定义好的问题等待回答；模型按句子阅读，在阅读过程中，问题的答案陆续被找到。模型从默认决策到非默认决策都是一个"跳转"的过程，正因此我们称模型为Jumper。在人类阅读的过程中，人们通常会获得一致的阅读理解的结果，但是阅读理解过程中的很多环节却经常是微妙和难以捉摸的。同样，我们也假设我们的训练标签仅包含最终结果，并且没有给出关于模型应该做出决定的步骤的监督信号。也就是说，我们通过强化学习在弱监督信号情况下训练Jumper模型。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2Ubg6AwWGrZn5d0INLAhygLtyNkhkoX01nfQyIFr6P2AjgroSbn8hL24w/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图1 Jumper模型在阅读段落的决策过程
    > 
    > Jumper模型主要由编码层、控制器、符号输出层构成。编码层将句子编码成定长的向量，控制器根据历史和当前输入产生当前的决定，符号输出层使模型的输出满足跳转约束，即每个决策过程最多只能有一次跳转。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbT2wWvGkU9YM2rddusgHXND6BPgkNMicFwjmibR80nZpkjPlO6Q9DGP3Q/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图2 Jumper模型的基本框架
    > 
    > 跳转约束的作用在于使模型更加慎重地决定何时跳转。因此，Jumper模型的优化目标有两个，第一个是尽可能早地"跳转"，第二个是尽可能预测准。假设t* 是最佳的跳转时间，那么如果模型在t* 时刻之前跳转，则模型还没有看到真正的pattern，那么得到的答案等同于随机猜；如果模型在t* 时刻之后跳转，而t* +1句话可能不存在，因此没有机会跳转从而预测错误。
    > 
    > 通过上述建模，论文把文本分类问题转化为离散的决策过程，训练好的Jumper输出的离散决策过程就可以表达模型对文本的理解过程；而决策过程本身并没有标签，因此我们用policy gradient强化学习算法来训练，如果最终的决定和分类标签一致，就奖励整个决策动作，如果不一致，则惩罚。
    > 
    > 我们对三个任务评估了Jumper，包括两个基准数据集和一个实际工业应用。我们首先分析了Jumper的分类准确性，并与几个基线进行了比较。表1显示Jumper在所有这些任务上实现了相当或更好的性能，这表明将文本分类建模为顺序决策过程不仅不会损害、甚至提高了分类准确性。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbSrZUN0tqyrknjNDkl1OSt5FwmNUzSJdw93CIDOExjCve9wPXVrK21g/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 表1 在电影评论数据集（MR）、新闻数据集（AG）和工伤数据集（OI）的测试集上的准确率
    > 
    > 我们想指出，"准确性"并不是我们关注的唯一表现。更重要的是，提出的模型能够减少阅读过程，或者找到文本分类的关键支撑句。只要在阅读过程中基于"跳转约束"限制而看到足够的证据，Jumper就能做出决定，并且在预测之后不需要再阅读之后的句子。在表2中可以看到，我们的模型与强基线相比达到了相似或更高的性能，与此同时，它还将文本读取的长度缩减了30-40％，从而加速了推断预测。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2Ub4fyMLlG6pjqQbffkibxoHgeYaTga62oTpCtldtytFdkZ2FUPUpU7kRQ/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 表2
    > 
    > 除了准确率高和推断速度快以外，我们更好奇Jumper是否能够在信息提取式任务（例如工伤级别分类任务）中找到正确的位置做出决策。我们在400个数据点中标注关键支撑句（即最佳跳转位置）作为测试基础。需要注意的是，在这个实验中我们仍然没有跳转位置的训练标签。我们将Jumper与使用相同神经网络的层级CNN-GRU模型进行比较，但在训练方法方面有所不同；层级CNN-GRU在训练时，用段落末尾的交叉熵作为损失函数。在测试期间，我们将预测器应用于每个步骤并找到它做出预测的第一个位置。我们还列出了一个经典CNN的结果作为基线模型，并使用了最大池化操作（max-pooling）选择的单词最多的那些句子来作为测试数据。我们使用了跳转动作的准确率来评测Jumper。通过表3可知，Jumper准确地找到了测试集中所有关键支撑句的位置，说明我们的单跳约束迫使模型更仔细地思考何时做出决策，也验证了强化学习是学习决策正确位置的有效方法。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbGsvNRWJO2zIDRldL6YA3Tzz5P6NwicHyVjIibUpkr3ZibzEsNZAM0TTBA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 表3 各模型在工伤等级分类任务（OI-Level）上寻找关键支撑句的效果统计。该任务的关键支撑句在文本中通常聚集于一处，不存在歧义，便于衡量各模型效果。CA：分类准确率，JA：跳跃准确率，OA：在分类准确条件下的跳跃准确率
    > 
    > 图3则显示了Jumper在阅读时做出决策的过程。其中，Jumper在前六个句子中保持默认决策（不做跳转），而在到达关键支撑句时突然跳转，这体现了Jumper可以识别关键支撑句，从而找到最佳跳跃位置。因此，在这类关键支撑语句集中出现时，Jumper可以在完成分类任务的同时找到关键支撑句，因此具有较强的可解释性。
    > 
    > ![](https://mmbiz.qpic.cn/mmbiz_png/micYOAOvzMGtX1NasPmY8PSBbLNsws2UbTADPZjwvgx6dwNP17cvv6MtMdOuCZy029xa7MBdicqKOyXDMNVsk0Wg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)
    > 
    > 图3 Jumper决策序列展示
    > 
    > **总结**
    > 
    > 我们提出了一种新的模型Jumper，它在阅读段落时将文本分类建模为逐个句子的顺序决策过程。我们通过强化学习训练带有跳转约束的Jumper，实验表明：1) Jumper的性能与基线相当或更高；2) 它在很大程度上减少了文本阅读量；3) 如果所需信息在文中的分布是局域性的 ，它可以找到关键的支撑句子，具有很好的可解释性。



